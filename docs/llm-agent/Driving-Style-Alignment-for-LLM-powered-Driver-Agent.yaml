- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: æœªåˆ†ç±»'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:50:12'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Driving Style Alignment for LLM-powered Driver Agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: æ¥æºï¼š[https://ar5iv.labs.arxiv.org/html/2403.11368](https://ar5iv.labs.arxiv.org/html/2403.11368)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Ruoxuan Yang, Xinyue Zhang, Anais Fernandez-Laaksonen, Xin Ding and Jiangtao
    Gong^(ğŸ–‚) The authors are with the Institute for AI Industry Research, Tsinghua
    University, Beijing, China. Corresponding Email: gongjiangtao@air.tsinghua.edu.cn'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Recently, LLM-powered driver agents have demonstrated considerable potential
    in the field of autonomous driving, showcasing human-like reasoning and decision-making
    abilities. However, current research on aligning driver agent behaviors with human
    driving styles remains limited, partly due to the scarcity of high-quality natural
    language data from human driving behaviors. To address this research gap, we propose
    a multi-alignment framework designed to align driver agents with human driving
    styles through demonstrations and feedback. Notably, we construct a natural language
    dataset of human driver behaviors through naturalistic driving experiments and
    post-driving interviews, offering high-quality human demonstrations for LLM alignment.
    The frameworkâ€™s effectiveness is validated through simulation experiments in the
    CARLA urban traffic simulator and further corroborated by human evaluations. Our
    research offers valuable insights into designing driving agents with diverse driving
    styles. The implementation of [the framework](https://github.com/AIR-DISCOVER/Multi-alignment-Drivng-Agent)Â¹Â¹1[https://github.com/AIR-DISCOVER/Multi-alignment-Drivng-Agent](https://github.com/AIR-DISCOVER/Multi-alignment-Drivng-Agent)
    and details of [the dataset](https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset)Â²Â²2[https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset](https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset)
    can be found at the link.
  prefs: []
  type: TYPE_NORMAL
- en: I INTRODUCTION
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the burgeoning field of autonomous driving (AV), driver agents powered by
    Large Language Models (LLMs) are demonstrating remarkable promise due to their
    exceptional planning[[1](#bib.bib1)] and reasoning[[2](#bib.bib2), [3](#bib.bib3),
    [4](#bib.bib4)] capabilities. Researchers have delved into the development of
    intricately designed driver agents that could perceive environmental stimuli[[5](#bib.bib5),
    [6](#bib.bib6), [7](#bib.bib7)], comprehend the situation[[8](#bib.bib8)], fetch
    their memories[[9](#bib.bib9), [10](#bib.bib10)] and deduce subsequent driving
    actions[[11](#bib.bib11)] that mirrors human decision-making. Such human-like
    AVs show promise in navigating a diverse range of driving scenariosÂ [[12](#bib.bib12),
    [13](#bib.bib13)], enabling better anticipation of AV behavior by other road usersÂ [[14](#bib.bib14)],
    while also enhancing human trust in these systemsÂ [[15](#bib.bib15)].
  prefs: []
  type: TYPE_NORMAL
- en: However, aligning these driver agents with human driving styles to imbue them
    with more human-like and personalized characteristics remains unexplored. Prevailing
    strategies for aligning LLM-based agents with humans, such as fine-tuning[[5](#bib.bib5),
    [6](#bib.bib6), [16](#bib.bib16)] and the integration of expert feedback[[17](#bib.bib17),
    [18](#bib.bib18)], are often hindered by their high costs. Recently, some studies
    have leveraged AI to generate feedback or reflections[[19](#bib.bib19), [20](#bib.bib20),
    [21](#bib.bib21), [22](#bib.bib22)], yet they fall short in aligning such reflections
    with human perspectives. On the other hand, despite researches focusing on employing
    AI to generate few-shot demonstrations[[1](#bib.bib1), [23](#bib.bib23)] for LLMs,
    another challenge in enhancing agent-human alignment lies in the lack of high-quality
    human behavior data in a form accessible to LLMs, making it difficult for agents
    to learn from human demonstrations. Existing datasets for autonomous driving learning
    either provide only environment data for perception tasks[[24](#bib.bib24), [25](#bib.bib25),
    [26](#bib.bib26)] rather than driving behaviors, or present driving behaviors
    in non-linguistic modalities (e.g. trajectories in maps[[27](#bib.bib27)], Controller
    Area Network Bus (CAN-Bus) data[[28](#bib.bib28), [29](#bib.bib29)], in-car videos[[30](#bib.bib30)])
    that are indirect for LLMs to learn from. Thus, successful alignment requires
    an approach that efficiently synchronizes LLM-based driver agents with human driving
    styles, as well as a collection of driving demonstrations across different driving
    styles in natural language for LLMsâ€™ comprehension and learning.
  prefs: []
  type: TYPE_NORMAL
- en: In this paper, we introduce a novel multi-alignment framework that utilizes
    demonstrations and feedback to align driver agents with human driving styles.
    Diverging from reliance on human expert feedback or reflections from LLMs themselves,
    our approach harnesses the few-shot learning capabilities[[31](#bib.bib31)] of
    LLMs to create a Coach Agent that learns from human demonstrations, evaluates
    past driving behaviors, and formulates driving guidelines. All human demonstrations
    are pre-collected, eliminating the need for additional human effort during alignment
    and substantially reducing costs.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, to collect high-quality demonstrations for alignment, we compiled
    a dataset that encompasses driving behaviors from drivers with varied driving
    styles. A real-world driving experiment was conducted, followed by a post-driving
    interview, wherein we gathered and structured human driversâ€™ decision-making data.
    This dataset likely represents the first effort to meticulously dissect human
    driving behaviors and articulate the driving decision-making process in a natural
    language format.
  prefs: []
  type: TYPE_NORMAL
- en: We validate our work through both simulation experiments and human evaluation
    surveys, demonstrating that our multi-aligned framework effectively creates driver
    agents with distinct driving styles that are not only statistically sound but
    also distinctly perceptible to humans.
  prefs: []
  type: TYPE_NORMAL
- en: 'The contributions of this paper are summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: â€¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A multi-alignment framework that can align LLM-based driver agents with human
    driving styles.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: â€¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dataset of human driving behaviors in natural language format.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: â€¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comprehensive validation through both simulation experiments and human evaluations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: II Multi-alignment Framework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3236b93846f5c54550d88b579c0787e7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: The multi-alignment framework'
  prefs: []
  type: TYPE_NORMAL
- en: Fig. [1](#S2.F1 "Figure 1 â€£ II Multi-alignment Framework â€£ Driving Style Alignment
    for LLM-powered Driver Agent") demonstrates the comprehensive structure of the
    multi-alignment framework, consisting of a Driver Agent, a Coach Agent, and demonstrations
    from human drivers. In this section, we first introduce the architecture and basic
    workflow of the Driver Agent. Then we show how to achieve multi-alignment through
    direct demonstration data from human drivers and feedback from the Coach Agent
    with human demonstrations.
  prefs: []
  type: TYPE_NORMAL
- en: II-A Driver Agent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Driver Agent acts as entities interacting with the surrounding driving environment
    and making driving decisions. It maintains an iterable, fixed-capacity short-term
    memory, which stores the most recent memory units, promoting the continuity and
    consistency of decision-making.
  prefs: []
  type: TYPE_NORMAL
- en: 'The workflow begins by capturing the current state and environment information
    for perception, including the speed and direction of the agent vehicle, the speed
    limits and other restrictions of the current road, as well as the status of other
    vehicles and pedestrians nearby. Next, it analyzes the collected information alongside
    its short-term memory to grasp the current situation. Following this analysis,
    along with provided Demonstrations and Guidelines for multi-alignment, the Driver
    Agent deduces the most appropriate driving action at the moment. Here, the Driver
    Agent is prompted to â€™Think Step by Step,â€™ employing a chain-of-thought (CoT)
    reasoning strategy towards the final decision:'
  prefs: []
  type: TYPE_NORMAL
- en: â€œGiven the rather faster speed of the vehicle ahead and inability to change
    lanes, the agent car should match the speed by gentle acceleration.â€
  prefs: []
  type: TYPE_NORMAL
- en: Next, the Driver Agent selects the most matching ones from a set of atomic driving
    operations as the stepâ€™s action and performs. The â€Situation,â€ â€Reasoning,â€ and
    â€Actionâ€ generated are then compiled into a memory unit and incorporated into
    the short-term memory, while the earliest memory unit is popped out. Through the
    consistent repetition of this process, the Driver Agent successfully crafts a
    sequence of fluid and coherent driving maneuvers.
  prefs: []
  type: TYPE_NORMAL
- en: II-B Multi-alignment through Demonstrations and Feedback
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We construct a framework that could multi-align the Driver Agent with human
    driving styles by adopting demonstrations and feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Demonstrations encompass representative decision-making processes of human drivers,
    featuring both cautious and risky driving demonstrations. They are collected and
    then organized into the form of the Driver Agentâ€™s memory units (with more details
    in Section [III](#S3 "III Driving Style Data Collection â€£ Driving Style Alignment
    for LLM-powered Driver Agent")). Demonstrations serve a dual purpose in alignment,
    being utilized by both the Driver Agent and the Coach Agent. For the Driver Agent,
    they serve as few-shot prompts, aiming to guide it towards making driving decisions
    similar in style. And for the Coach Agent, they are provided as â€™Goodâ€™ examples,
    prompting it to make evaluations with driving style preferences, further generating
    guidelines that embody driving styles.
  prefs: []
  type: TYPE_NORMAL
- en: To implement feedback, a Coach Agent was established, outfitted with a Guidelines
    module that compiles driving suggestions gleaned from continuous evaluations.
    It scrutinizes the current short-term memory of the Driver Agent and issues a
    judgment of â€™Goodâ€™ or â€™Badâ€™, along with the reason for this judgement. The criteria
    for evaluation include whether the decisions in the short-memory align with common
    driving sense, conform to the requirements proposed in the Guidelines, and match
    the style of the provided â€™Goodâ€™ examples. Should an evaluation yield a â€™Badâ€™
    rating, the Coach Agent formulates a new guideline addressing the suboptimal driving
    decision. This new guideline is then assimilated into the existing Guidelines
    repository.
  prefs: []
  type: TYPE_NORMAL
- en: III Driving Style Data Collection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: III-A Natural Driving Experiment and Post-driving Interview
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To gather authentic human driving behavior data for alignment, we conducted
    a natural driving experiment with human drivers followed by a post-experiment
    interview. A total of 24 drivers were invited to participate in our data collection
    experiment, covering different genders and age groups. Notably, in order to gather
    data on different driving styles, the participants also included both seasoned
    professional drivers and novice drivers with less driving experience.
  prefs: []
  type: TYPE_NORMAL
- en: To delve deeply into specific driving behaviors, we initially had each driver
    perform an urban road driving task covering 13 driving conditions, with a total
    length of 5.7 kilometers. To faithfully recreate the entire driving process during
    the following post-experiment interview, we set up a roof-mounted 360-degree panoramic
    camera to record the environment around the vehicle during task execution, an
    in-car motion camera to capture the driverâ€™s actions, as well as an eye tracker
    to record changes in the driverâ€™s gaze. Additionally, real-time CAN-Bus data on
    the vehicleâ€™s status were recorded, including speed, the throttle and brake percentage,
    and the turning of the steering wheel.
  prefs: []
  type: TYPE_NORMAL
- en: For safety reasons, drivers were not requested to verbalize their thought processes
    while performing driving tasks. Right after the natural driving experiment, drivers
    would participate in a detailed post-experiment interview, which typically lasted
    for 1.5-2 hours. During the interview, we used the collected videos to recreate
    the task situation just experienced by the driver. For each driving action (e.g.
    accelerating, lane changing or turning), drivers were asked to recall and describe
    the entire decision-making process, from evaluating the surrounding environment
    to executing the corresponding driving action. These interview data will assist
    in determining the driverâ€™s driving style, and also serve as the source of Demonstrations
    in the Multi-alignment Framework.
  prefs: []
  type: TYPE_NORMAL
- en: III-B Driving Style Selection and Data Organization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Having completed driving experiments and post-experiment interviews, our next
    task is to differentiate the driversâ€™ driving styles and organize the think-aloud
    data into demonstrations of different styles.
  prefs: []
  type: TYPE_NORMAL
- en: 'The differentiation of driving styles is based on subjective questionnaire
    results and objective driving records in driving tasks. We distributed a MDSI
    questionnaire[[32](#bib.bib32)] to each driver invited to participate in the experiment.
    The results indicated the presence of four driving styles among the 24 drivers:
    risky, high-velocity, patient, and careful. Notably, the risky style often coincided
    with the high-velocity style, while the patient style typically appeared alongside
    the careful style. Further analysis of the CAN-Bus data during driving tasks revealed
    that 3 drivers exhibited speeds and throttle percentages significantly above the
    average â€” specifically, the average speed of all drivers was 6.40 m/s and average
    throttle percentage was 23.09%, while average speed of these 3 drivers respectively
    reached speeds of 7.73 m/s (20.78% higher than average), 7.50 m/s (17.19% higher
    than average) and 7.41 m/s (15.78% higher than average), and average throttle
    percentages reached 29.09% (25.99% higher than average), 24.42% (5.76% higher
    than average) and 24.37% (5.54% higher than average) â€” aligning with their self-reported
    â€™risky and high-velocityâ€™ driving styles in the questionnaire. Conversely, 2 other
    drivers had lower metrics â€” with speeds of 5.15 m/s (19.53% lower than average)
    and 5.28 m/s (17.50% lower than average) respectively, and throttle percentage
    of 21.00% (9.05% lower than average) and 21.34% (7.58% lower than average) â€” aligning
    with their self-reported â€™patient and carefulâ€™ driving styles in the questionnaire.
    Additionally, a few drivers who reported to have driving styles in the questionnaire
    did not show clear trends in either driving data or interview records.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we identified two basic driving styles: â€™riskyâ€™ and â€™high-velocityâ€™
    were merged into â€™risky,â€™ while â€™patientâ€™ and â€™carefulâ€™ were combined into â€™cautious.â€™
    We reviewed the interview data of drivers with risky driving styles and those
    with cautious driving styles, selecting representative decision-making processes
    that exemplify each driving style. Then, we organized each process according to
    the decision sequence into the format of â€™Situationâ€™, â€™Reasoningâ€™ and â€™Actionâ€™,
    forming the final Demonstrations for alignment with humans.'
  prefs: []
  type: TYPE_NORMAL
- en: IV Experiment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we validated the proposed Multi-alignment Framework by exploring
    the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: â€¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can Driver Agents with different driving styles be constructed using human think-aloud
    data?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: â€¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which alignment method can efficiently achieve human alignment of driving styles?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To this end, we implemented the Multi-alignment Framework on CARLAâ€”a high-fidelity
    traffic simulator. A simulation experiment was carried out under urban driving
    conditions, upon which we further conducted a user experiment to collect human
    evaluations of its performance.
  prefs: []
  type: TYPE_NORMAL
- en: IV-A Conditions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b3b17ff62b998d04a62d63d0fa610805.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Experiment conditions'
  prefs: []
  type: TYPE_NORMAL
- en: 'The experiment adopts an approximate 3 Ã— 3 with-in subject design with two
    main variables: Driving Style [cautiousÂ (C), riskyÂ (R)and not-alignedÂ (N)] and
    Alignment Method [demonstrationsÂ (D), feedbackÂ (F)and multi-alignmentÂ (M)]. Fig.
    [2](#S4.F2 "Figure 2 â€£ IV-A Conditions â€£ IV Experiment â€£ Driving Style Alignment
    for LLM-powered Driver Agent") shows the general design of different conditions.'
  prefs: []
  type: TYPE_NORMAL
- en: In terms of Driving Style, we compared the effects of using cautiousÂ driving
    demonstrations, riskyÂ driving demonstrations, and no demonstrations (i.e., not-aligned).
  prefs: []
  type: TYPE_NORMAL
- en: Alignment Method was organized in an ablation format, with conditions including
    demonstrations, feedback, and multi-alignmentÂ (i.e., the full alignment framework).
    The demonstrationsÂ condition involves Driver Agents provided with demonstrations,
    and the feedbackÂ condition involves Driver Agents without demonstrations and Coach
    Agents that were provided with demonstrations, while in the multi-alignmentÂ condition,
    both Driver Agent and Coach Agent were provided with demonstrations.
  prefs: []
  type: TYPE_NORMAL
- en: IV-B CARLA Simulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: IV-B1 Set-up
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The simulation experiment setup involved a ThundeRobot Zero desktop computer
    as the hardware foundation. The simulation environment was built upon the CARLA
    simulator, specifically, version 0.9.14Â³Â³3[http://carla.org/2022/12/23/release-0.9.14/](http://carla.org/2022/12/23/release-0.9.14/)
    and operated on Python 3.7 with Unreal Engine 4â´â´4[https://docs.unrealengine.com/4.27/en-US/](https://docs.unrealengine.com/4.27/en-US/).
    We use the map Town10, a typical urban driving scene, with both the number of
    other vehicles and pedestrians in the scenario set to 60\. And Audi TT was the
    designated vehicle for all experiments, with fixed starting and continuously,
    randomly generated ending points for its path (After a vehicle is generated at
    a predefined fixed point, a random endpoint is generated. Upon reaching the endpoint,
    another endpoint is randomly generated, and so on.).
  prefs: []
  type: TYPE_NORMAL
- en: We leverage OpenAIâ€™s GPT-4âµâµ5[https://openai.com/gpt-4](https://openai.com/gpt-4)
    APIs for constructing both the Driver Agent and the Coach Agent. However, it takes
    several seconds for GPT to generate a response, which is too long in a driving
    context for making immediate decisions. Therefore, we slowed down CARLAâ€™s simulation
    time based on the required token count by setting a fixed time-step of 0.0008-0.0015
    seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Each simulation process is recorded on video. Additionally, to collect vehicle
    status information during the simulation, we initiated a log-collector thread
    to accumulate log on collisions, speed, throttle percentage, and brake percentage
    from the agent vehicle on a second-by-second basis.
  prefs: []
  type: TYPE_NORMAL
- en: IV-B2 Metrics
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Here, we introduce three metrics to evaluate the driving performance of the
    Driver Agent: collision rate, speed, throttle percentage, and brake percentage.'
  prefs: []
  type: TYPE_NORMAL
- en: â€¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Collision rate: The number of collisions can be obtained from the log, with
    distance traveled being cumulative up to the last collision. The calculating formula
    is $1$2'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: â€¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Speed: The statistical measures for speed include the average speed of the
    agent vehicle during each simulation and the segmented average speed per minute
    (simulator time). All calculations of average speed exclude zero values to minimize
    the impact of the agent vehicle waiting at traffic signals and in traffic jams.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: â€¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Throttle percentage & brake percentage: The statistics for throttle and brake
    percentages are also divided into overall average values and segmented average
    values per minute. Similarly, all calculations exclude data from when the agent
    vehicle is stationary.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: IV-B3 Results
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '![Refer to caption](img/52b42b10ae333ff6242b5f16f4cb1e9c.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Collision rates per meter (with increased incidences of abrupt maneuvers
    by surrounding vehicles and pedestrians).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/47e235384fcae6e8ede37f9bb6721039.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Average throttle percentage (left), brake percentage (middle), and speed
    (right) of the agent vehicle, with all calculations excluding data from when the
    agent vehicle was stationary (the speed limit is km/h).
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3: Simulation experiment results for predefined metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: We conducted approximately 50.3 hours of simulation experiments under various
    conditions, which corresponds to an average of about 6.7 minutes of driving per
    condition for the agent vehicle on the simulation platform. The average distance
    the agent vehicle traveled per condition was approximately 1.5 kilometers. Notably,
    we adjusted the algorithms controlling other vehicles and pedestrians to make
    them more prone to sudden maneuvers (e.g. abrupt lane changes, running red lights).
    These edge cases aim to increase the risk level of the driving environment for
    the agent vehicle, making its driving style more observable.
  prefs: []
  type: TYPE_NORMAL
- en: Fig. [3(a)](#S4.F3.sf1 "In Figure 3 â€£ IV-B3 Results â€£ IV-B CARLA Simulation
    â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered Driver Agent") displays
    the collision rates per meter for the agent vehicle calculated under different
    conditions. Agents aligned with the riskyÂ driving style overall exhibit higher
    collision rates, while those aligned with the cautiousÂ driving style show lower
    collision rates overall. Additionally, when aligned with cautiousÂ driving style,
    the multi-alignmentÂ method displayed the lowest collision rate while the demonstrationsÂ method
    displayed the highest, and when aligned with riskyÂ driving style, the multi-alignmentÂ method
    showed the highest collision rate while the demonstrationsÂ method displayed the
    highest. When not-aligned, the collision rate for the demonstrationsÂ method is
    higher than that for the feedbackÂ method.
  prefs: []
  type: TYPE_NORMAL
- en: Fig. [3(b)](#S4.F3.sf2 "In Figure 3 â€£ IV-B3 Results â€£ IV-B CARLA Simulation
    â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered Driver Agent") presents
    the average throttle percentage, brake percentage, and speed of the agent vehicle
    during the driving process under different conditions, with all calculations excluding
    data from when the agent vehicle was stationary. When using the same alignment
    method, agents aligned with the riskyÂ driving style had the highest average speed,
    highest throttle percentage, and lowest brake percentage, while agents aligned
    with the cautiousÂ driving style had the lowest speed, lowest throttle percentage,
    and highest brake percentage. When aligned with the cautiousÂ driving style, the
    average speed and throttle percentage decrease while the average brake percentage
    increases across the demonstrations, feedback, and multi-alignment, in that order.
    The opposite trend is observed when aligning with the riskyÂ driving style. When
    not-aligned, the average speed and throttle percentage for the demonstrationsÂ method
    are higher than those for the feedbackÂ method, while the average brake percentage
    is lower.
  prefs: []
  type: TYPE_NORMAL
- en: IV-B4 Findings
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Based on the hypothesis that agents with more cautious driving styles are safer,
    agents can exhibit corresponding driving styles by aligning with different driving
    styles. multi-alignmentÂ was the most effective method, displaying the most significant
    differences in collision rates, average throttle, brake, and speed between cautious
    and risky driving styles, while demonstrationsÂ were less effective.
  prefs: []
  type: TYPE_NORMAL
- en: IV-C Human Evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: IV-C1 Procedure
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We designed two survey questionnaires to collect human driversâ€™ evaluations
    of the Driver Agentâ€™s performance, which was presented to participants in the
    questionnaire through video clips of the simulation, with about 30 seconds of
    driving footage captured for each experimental condition.
  prefs: []
  type: TYPE_NORMAL
- en: In Part I of the first questionnaire, we initially collected basic information
    (e.g. age, gender, whether holding a driving license) from participants. A partial
    MDSI self-assessment was also included, with items covering indicators of risky
    and careful driving styles from the MDSI.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Part II, the video clips are divided into four groups:'
  prefs: []
  type: TYPE_NORMAL
- en: â€¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Demonstrations Group: {demonstrationsÂ cautiousÂ (DC), demonstrationsÂ not-alignedÂ (DN),
    demonstrationsÂ riskyÂ (DR)}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: â€¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Feedback Group: {feedbackÂ cautiousÂ (FC), feedbackÂ not-alignedÂ (FN), feedbackÂ riskyÂ (FR),
    demonstrationsÂ not-alignedÂ (DN, serving as baseline in this group)}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: â€¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cautious Group: {demonstrationsÂ cautiousÂ (DC), feedbackÂ cautiousÂ (FC), multi-alignmentÂ cautiousÂ (MC)}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: â€¢
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Risky Group: {demonstrationsÂ riskyÂ (DR), feedbackÂ riskyÂ (FR), multi-alignmentÂ riskyÂ (MR)}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Each group of video clips will appear in a random order, accompanied by a ranking
    question requiring participants to rank the driving styles in the videos according
    to their level of riskiness (a smaller number indicates more risky) and a reason
    question for explaining their rankings.
  prefs: []
  type: TYPE_NORMAL
- en: Parts I of the second questionnaire are identical to the first questionnaire.
    In Part II, participants were instructed to watch all of the eight videos clips,
    which were also organized in a random order, with three scoring questions respectively
    investigated the intelligence level, riskiness level and human-likeness level
    of the agent vehicle (all from 0 to 10) and a reason question attached below each
    clip.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, to filter out carelessly completed questionnaires, we set a minimum
    answering time and included trap questions in the questionnaire, which required
    participants to select a certain option.
  prefs: []
  type: TYPE_NORMAL
- en: IV-C2 Participants
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We recruited over 200 participants through a third-party recruitment channel
    provided by the survey platform, offering a compensation of approximately $2.08
    per valid questionnaire completed. Additionally, our team of five researchers
    also shared our questionnaires on social media platforms, recruiting over 60 participants.
  prefs: []
  type: TYPE_NORMAL
- en: All 270 participants verified in the questionnaire that they possess a driving
    license. Among them, there were 141 male participants, accounting for 52.22%,
    and 129 female participants, accounting for 47.78%, with ages ranging from 19
    to 54 years old.
  prefs: []
  type: TYPE_NORMAL
- en: IV-C3 Data Analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For both questionnaires, we first categorized participantsâ€™ driving styles based
    on the results from Section I. The formula for calculating the driving style score
    is $S_{driving\ style}=\Sigma o_{risky}-\Sigma o_{cautious}$ represents the option
    for each cautious indicator (with two negative indicators within, where options
    are included as negative values). The higher the driving style score, the more
    a participantâ€™s driving style tends towards being risky.
  prefs: []
  type: TYPE_NORMAL
- en: For Part II of the first questionnaire, we calculated the rankings obtained
    by different video clips in the ranking question following each group of video
    clips, as well as the statistical significance between their rankings.
  prefs: []
  type: TYPE_NORMAL
- en: For Part II of the second questionnaire, we separately tallied the results of
    the three scoring questions after each video clip, representing the agent vehicleâ€™s
    intelligence, riskiness, and human-likeness.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we scrutinized all the answers to the reasoning questions in both
    questionnaires, summarizing supports for judging the driving behaviors of the
    agent vehicles.
  prefs: []
  type: TYPE_NORMAL
- en: IV-C4 Results
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '![Refer to caption](img/608a4cefdc2862f11df7c93b2ff524f8.png)'
  prefs: []
  type: TYPE_IMG
- en: '(a) Frequency of riskiness rankings in different groups: demonstrations with
    different driving styles (left), feedback with different driving styles (middle-left),
    cautious driving style under different alignment methods (middle-right), and risky
    driving style under different alignment methods (right). Higher rankings indicate
    higher riskiness.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/476435b8c1d24c118898b6e2512adc4b.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Pearson correlation and significance of scores for agent vehicleâ€™s riskiness
    (R), human-likeness (H), and intelligence (I).
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4: Human evaluation results.'
  prefs: []
  type: TYPE_NORMAL
- en: We distributed two questionnaires for 3 days and received a total of 259 valid
    responses after screening, with 198 for the first questionnaire and 59 for the
    second. The driving style statistics in part I are highly diverse. With an average
    score of 0.61, 34 participants scores below -4 (suggesting a cautious driving
    style), while 37 participants scores over 5 (suggesting a risky driving style),
    indicating good representativeness of our results.
  prefs: []
  type: TYPE_NORMAL
- en: Fig. [4(a)](#S4.F4.sf1 "In Figure 4 â€£ IV-C4 Results â€£ IV-C Human Evaluation
    â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered Driver Agent") shows
    the rankings of riskiness for different video clips in each group from the first
    questionnaire, with higher rankings indicating higher riskiness.
  prefs: []
  type: TYPE_NORMAL
- en: In both the demonstrations and feedback groups, the rankings for DC and FC were
    significantly lower than those for other videos in the same group, indicating
    that they were perceived as the least risky. One participant explained choosing
    DC as the least risky in the Demonstration Group, noting, â€The car ran stably
    without veering left or right.â€ Another participant cited their reasoning for
    deeming FC the least risky in the Feedback Group, stating, â€It waits for the pedestrian
    ahead to pass by.â€
  prefs: []
  type: TYPE_NORMAL
- en: When not-aligned, the riskiness of FN decreases compared to DN, with multiple
    participants noting DNâ€™s â€Decelerate too slowly when approaching a pedestrian
    crossing.â€ However, DN shows no significant difference when compared to either
    DR or FR, because they â€all look very riskyâ€
  prefs: []
  type: TYPE_NORMAL
- en: In the cautious group, the ranking of riskiness goes significantly as DC <math
    id="S4.SS3.SSS4.p5.1.m1.1" class="ltx_Math" alttext="></math> MC, indicating that
    multi-alignmentÂ has the best alignment effect, with demonstrationsÂ being the least
    effective. The majority of participants attributed the rankings to â€Driver x (DC)
    performs lane changes a bit too quickly, whereas driver y (MC) not only waits
    for pedestrians but also yields to other vehicles.â€
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the demonstrationsÂ method also showed the poorest alignment effect
    in the risky group, with MR slightly better than FR but not significant.
  prefs: []
  type: TYPE_NORMAL
- en: Fig.Â [4(b)](#S4.F4.sf2 "In Figure 4 â€£ IV-C4 Results â€£ IV-C Human Evaluation
    â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered Driver Agent") presents
    the results of the correlation analysis among participantsâ€™ scores for riskiness,
    human-likeness, and intelligence for the same video clip in the second questionnaire.
    It can be observed that humans tend to associate higher riskiness with lower intelligence,
    and higher intelligence with greater human-likeness. Interestingly, despite cautious
    driving being safer, humans still tend to associate higher riskiness with greater
    human-likeness. One participant remarked, â€It (MR) is really like an experienced
    driver who is showing off his driving skills.â€
  prefs: []
  type: TYPE_NORMAL
- en: IV-C5 Findings
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The human evaluation results indicated a clear distinction in perceived riskiness
    between different driving styles. Agents aligned with cautious driving were consistently
    rated as less risky, particularly under the multi-alignment condition, which was
    proven to be the most effective for aligning driving styles. Demonstrations alone
    showed the least effectiveness in both cautious and risky conditions. Additionally,
    there is an interesting psychological insight that despite associating cautious
    driving with safety, participants tended to equate higher cautiousness with less
    human-likeness, reflecting a complex perception of human driving behavior.
  prefs: []
  type: TYPE_NORMAL
- en: V CONCLUSIONS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This paper presents a novel multi-alignment framework for aligning LLM-powered
    Driver Agents with human driving styles. Through a comprehensive set of experiments
    and evaluations, we successfully demonstrate that Driver Agents can be tailored
    to exhibit distinct driving stylesâ€”risky and cautiousâ€”by leveraging human driving
    data as chain-of-thought prompts. The frameworkâ€™s effectiveness is validated through
    simulation experiments in the CARLA urban traffic simulator and further corroborated
    by human evaluations.
  prefs: []
  type: TYPE_NORMAL
- en: By illustrating the potential of LLMs in achieving nuanced human-agent alignment,
    this work opens new avenues for research into autonomous driving technologies
    that cater to individual preferences. By encoding the intricacies of human driving
    behaviors in a format accessible to language models, this work paves the way for
    more intuitive and effective human-agent alignment across a broad spectrum of
    applications beyond autonomous driving. Additionally, the insights into human
    perceptions of riskiness and human-likeness in driving styles underscore the complexity
    of aligning autonomous agents with human expectations and behaviors, highlighting
    the importance of further interdisciplinary research in this area.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] C.Â H. Song, J.Â Wu, C.Â Washington, B.Â M. Sadler, W.-L. Chao, and Y.Â Su,
    â€œLlm-planner: Few-shot grounded planning for embodied agents with large language
    models,â€ in *Proceedings of the IEEE/CVF International Conference on Computer
    Vision*, 2023, pp. 2998â€“3009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] J.Â Wei, X.Â Wang, D.Â Schuurmans, M.Â Bosma, F.Â Xia, E.Â Chi, Q.Â V. Le, D.Â Zhou,
    *etÂ al.*, â€œChain-of-thought prompting elicits reasoning in large language models,â€
    *Advances in Neural Information Processing Systems*, vol.Â 35, pp. 24â€‰824â€“24â€‰837,
    2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] X.Â Wang, J.Â Wei, D.Â Schuurmans, Q.Â Le, E.Â Chi, S.Â Narang, A.Â Chowdhery,
    and D.Â Zhou, â€œSelf-consistency improves chain of thought reasoning in language
    models,â€ *arXiv preprint arXiv:2203.11171*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] S.Â Yao, D.Â Yu, J.Â Zhao, I.Â Shafran, T.Â L. Griffiths, Y.Â Cao, and K.Â Narasimhan,
    â€œTree of thoughts: Deliberate problem solving with large language models,â€ *arXiv
    preprint arXiv:2305.10601*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] L.Â Chen, O.Â Sinavski, J.Â HÃ¼nermann, A.Â Karnsund, A.Â J. Willmott, D.Â Birch,
    D.Â Maund, and J.Â Shotton, â€œDriving with llms: Fusing object-level vector modality
    for explainable autonomous driving,â€ *arXiv preprint arXiv:2310.01957*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] Z.Â Xu, Y.Â Zhang, E.Â Xie, Z.Â Zhao, Y.Â Guo, K.Â K. Wong, Z.Â Li, and H.Â Zhao,
    â€œDrivegpt4: Interpretable end-to-end autonomous driving via large language model,â€
    *arXiv preprint arXiv:2310.01412*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] A.Â Hu, L.Â Russell, H.Â Yeo, Z.Â Murez, G.Â Fedoseev, A.Â Kendall, J.Â Shotton,
    and G.Â Corrado, â€œGaia-1: A generative world model for autonomous driving,â€ *arXiv
    preprint arXiv:2309.17080*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] H.Â Shao, Y.Â Hu, L.Â Wang, S.Â L. Waslander, Y.Â Liu, and H.Â Li, â€œLmdrive:
    Closed-loop end-to-end driving with large language models,â€ 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] C.Â Cui, Y.Â Ma, X.Â Cao, W.Â Ye, and Z.Â Wang, â€œDrive as you speak: Enabling
    human-like interaction with large language models in autonomous vehicles,â€ in
    *Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision*,
    2024, pp. 902â€“909.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] L.Â Wen, D.Â Fu, X.Â Li, X.Â Cai, T.Â Ma, P.Â Cai, M.Â Dou, B.Â Shi, L.Â He, and
    Y.Â Qiao, â€œDilu: A knowledge-driven approach to autonomous driving with large language
    models,â€ *arXiv preprint arXiv:2309.16292*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] W.Â Wang, J.Â Xie, C.Â Hu, H.Â Zou, J.Â Fan, W.Â Tong, Y.Â Wen, S.Â Wu, H.Â Deng,
    Z.Â Li, H.Â Tian, L.Â Lu, X.Â Zhu, X.Â Wang, Y.Â Qiao, and J.Â Dai, â€œDrivemlm: Aligning
    multi-modal large language models with behavioral planning states for autonomous
    driving,â€ 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] S.Â Kolekar, J.Â deÂ Winter, and D.Â Abbink, â€œHuman-like driving behaviour
    emerges from a risk-based driver model,â€ *Nature communications*, vol.Â 11, no.Â 1,
    p. 4850, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Y.Â Jin, X.Â Shen, H.Â Peng, X.Â Liu, J.Â Qin, J.Â Li, J.Â Xie, P.Â Gao, G.Â Zhou,
    and J.Â Gong, â€œSurrealdriver: Designing generative driver agent simulation framework
    in urban contexts based on large language model,â€ *arXiv preprint arXiv:2309.13193*,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] S.Â Hecker, D.Â Dai, and L.Â VanÂ Gool, â€œLearning accurate, comfortable and
    human-like driving,â€ *arXiv preprint arXiv:1903.10995*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] A.Â Waytz, J.Â Heafner, and N.Â Epley, â€œThe mind in the machine: Anthropomorphism
    increases trust in an autonomous vehicle,â€ *Journal of experimental social psychology*,
    vol.Â 52, pp. 113â€“117, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] J.Â Mao, Y.Â Qian, H.Â Zhao, and Y.Â Wang, â€œGpt-driver: Learning to drive
    with gpt,â€ *arXiv preprint arXiv:2310.01415*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] L.Â Ouyang, J.Â Wu, X.Â Jiang, D.Â Almeida, C.Â L. Wainwright, P.Â Mishkin,
    C.Â Zhang, S.Â Agarwal, K.Â Slama, A.Â Ray, *etÂ al.*, â€œTraining language models to
    follow instructions with human feedback, 2022,â€ *URL https://arxiv. org/abs/2203.02155*,
    vol.Â 13, p.Â 1, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] D.Â Fu, X.Â Li, L.Â Wen, M.Â Dou, P.Â Cai, B.Â Shi, and Y.Â Qiao, â€œDrive like
    a human: Rethinking autonomous driving with large language models,â€ in *Proceedings
    of the IEEE/CVF Winter Conference on Applications of Computer Vision*, 2024, pp.
    910â€“919.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] A.Â Zhao, D.Â Huang, Q.Â Xu, M.Â Lin, Y.-J. Liu, and G.Â Huang, â€œExpel: Llm
    agents are experiential learners,â€ *arXiv preprint arXiv:2308.10144*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] N.Â Shinn, F.Â Cassano, A.Â Gopinath, K.Â Narasimhan, and S.Â Yao, â€œReflexion:
    Language agents with verbal reinforcement learning,â€ *Advances in Neural Information
    Processing Systems*, vol.Â 36, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] W.Â Yao, S.Â Heinecke, J.Â C. Niebles, Z.Â Liu, Y.Â Feng, L.Â Xue, R.Â Murthy,
    Z.Â Chen, J.Â Zhang, D.Â Arpit, *etÂ al.*, â€œRetroformer: Retrospective large language
    agents with policy gradient optimization,â€ *arXiv preprint arXiv:2308.02151*,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Z.Â Yang, P.Â Li, and Y.Â Liu, â€œFailures pave the way: Enhancing large language
    models through tuning-free rule accumulation,â€ *arXiv preprint arXiv:2310.15746*,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] X.Â Wang, W.Â Zhu, M.Â Saxon, M.Â Steyvers, and W.Â Y. Wang, â€œLarge language
    models are implicitly topic models: Explaining and finding good demonstrations
    for in-context learning,â€ in *Workshop on Efficient Systems for Foundation Models@
    ICML2023*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] H.Â Caesar, V.Â Bankiti, A.Â H. Lang, S.Â Vora, V.Â E. Liong, Q.Â Xu, A.Â Krishnan,
    Y.Â Pan, G.Â Baldan, and O.Â Beijbom, â€œnuscenes: A multimodal dataset for autonomous
    driving,â€ in *Proceedings of the IEEE/CVF conference on computer vision and pattern
    recognition*, 2020, pp. 11â€‰621â€“11â€‰631.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] J.Â Geyer, Y.Â Kassahun, M.Â Mahmudi, X.Â Ricou, R.Â Durgesh, A.Â S. Chung,
    L.Â Hauswald, V.Â H. Pham, M.Â MÃ¼hlegg, S.Â Dorn, *etÂ al.*, â€œA2d2: Audi autonomous
    driving dataset,â€ *arXiv preprint arXiv:2004.06320*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] X.Â Huang, X.Â Cheng, Q.Â Geng, B.Â Cao, D.Â Zhou, P.Â Wang, Y.Â Lin, and R.Â Yang,
    â€œThe apolloscape dataset for autonomous driving,â€ in *Proceedings of the IEEE
    conference on computer vision and pattern recognition workshops*, 2018, pp. 954â€“960.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] W.Â Zhan, L.Â Sun, D.Â Wang, H.Â Shi, A.Â Clausse, M.Â Naumann, J.Â Kummerle,
    H.Â Konigshof, C.Â Stiller, A.Â deÂ LaÂ Fortelle, *etÂ al.*, â€œInteraction dataset: An
    international, adversarial and cooperative motion dataset in interactive driving
    scenarios with semantic maps,â€ *arXiv preprint arXiv:1910.03088*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] T.Â Li, A.Â Alhilal, A.Â Zhang, M.Â A. Hoque, D.Â Chatzopoulos, Z.Â Xiao, Y.Â Li,
    and P.Â Hui, â€œDriving big data: A first look at driving behavior via a large-scale
    private car dataset,â€ in *2019 IEEE 35th International Conference on Data Engineering
    Workshops (ICDEW)*.Â Â Â IEEE, 2019, pp. 61â€“68.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] X.Â Hu, Z.Â Zheng, D.Â Chen, X.Â Zhang, and J.Â Sun, â€œProcessing, assessing,
    and enhancing the waymo autonomous vehicle open dataset for driving behavior research,â€
    *Transportation Research Part C: Emerging Technologies*, vol. 134, p. 103490,
    2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] M.Â Martin, A.Â Roitberg, M.Â Haurilet, M.Â Horne, S.Â ReiÃŸ, M.Â Voit, and R.Â Stiefelhagen,
    â€œDrive&act: A multi-modal dataset for fine-grained driver behavior recognition
    in autonomous vehicles,â€ in *Proceedings of the IEEE/CVF International Conference
    on Computer Vision*, 2019, pp. 2801â€“2810.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] T.Â Brown, B.Â Mann, N.Â Ryder, M.Â Subbiah, J.Â D. Kaplan, P.Â Dhariwal, A.Â Neelakantan,
    P.Â Shyam, G.Â Sastry, A.Â Askell, *etÂ al.*, â€œLanguage models are few-shot learners,â€
    *Advances in neural information processing systems*, vol.Â 33, pp. 1877â€“1901, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] O.Â Taubman-Ben-Ari, M.Â Mikulincer, and O.Â Gillath, â€œThe multidimensional
    driving style inventoryâ€”scale construct and validation,â€ *Accident Analysis &
    Prevention*, vol.Â 36, no.Â 3, pp. 323â€“332, 2004.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
