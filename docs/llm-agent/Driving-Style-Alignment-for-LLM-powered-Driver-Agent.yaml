- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: æœªåˆ†ç±»'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: æœªåˆ†ç±»'
- en: 'date: 2024-09-08 18:50:12'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¥æœŸï¼š2024-09-08 18:50:12
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Driving Style Alignment for LLM-powered Driver Agent
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„é©¾é©¶ä»£ç†çš„é©¾é©¶é£æ ¼å¯¹é½
- en: æ¥æºï¼š[https://ar5iv.labs.arxiv.org/html/2403.11368](https://ar5iv.labs.arxiv.org/html/2403.11368)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¥æºï¼š[https://ar5iv.labs.arxiv.org/html/2403.11368](https://ar5iv.labs.arxiv.org/html/2403.11368)
- en: 'Ruoxuan Yang, Xinyue Zhang, Anais Fernandez-Laaksonen, Xin Ding and Jiangtao
    Gong^(ğŸ–‚) The authors are with the Institute for AI Industry Research, Tsinghua
    University, Beijing, China. Corresponding Email: gongjiangtao@air.tsinghua.edu.cn'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨è‹¥è½©ã€å¼ å¿ƒæ‚¦ã€å®‰å¨œä¼Šæ–¯Â·è´¹å°”å—å¾·æ–¯-æ‹‰å…‹æ¾æ©ã€ä¸é‘«å’Œé¾šæ±Ÿæ¶›^(ğŸ–‚) ä½œè€…éš¶å±äºä¸­å›½åŒ—äº¬æ¸…åå¤§å­¦äººå·¥æ™ºèƒ½äº§ä¸šç ”ç©¶é™¢ã€‚ è”ç³»é‚®ç®±ï¼šgongjiangtao@air.tsinghua.edu.cn
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æ‘˜è¦
- en: Recently, LLM-powered driver agents have demonstrated considerable potential
    in the field of autonomous driving, showcasing human-like reasoning and decision-making
    abilities. However, current research on aligning driver agent behaviors with human
    driving styles remains limited, partly due to the scarcity of high-quality natural
    language data from human driving behaviors. To address this research gap, we propose
    a multi-alignment framework designed to align driver agents with human driving
    styles through demonstrations and feedback. Notably, we construct a natural language
    dataset of human driver behaviors through naturalistic driving experiments and
    post-driving interviews, offering high-quality human demonstrations for LLM alignment.
    The frameworkâ€™s effectiveness is validated through simulation experiments in the
    CARLA urban traffic simulator and further corroborated by human evaluations. Our
    research offers valuable insights into designing driving agents with diverse driving
    styles. The implementation of [the framework](https://github.com/AIR-DISCOVER/Multi-alignment-Drivng-Agent)Â¹Â¹1[https://github.com/AIR-DISCOVER/Multi-alignment-Drivng-Agent](https://github.com/AIR-DISCOVER/Multi-alignment-Drivng-Agent)
    and details of [the dataset](https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset)Â²Â²2[https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset](https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset)
    can be found at the link.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€è¿‘ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„é©¾é©¶ä»£ç†åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸå±•ç°äº†ç›¸å½“å¤§çš„æ½œåŠ›ï¼Œå±•ç¤ºäº†ç±»äººçš„æ¨ç†å’Œå†³ç­–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç›®å‰å…³äºå°†é©¾é©¶ä»£ç†è¡Œä¸ºä¸äººç±»é©¾é©¶é£æ ¼å¯¹é½çš„ç ”ç©¶ä»ç„¶æœ‰é™ï¼Œéƒ¨åˆ†åŸå› æ˜¯ç¼ºä¹æ¥è‡ªäººç±»é©¾é©¶è¡Œä¸ºçš„é«˜è´¨é‡è‡ªç„¶è¯­è¨€æ•°æ®ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç ”ç©¶ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤šå¯¹é½æ¡†æ¶ï¼Œé€šè¿‡æ¼”ç¤ºå’Œåé¦ˆå°†é©¾é©¶ä»£ç†ä¸äººç±»é©¾é©¶é£æ ¼å¯¹é½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬é€šè¿‡è‡ªç„¶é©¾é©¶å®éªŒå’Œé©¾é©¶åè®¿è°ˆæ„å»ºäº†ä¸€ä¸ªäººç±»é©¾é©¶è¡Œä¸ºçš„è‡ªç„¶è¯­è¨€æ•°æ®é›†ï¼Œä¸ºLLMå¯¹é½æä¾›äº†é«˜è´¨é‡çš„äººç±»æ¼”ç¤ºã€‚è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§é€šè¿‡CARLAåŸå¸‚äº¤é€šæ¨¡æ‹Ÿå™¨ä¸­çš„æ¨¡æ‹Ÿå®éªŒè¿›è¡Œäº†éªŒè¯ï¼Œå¹¶é€šè¿‡äººå·¥è¯„ä¼°è¿›ä¸€æ­¥è¯å®ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºè®¾è®¡å…·æœ‰å¤šæ ·é©¾é©¶é£æ ¼çš„é©¾é©¶ä»£ç†æä¾›äº†å®è´µçš„è§è§£ã€‚æ¡†æ¶çš„å®ç°å’Œæ•°æ®é›†çš„è¯¦ç»†ä¿¡æ¯å¯ä»¥åœ¨[è¯¥é“¾æ¥](https://github.com/AIR-DISCOVER/Multi-alignment-Drivng-Agent)å’Œ[è¯¥é“¾æ¥](https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset)æ‰¾åˆ°ã€‚
- en: I INTRODUCTION
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I å¼•è¨€
- en: In the burgeoning field of autonomous driving (AV), driver agents powered by
    Large Language Models (LLMs) are demonstrating remarkable promise due to their
    exceptional planning[[1](#bib.bib1)] and reasoning[[2](#bib.bib2), [3](#bib.bib3),
    [4](#bib.bib4)] capabilities. Researchers have delved into the development of
    intricately designed driver agents that could perceive environmental stimuli[[5](#bib.bib5),
    [6](#bib.bib6), [7](#bib.bib7)], comprehend the situation[[8](#bib.bib8)], fetch
    their memories[[9](#bib.bib9), [10](#bib.bib10)] and deduce subsequent driving
    actions[[11](#bib.bib11)] that mirrors human decision-making. Such human-like
    AVs show promise in navigating a diverse range of driving scenariosÂ [[12](#bib.bib12),
    [13](#bib.bib13)], enabling better anticipation of AV behavior by other road usersÂ [[14](#bib.bib14)],
    while also enhancing human trust in these systemsÂ [[15](#bib.bib15)].
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿…é€Ÿå‘å±•çš„è‡ªåŠ¨é©¾é©¶ï¼ˆAVï¼‰é¢†åŸŸï¼Œç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é©±åŠ¨çš„é©¾é©¶ä»£ç†æ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ½œåŠ›ï¼Œå¾—ç›Šäºå…¶å“è¶Šçš„è§„åˆ’[[1](#bib.bib1)]å’Œæ¨ç†[[2](#bib.bib2),
    [3](#bib.bib3), [4](#bib.bib4)]èƒ½åŠ›ã€‚ ç ”ç©¶äººå‘˜å·²ç»æ·±å…¥ç ”ç©¶äº†ç²¾å¿ƒè®¾è®¡çš„é©¾é©¶ä»£ç†ï¼Œè¿™äº›ä»£ç†èƒ½å¤Ÿæ„ŸçŸ¥ç¯å¢ƒåˆºæ¿€[[5](#bib.bib5),
    [6](#bib.bib6), [7](#bib.bib7)]ï¼Œç†è§£æƒ…å†µ[[8](#bib.bib8)]ï¼Œæå–è®°å¿†[[9](#bib.bib9), [10](#bib.bib10)]å¹¶æ¨æ–­åç»­é©¾é©¶è¡Œä¸º[[11](#bib.bib11)]ï¼Œè¿™ç±»ä¼¼äºäººç±»çš„å†³ç­–è¿‡ç¨‹ã€‚
    è¿™äº›ç±»äººåŒ–çš„AVåœ¨åº”å¯¹å„ç§é©¾é©¶åœºæ™¯æ–¹é¢å±•ç°å‡ºæ½œåŠ›[[12](#bib.bib12), [13](#bib.bib13)]ï¼Œä½¿å…¶ä»–é“è·¯ä½¿ç”¨è€…èƒ½å¤Ÿæ›´å¥½åœ°é¢„æµ‹AVè¡Œä¸º[[14](#bib.bib14)]ï¼ŒåŒæ—¶å¢å¼ºäº†äººç±»å¯¹è¿™äº›ç³»ç»Ÿçš„ä¿¡ä»»[[15](#bib.bib15)]ã€‚
- en: However, aligning these driver agents with human driving styles to imbue them
    with more human-like and personalized characteristics remains unexplored. Prevailing
    strategies for aligning LLM-based agents with humans, such as fine-tuning[[5](#bib.bib5),
    [6](#bib.bib6), [16](#bib.bib16)] and the integration of expert feedback[[17](#bib.bib17),
    [18](#bib.bib18)], are often hindered by their high costs. Recently, some studies
    have leveraged AI to generate feedback or reflections[[19](#bib.bib19), [20](#bib.bib20),
    [21](#bib.bib21), [22](#bib.bib22)], yet they fall short in aligning such reflections
    with human perspectives. On the other hand, despite researches focusing on employing
    AI to generate few-shot demonstrations[[1](#bib.bib1), [23](#bib.bib23)] for LLMs,
    another challenge in enhancing agent-human alignment lies in the lack of high-quality
    human behavior data in a form accessible to LLMs, making it difficult for agents
    to learn from human demonstrations. Existing datasets for autonomous driving learning
    either provide only environment data for perception tasks[[24](#bib.bib24), [25](#bib.bib25),
    [26](#bib.bib26)] rather than driving behaviors, or present driving behaviors
    in non-linguistic modalities (e.g. trajectories in maps[[27](#bib.bib27)], Controller
    Area Network Bus (CAN-Bus) data[[28](#bib.bib28), [29](#bib.bib29)], in-car videos[[30](#bib.bib30)])
    that are indirect for LLMs to learn from. Thus, successful alignment requires
    an approach that efficiently synchronizes LLM-based driver agents with human driving
    styles, as well as a collection of driving demonstrations across different driving
    styles in natural language for LLMsâ€™ comprehension and learning.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå°†è¿™äº›é©±åŠ¨ä»£ç†ä¸äººç±»é©¾é©¶é£æ ¼å¯¹é½ï¼Œä»¥èµ‹äºˆå…¶æ›´å…·äººæ€§åŒ–å’Œä¸ªæ€§åŒ–çš„ç‰¹å¾ä»ç„¶æœªè¢«æ¢ç´¢ã€‚ç°è¡Œçš„å°†åŸºäºLLMçš„ä»£ç†ä¸äººç±»å¯¹é½çš„ç­–ç•¥ï¼Œå¦‚å¾®è°ƒ[[5](#bib.bib5),
    [6](#bib.bib6), [16](#bib.bib16)]å’Œä¸“å®¶åé¦ˆçš„æ•´åˆ[[17](#bib.bib17), [18](#bib.bib18)]ï¼Œé€šå¸¸å› å…¶é«˜æˆæœ¬è€Œå—åˆ°é˜»ç¢ã€‚æœ€è¿‘ï¼Œä¸€äº›ç ”ç©¶åˆ©ç”¨AIç”Ÿæˆåé¦ˆæˆ–åæ€[[19](#bib.bib19),
    [20](#bib.bib20), [21](#bib.bib21), [22](#bib.bib22)]ï¼Œä½†åœ¨å°†è¿™äº›åæ€ä¸äººç±»è§†è§’å¯¹é½æ–¹é¢ä»æ˜¾ä¸è¶³ã€‚å¦ä¸€æ–¹é¢ï¼Œå°½ç®¡ç ”ç©¶é›†ä¸­åœ¨ä½¿ç”¨AIç”Ÿæˆå°‘é‡ç¤ºèŒƒ[[1](#bib.bib1),
    [23](#bib.bib23)]ä»¥ç”¨äºLLMsï¼Œå¢å¼ºä»£ç†ä¸äººç±»å¯¹é½çš„å¦ä¸€ä¸ªæŒ‘æˆ˜åœ¨äºç¼ºä¹ä»¥LLMså¯è®¿é—®çš„å½¢å¼æä¾›çš„é«˜è´¨é‡äººç±»è¡Œä¸ºæ•°æ®ï¼Œè¿™ä½¿å¾—ä»£ç†å¾ˆéš¾ä»äººç±»ç¤ºèŒƒä¸­å­¦ä¹ ã€‚ç°æœ‰çš„è‡ªåŠ¨é©¾é©¶å­¦ä¹ æ•°æ®é›†è¦ä¹ˆä»…æä¾›æ„ŸçŸ¥ä»»åŠ¡çš„ç¯å¢ƒæ•°æ®[[24](#bib.bib24),
    [25](#bib.bib25), [26](#bib.bib26)]ï¼Œè€Œéé©¾é©¶è¡Œä¸ºï¼Œè¦ä¹ˆä»¥éè¯­è¨€æ–¹å¼å‘ˆç°é©¾é©¶è¡Œä¸ºï¼ˆä¾‹å¦‚åœ°å›¾ä¸­çš„è½¨è¿¹[[27](#bib.bib27)]ï¼Œæ§åˆ¶å™¨å±€åŸŸç½‘æ€»çº¿ï¼ˆCAN-Busï¼‰æ•°æ®[[28](#bib.bib28),
    [29](#bib.bib29)]ï¼Œè½¦å†…è§†é¢‘[[30](#bib.bib30)]ï¼‰ï¼Œè¿™äº›éƒ½å¯¹LLMsçš„å­¦ä¹ é—´æ¥ã€‚å› æ­¤ï¼ŒæˆåŠŸçš„å¯¹é½éœ€è¦ä¸€ç§æ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å°†åŸºäºLLMçš„é©±åŠ¨ä»£ç†ä¸äººç±»é©¾é©¶é£æ ¼åŒæ­¥ï¼Œå¹¶æ”¶é›†ä¸åŒé©¾é©¶é£æ ¼çš„è‡ªç„¶è¯­è¨€é©¾é©¶ç¤ºèŒƒï¼Œä»¥ä¾¿LLMsç†è§£å’Œå­¦ä¹ ã€‚
- en: In this paper, we introduce a novel multi-alignment framework that utilizes
    demonstrations and feedback to align driver agents with human driving styles.
    Diverging from reliance on human expert feedback or reflections from LLMs themselves,
    our approach harnesses the few-shot learning capabilities[[31](#bib.bib31)] of
    LLMs to create a Coach Agent that learns from human demonstrations, evaluates
    past driving behaviors, and formulates driving guidelines. All human demonstrations
    are pre-collected, eliminating the need for additional human effort during alignment
    and substantially reducing costs.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§æ–°é¢–çš„å¤šé‡å¯¹é½æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ç¤ºèŒƒå’Œåé¦ˆå°†é©±åŠ¨ä»£ç†ä¸äººç±»é©¾é©¶é£æ ¼å¯¹é½ã€‚ä¸ä¾èµ–äººç±»ä¸“å®¶åé¦ˆæˆ–LLMsè‡ªèº«åæ€ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨LLMsçš„å°‘é‡å­¦ä¹ èƒ½åŠ›[[31](#bib.bib31)]åˆ›å»ºä¸€ä¸ªæ•™ç»ƒä»£ç†ï¼Œè¯¥ä»£ç†ä»äººç±»ç¤ºèŒƒä¸­å­¦ä¹ ï¼Œè¯„ä¼°è¿‡å»çš„é©¾é©¶è¡Œä¸ºï¼Œå¹¶åˆ¶å®šé©¾é©¶æŒ‡å—ã€‚æ‰€æœ‰äººç±»ç¤ºèŒƒå‡ä¸ºé¢„å…ˆæ”¶é›†çš„ï¼Œæ¶ˆé™¤äº†å¯¹é½è¿‡ç¨‹ä¸­é¢å¤–çš„äººåŠ›éœ€æ±‚ï¼Œå¤§å¹…é™ä½äº†æˆæœ¬ã€‚
- en: Moreover, to collect high-quality demonstrations for alignment, we compiled
    a dataset that encompasses driving behaviors from drivers with varied driving
    styles. A real-world driving experiment was conducted, followed by a post-driving
    interview, wherein we gathered and structured human driversâ€™ decision-making data.
    This dataset likely represents the first effort to meticulously dissect human
    driving behaviors and articulate the driving decision-making process in a natural
    language format.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œä¸ºäº†æ”¶é›†ç”¨äºå¯¹é½çš„é«˜è´¨é‡ç¤ºèŒƒï¼Œæˆ‘ä»¬ç¼–åˆ¶äº†ä¸€ä¸ªæ¶µç›–å„ç§é©¾é©¶é£æ ¼é©¾é©¶è¡Œä¸ºçš„æ•°æ®é›†ã€‚è¿›è¡Œäº†ä¸€é¡¹ç°å®ä¸–ç•Œçš„é©¾é©¶å®éªŒï¼Œéšåè¿›è¡Œäº†ä¸€æ¬¡é©¾é©¶åçš„è®¿è°ˆï¼Œåœ¨æ­¤è¿‡ç¨‹ä¸­æˆ‘ä»¬æ”¶é›†å¹¶æ•´ç†äº†äººç±»é©¾é©¶è€…çš„å†³ç­–æ•°æ®ã€‚è¿™ä¸ªæ•°æ®é›†å¯èƒ½ä»£è¡¨äº†é¦–æ¬¡ç»†è‡´å‰–æäººç±»é©¾é©¶è¡Œä¸ºå¹¶ä»¥è‡ªç„¶è¯­è¨€æ ¼å¼é˜è¿°é©¾é©¶å†³ç­–è¿‡ç¨‹çš„åŠªåŠ›ã€‚
- en: We validate our work through both simulation experiments and human evaluation
    surveys, demonstrating that our multi-aligned framework effectively creates driver
    agents with distinct driving styles that are not only statistically sound but
    also distinctly perceptible to humans.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡æ¨¡æ‹Ÿå®éªŒå’Œäººå·¥è¯„ä¼°è°ƒæŸ¥éªŒè¯äº†æˆ‘ä»¬çš„å·¥ä½œï¼Œè¯æ˜æˆ‘ä»¬çš„å¤šé‡å¯¹é½æ¡†æ¶æœ‰æ•ˆåœ°åˆ›å»ºäº†å…·æœ‰æ˜æ˜¾é©¾é©¶é£æ ¼çš„é©¾é©¶ä»£ç†ï¼Œè¿™äº›é£æ ¼ä¸ä»…åœ¨ç»Ÿè®¡ä¸Šåˆç†ï¼Œè€Œä¸”å¯¹äººç±»æ¥è¯´ä¹Ÿååˆ†æ˜æ˜¾ã€‚
- en: 'The contributions of this paper are summarized as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡çš„è´¡çŒ®æ€»ç»“å¦‚ä¸‹ï¼š
- en: â€¢
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: A multi-alignment framework that can align LLM-based driver agents with human
    driving styles.
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå¯ä»¥å°†åŸºäºLLMçš„é©¾é©¶ä»£ç†ä¸äººç±»é©¾é©¶é£æ ¼å¯¹é½çš„å¤šé‡å¯¹é½æ¡†æ¶ã€‚
- en: â€¢
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: A dataset of human driving behaviors in natural language format.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¸€ä»½ä»¥è‡ªç„¶è¯­è¨€æ ¼å¼è®°å½•çš„äººç±»é©¾é©¶è¡Œä¸ºæ•°æ®é›†ã€‚
- en: â€¢
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Comprehensive validation through both simulation experiments and human evaluations.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é€šè¿‡æ¨¡æ‹Ÿå®éªŒå’Œäººå·¥è¯„ä¼°è¿›è¡Œå…¨é¢éªŒè¯ã€‚
- en: II Multi-alignment Framework
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II å¤šé‡å¯¹é½æ¡†æ¶
- en: '![Refer to caption](img/3236b93846f5c54550d88b579c0787e7.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§å›¾ä¾‹](img/3236b93846f5c54550d88b579c0787e7.png)'
- en: 'Figure 1: The multi-alignment framework'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 1ï¼šå¤šé‡å¯¹é½æ¡†æ¶
- en: Fig. [1](#S2.F1 "Figure 1 â€£ II Multi-alignment Framework â€£ Driving Style Alignment
    for LLM-powered Driver Agent") demonstrates the comprehensive structure of the
    multi-alignment framework, consisting of a Driver Agent, a Coach Agent, and demonstrations
    from human drivers. In this section, we first introduce the architecture and basic
    workflow of the Driver Agent. Then we show how to achieve multi-alignment through
    direct demonstration data from human drivers and feedback from the Coach Agent
    with human demonstrations.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ [1](#S2.F1 "Figure 1 â€£ II Multi-alignment Framework â€£ Driving Style Alignment
    for LLM-powered Driver Agent") å±•ç¤ºäº†å¤šé‡å¯¹é½æ¡†æ¶çš„å…¨é¢ç»“æ„ï¼ŒåŒ…æ‹¬ä¸€ä¸ªé©¾é©¶ä»£ç†ã€ä¸€ä¸ªæ•™ç»ƒä»£ç†å’Œæ¥è‡ªäººç±»é©¾é©¶å‘˜çš„ç¤ºèŒƒã€‚åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬é¦–å…ˆä»‹ç»é©¾é©¶ä»£ç†çš„æ¶æ„å’ŒåŸºæœ¬å·¥ä½œæµç¨‹ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•é€šè¿‡æ¥è‡ªäººç±»é©¾é©¶å‘˜çš„ç›´æ¥ç¤ºèŒƒæ•°æ®å’Œæ•™ç»ƒä»£ç†çš„åé¦ˆå®ç°å¤šé‡å¯¹é½ã€‚
- en: II-A Driver Agent
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A é©¾é©¶ä»£ç†
- en: The Driver Agent acts as entities interacting with the surrounding driving environment
    and making driving decisions. It maintains an iterable, fixed-capacity short-term
    memory, which stores the most recent memory units, promoting the continuity and
    consistency of decision-making.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: é©¾é©¶ä»£ç†ä½œä¸ºä¸å‘¨å›´é©¾é©¶ç¯å¢ƒäº¤äº’å¹¶åšå‡ºé©¾é©¶å†³ç­–çš„å®ä½“ã€‚å®ƒç»´æŒä¸€ä¸ªå¯è¿­ä»£çš„å›ºå®šå®¹é‡çŸ­æœŸè®°å¿†ï¼Œå­˜å‚¨æœ€æ–°çš„è®°å¿†å•å…ƒï¼Œä¿ƒè¿›å†³ç­–çš„è¿ç»­æ€§å’Œä¸€è‡´æ€§ã€‚
- en: 'The workflow begins by capturing the current state and environment information
    for perception, including the speed and direction of the agent vehicle, the speed
    limits and other restrictions of the current road, as well as the status of other
    vehicles and pedestrians nearby. Next, it analyzes the collected information alongside
    its short-term memory to grasp the current situation. Following this analysis,
    along with provided Demonstrations and Guidelines for multi-alignment, the Driver
    Agent deduces the most appropriate driving action at the moment. Here, the Driver
    Agent is prompted to â€™Think Step by Step,â€™ employing a chain-of-thought (CoT)
    reasoning strategy towards the final decision:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å·¥ä½œæµç¨‹å§‹äºæ•æ‰å½“å‰çŠ¶æ€å’Œç¯å¢ƒä¿¡æ¯ä»¥è¿›è¡Œæ„ŸçŸ¥ï¼ŒåŒ…æ‹¬ä»£ç†è½¦è¾†çš„é€Ÿåº¦å’Œæ–¹å‘ã€å½“å‰é“è·¯çš„é™é€Ÿå’Œå…¶ä»–é™åˆ¶ï¼Œä»¥åŠé™„è¿‘å…¶ä»–è½¦è¾†å’Œè¡Œäººçš„çŠ¶æ€ã€‚æ¥ä¸‹æ¥ï¼Œå®ƒåˆ†ææ”¶é›†åˆ°çš„ä¿¡æ¯ä»¥åŠå…¶çŸ­æœŸè®°å¿†ï¼Œä»¥æŠŠæ¡å½“å‰æƒ…å†µã€‚åœ¨è¿™ä¸€åˆ†æä¹‹åï¼Œç»“åˆæä¾›çš„ç¤ºèŒƒå’Œå¤šé‡å¯¹é½æŒ‡å—ï¼Œé©¾é©¶ä»£ç†æ¨æ–­å‡ºæ­¤æ—¶æœ€åˆé€‚çš„é©¾é©¶åŠ¨ä½œã€‚åœ¨è¿™é‡Œï¼Œé©¾é©¶ä»£ç†è¢«æç¤ºâ€œé€æ­¥æ€è€ƒâ€ï¼Œé‡‡ç”¨é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ¨ç†ç­–ç•¥æ¥åšå‡ºæœ€ç»ˆå†³ç­–ï¼š
- en: â€œGiven the rather faster speed of the vehicle ahead and inability to change
    lanes, the agent car should match the speed by gentle acceleration.â€
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: â€œé‰´äºå‰æ–¹è½¦è¾†é€Ÿåº¦è¾ƒå¿«ä¸”æ— æ³•å˜é“ï¼Œä»£ç†è½¦åº”é€šè¿‡è½»å¾®åŠ é€Ÿæ¥åŒ¹é…é€Ÿåº¦ã€‚â€
- en: Next, the Driver Agent selects the most matching ones from a set of atomic driving
    operations as the stepâ€™s action and performs. The â€Situation,â€ â€Reasoning,â€ and
    â€Actionâ€ generated are then compiled into a memory unit and incorporated into
    the short-term memory, while the earliest memory unit is popped out. Through the
    consistent repetition of this process, the Driver Agent successfully crafts a
    sequence of fluid and coherent driving maneuvers.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œé©¾é©¶ä»£ç†ä»ä¸€ç»„åŸå­é©¾é©¶æ“ä½œä¸­é€‰æ‹©æœ€åŒ¹é…çš„æ“ä½œä½œä¸ºæ­¥éª¤åŠ¨ä½œå¹¶æ‰§è¡Œã€‚ç”Ÿæˆçš„â€œæƒ…å¢ƒâ€ã€â€œæ¨ç†â€å’Œâ€œè¡ŒåŠ¨â€è¢«ç¼–å…¥è®°å¿†å•å…ƒå¹¶çº³å…¥çŸ­æœŸè®°å¿†ï¼ŒåŒæ—¶æœ€æ—©çš„è®°å¿†å•å…ƒè¢«å¼¹å‡ºã€‚é€šè¿‡ä¸€è‡´é‡å¤è¿™ä¸€è¿‡ç¨‹ï¼Œé©¾é©¶ä»£ç†æˆåŠŸåœ°åˆ¶å®šå‡ºä¸€ç³»åˆ—æµç•…ä¸”è¿è´¯çš„é©¾é©¶åŠ¨ä½œã€‚
- en: II-B Multi-alignment through Demonstrations and Feedback
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B é€šè¿‡ç¤ºèŒƒå’Œåé¦ˆå®ç°å¤šé‡å¯¹é½
- en: We construct a framework that could multi-align the Driver Agent with human
    driving styles by adopting demonstrations and feedback.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ¡†æ¶ï¼Œé€šè¿‡é‡‡ç”¨æ¼”ç¤ºå’Œåé¦ˆï¼Œå°†é©¾é©¶å‘˜ä»£ç†ä¸äººç±»é©¾é©¶é£æ ¼è¿›è¡Œå¤šé‡å¯¹é½ã€‚
- en: Demonstrations encompass representative decision-making processes of human drivers,
    featuring both cautious and risky driving demonstrations. They are collected and
    then organized into the form of the Driver Agentâ€™s memory units (with more details
    in Section [III](#S3 "III Driving Style Data Collection â€£ Driving Style Alignment
    for LLM-powered Driver Agent")). Demonstrations serve a dual purpose in alignment,
    being utilized by both the Driver Agent and the Coach Agent. For the Driver Agent,
    they serve as few-shot prompts, aiming to guide it towards making driving decisions
    similar in style. And for the Coach Agent, they are provided as â€™Goodâ€™ examples,
    prompting it to make evaluations with driving style preferences, further generating
    guidelines that embody driving styles.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æ¼”ç¤ºæ¶µç›–äº†äººç±»é©¾é©¶å‘˜çš„ä»£è¡¨æ€§å†³ç­–è¿‡ç¨‹ï¼ŒåŒ…æ‹¬è°¨æ…å’Œå†’é™©çš„é©¾é©¶ç¤ºèŒƒã€‚è¿™äº›ç¤ºèŒƒè¢«æ”¶é›†å¹¶æ•´ç†æˆé©¾é©¶å‘˜ä»£ç†çš„è®°å¿†å•å…ƒï¼ˆæ›´å¤šç»†èŠ‚è§ç¬¬[III](#S3 "III é©¾é©¶é£æ ¼æ•°æ®æ”¶é›†
    â€£ é©¾é©¶é£æ ¼å¯¹é½")èŠ‚ï¼‰ã€‚æ¼”ç¤ºåœ¨å¯¹é½ä¸­å‘æŒ¥äº†åŒé‡ä½œç”¨ï¼Œæ—¢ä¾›é©¾é©¶å‘˜ä»£ç†ä½¿ç”¨ï¼Œä¹Ÿä¾›æ•™ç»ƒä»£ç†ä½¿ç”¨ã€‚å¯¹äºé©¾é©¶å‘˜ä»£ç†ï¼Œå®ƒä»¬ä½œä¸ºå°‘é‡ç¤ºä¾‹æç¤ºï¼Œæ—¨åœ¨å¼•å¯¼å…¶åšå‡ºé£æ ¼ç›¸ä¼¼çš„é©¾é©¶å†³ç­–ã€‚è€Œå¯¹äºæ•™ç»ƒä»£ç†ï¼Œå®ƒä»¬ä½œä¸ºâ€˜å¥½â€™ç¤ºä¾‹ï¼Œä¿ƒä½¿å…¶è¿›è¡Œå¸¦æœ‰é©¾é©¶é£æ ¼åå¥½çš„è¯„ä¼°ï¼Œè¿›ä¸€æ­¥ç”Ÿæˆä½“ç°é©¾é©¶é£æ ¼çš„æŒ‡å¯¼æ–¹é’ˆã€‚
- en: To implement feedback, a Coach Agent was established, outfitted with a Guidelines
    module that compiles driving suggestions gleaned from continuous evaluations.
    It scrutinizes the current short-term memory of the Driver Agent and issues a
    judgment of â€™Goodâ€™ or â€™Badâ€™, along with the reason for this judgement. The criteria
    for evaluation include whether the decisions in the short-memory align with common
    driving sense, conform to the requirements proposed in the Guidelines, and match
    the style of the provided â€™Goodâ€™ examples. Should an evaluation yield a â€™Badâ€™
    rating, the Coach Agent formulates a new guideline addressing the suboptimal driving
    decision. This new guideline is then assimilated into the existing Guidelines
    repository.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å®æ–½åé¦ˆï¼Œå»ºç«‹äº†ä¸€ä¸ªæ•™ç»ƒä»£ç†ï¼Œå¹¶é…å¤‡äº†ä¸€ä¸ªæ±‡æ€»äº†æŒç»­è¯„ä¼°æ‰€è·å¾—é©¾é©¶å»ºè®®çš„æŒ‡å¯¼æ¨¡å—ã€‚å®ƒå®¡æŸ¥é©¾é©¶å‘˜ä»£ç†å½“å‰çš„çŸ­æœŸè®°å¿†ï¼Œå¹¶ç»™å‡ºâ€˜å¥½â€™æˆ–â€˜å·®â€™çš„åˆ¤æ–­ï¼Œä»¥åŠè¿™ä¸€åˆ¤æ–­çš„ç†ç”±ã€‚è¯„ä¼°æ ‡å‡†åŒ…æ‹¬çŸ­æœŸè®°å¿†ä¸­çš„å†³ç­–æ˜¯å¦ç¬¦åˆå¸¸è§„é©¾é©¶å¸¸è¯†ã€æ˜¯å¦ç¬¦åˆæŒ‡å¯¼æ¨¡å—ä¸­çš„è¦æ±‚ï¼Œå¹¶ä¸”æ˜¯å¦ä¸æä¾›çš„â€˜å¥½â€™ç¤ºä¾‹çš„é£æ ¼åŒ¹é…ã€‚å¦‚æœè¯„ä¼°ç»“æœä¸ºâ€˜å·®â€™ï¼Œæ•™ç»ƒä»£ç†ä¼šåˆ¶å®šä¸€ä¸ªæ–°çš„æŒ‡å¯¼æ–¹é’ˆï¼Œè§£å†³ä¸ä½³çš„é©¾é©¶å†³ç­–ã€‚è¿™ä¸ªæ–°çš„æŒ‡å¯¼æ–¹é’ˆä¼šè¢«çº³å…¥ç°æœ‰çš„æŒ‡å¯¼æ–¹é’ˆåº“ä¸­ã€‚
- en: III Driving Style Data Collection
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III é©¾é©¶é£æ ¼æ•°æ®æ”¶é›†
- en: III-A Natural Driving Experiment and Post-driving Interview
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A è‡ªç„¶é©¾é©¶å®éªŒä¸åé©¾é©¶é‡‡è®¿
- en: To gather authentic human driving behavior data for alignment, we conducted
    a natural driving experiment with human drivers followed by a post-experiment
    interview. A total of 24 drivers were invited to participate in our data collection
    experiment, covering different genders and age groups. Notably, in order to gather
    data on different driving styles, the participants also included both seasoned
    professional drivers and novice drivers with less driving experience.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ”¶é›†çœŸå®çš„äººç±»é©¾é©¶è¡Œä¸ºæ•°æ®è¿›è¡Œå¯¹é½ï¼Œæˆ‘ä»¬è¿›è¡Œäº†è‡ªç„¶é©¾é©¶å®éªŒï¼Œå¹¶åœ¨å®éªŒåè¿›è¡Œäº†é‡‡è®¿ã€‚å…±æœ‰24åé©¾é©¶å‘˜è¢«é‚€è¯·å‚ä¸æˆ‘ä»¬çš„æ•°æ®æ”¶é›†å®éªŒï¼Œæ¶µç›–ä¸åŒçš„æ€§åˆ«å’Œå¹´é¾„ç»„ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¸ºäº†æ”¶é›†ä¸åŒçš„é©¾é©¶é£æ ¼æ•°æ®ï¼Œå‚ä¸è€…ä¸­è¿˜åŒ…æ‹¬äº†ç»éªŒä¸°å¯Œçš„èŒä¸šå¸æœºå’Œç»éªŒè¾ƒå°‘çš„æ–°æ‰‹å¸æœºã€‚
- en: To delve deeply into specific driving behaviors, we initially had each driver
    perform an urban road driving task covering 13 driving conditions, with a total
    length of 5.7 kilometers. To faithfully recreate the entire driving process during
    the following post-experiment interview, we set up a roof-mounted 360-degree panoramic
    camera to record the environment around the vehicle during task execution, an
    in-car motion camera to capture the driverâ€™s actions, as well as an eye tracker
    to record changes in the driverâ€™s gaze. Additionally, real-time CAN-Bus data on
    the vehicleâ€™s status were recorded, including speed, the throttle and brake percentage,
    and the turning of the steering wheel.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†*æ·±å…¥æ¢è®¨*ç‰¹å®šçš„é©¾é©¶è¡Œä¸ºï¼Œæˆ‘ä»¬é¦–å…ˆè®©æ¯ä½é©¾é©¶å‘˜å®Œæˆä¸€ä¸ªè¦†ç›–13ç§é©¾é©¶æ¡ä»¶çš„åŸå¸‚é“è·¯é©¾é©¶ä»»åŠ¡ï¼Œæ€»é•¿åº¦ä¸º5.7å…¬é‡Œã€‚ä¸ºäº†å¿ å®åœ°é‡ç°æ•´ä¸ªé©¾é©¶è¿‡ç¨‹ï¼Œåœ¨éšåçš„å®éªŒåé‡‡è®¿ä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº†ä¸€ä¸ªè½¦é¡¶å®‰è£…çš„360åº¦å…¨æ™¯æ‘„åƒå¤´è®°å½•è½¦è¾†å‘¨å›´çš„ç¯å¢ƒï¼Œä¸€ä¸ªè½¦å†…è¿åŠ¨æ‘„åƒå¤´æ•æ‰é©¾é©¶å‘˜çš„åŠ¨ä½œï¼Œä»¥åŠä¸€ä¸ªçœ¼åŠ¨ä»ªè®°å½•é©¾é©¶å‘˜è§†çº¿çš„å˜åŒ–ã€‚æ­¤å¤–ï¼Œå®æ—¶è®°å½•äº†è½¦è¾†çŠ¶æ€çš„CAN-Busæ•°æ®ï¼ŒåŒ…æ‹¬é€Ÿåº¦ã€æ²¹é—¨å’Œåˆ¹è½¦çš„ç™¾åˆ†æ¯”ä»¥åŠæ–¹å‘ç›˜çš„è½¬åŠ¨æƒ…å†µã€‚
- en: For safety reasons, drivers were not requested to verbalize their thought processes
    while performing driving tasks. Right after the natural driving experiment, drivers
    would participate in a detailed post-experiment interview, which typically lasted
    for 1.5-2 hours. During the interview, we used the collected videos to recreate
    the task situation just experienced by the driver. For each driving action (e.g.
    accelerating, lane changing or turning), drivers were asked to recall and describe
    the entire decision-making process, from evaluating the surrounding environment
    to executing the corresponding driving action. These interview data will assist
    in determining the driverâ€™s driving style, and also serve as the source of Demonstrations
    in the Multi-alignment Framework.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ºäºå®‰å…¨è€ƒè™‘ï¼Œé©¾é©¶å‘˜åœ¨è¿›è¡Œé©¾é©¶ä»»åŠ¡æ—¶ä¸è¦æ±‚å£å¤´è¡¨è¾¾å…¶æ€ç»´è¿‡ç¨‹ã€‚è‡ªç„¶é©¾é©¶å®éªŒç»“æŸåï¼Œé©¾é©¶å‘˜ä¼šå‚åŠ è¯¦ç»†çš„åç»­è®¿è°ˆï¼Œè®¿è°ˆé€šå¸¸æŒç»­1.5-2å°æ—¶ã€‚åœ¨è®¿è°ˆè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æ”¶é›†åˆ°çš„è§†é¢‘é‡ç°é©¾é©¶å‘˜åˆšåˆšç»å†çš„ä»»åŠ¡æƒ…å¢ƒã€‚å¯¹äºæ¯ä¸ªé©¾é©¶åŠ¨ä½œï¼ˆå¦‚åŠ é€Ÿã€å˜é“æˆ–è½¬å¼¯ï¼‰ï¼Œé©¾é©¶å‘˜è¢«è¦æ±‚å›å¿†å¹¶æè¿°æ•´ä¸ªå†³ç­–è¿‡ç¨‹ï¼Œä»è¯„ä¼°å‘¨å›´ç¯å¢ƒåˆ°æ‰§è¡Œç›¸åº”çš„é©¾é©¶åŠ¨ä½œã€‚è¿™äº›è®¿è°ˆæ•°æ®å°†æœ‰åŠ©äºç¡®å®šé©¾é©¶å‘˜çš„é©¾é©¶é£æ ¼ï¼ŒåŒæ—¶ä¹Ÿä½œä¸ºå¤šå¯¹é½æ¡†æ¶ä¸­çš„æ¼”ç¤ºæºã€‚
- en: III-B Driving Style Selection and Data Organization
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B é©¾é©¶é£æ ¼é€‰æ‹©ä¸æ•°æ®æ•´ç†
- en: Having completed driving experiments and post-experiment interviews, our next
    task is to differentiate the driversâ€™ driving styles and organize the think-aloud
    data into demonstrations of different styles.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œæˆé©¾é©¶å®éªŒå’Œåç»­è®¿è°ˆåï¼Œæˆ‘ä»¬çš„ä¸‹ä¸€æ­¥ä»»åŠ¡æ˜¯åŒºåˆ†é©¾é©¶å‘˜çš„é©¾é©¶é£æ ¼ï¼Œå¹¶å°†æ€ç»´è¿‡ç¨‹æ•°æ®æ•´ç†ä¸ºä¸åŒé£æ ¼çš„æ¼”ç¤ºã€‚
- en: 'The differentiation of driving styles is based on subjective questionnaire
    results and objective driving records in driving tasks. We distributed a MDSI
    questionnaire[[32](#bib.bib32)] to each driver invited to participate in the experiment.
    The results indicated the presence of four driving styles among the 24 drivers:
    risky, high-velocity, patient, and careful. Notably, the risky style often coincided
    with the high-velocity style, while the patient style typically appeared alongside
    the careful style. Further analysis of the CAN-Bus data during driving tasks revealed
    that 3 drivers exhibited speeds and throttle percentages significantly above the
    average â€” specifically, the average speed of all drivers was 6.40 m/s and average
    throttle percentage was 23.09%, while average speed of these 3 drivers respectively
    reached speeds of 7.73 m/s (20.78% higher than average), 7.50 m/s (17.19% higher
    than average) and 7.41 m/s (15.78% higher than average), and average throttle
    percentages reached 29.09% (25.99% higher than average), 24.42% (5.76% higher
    than average) and 24.37% (5.54% higher than average) â€” aligning with their self-reported
    â€™risky and high-velocityâ€™ driving styles in the questionnaire. Conversely, 2 other
    drivers had lower metrics â€” with speeds of 5.15 m/s (19.53% lower than average)
    and 5.28 m/s (17.50% lower than average) respectively, and throttle percentage
    of 21.00% (9.05% lower than average) and 21.34% (7.58% lower than average) â€” aligning
    with their self-reported â€™patient and carefulâ€™ driving styles in the questionnaire.
    Additionally, a few drivers who reported to have driving styles in the questionnaire
    did not show clear trends in either driving data or interview records.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: é©¾é©¶é£æ ¼çš„åŒºåˆ†åŸºäºä¸»è§‚é—®å·ç»“æœå’Œå®¢è§‚é©¾é©¶è®°å½•ã€‚æˆ‘ä»¬å‘æ¯ä½å—é‚€å‚åŠ å®éªŒçš„é©¾é©¶å‘˜åˆ†å‘äº† MDSI é—®å·[[32](#bib.bib32)]ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨24åé©¾é©¶å‘˜ä¸­å­˜åœ¨å››ç§é©¾é©¶é£æ ¼ï¼šå†’é™©å‹ã€é«˜é€Ÿå‹ã€è€å¿ƒå‹å’Œè°¨æ…å‹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå†’é™©å‹é£æ ¼é€šå¸¸ä¸é«˜é€Ÿå‹é£æ ¼é‡åˆï¼Œè€Œè€å¿ƒå‹é£æ ¼é€šå¸¸ä¸è°¨æ…å‹é£æ ¼åŒæ—¶å‡ºç°ã€‚å¯¹é©¾é©¶ä»»åŠ¡ä¸­
    CAN-Bus æ•°æ®çš„è¿›ä¸€æ­¥åˆ†ææ˜¾ç¤ºï¼Œ3åé©¾é©¶å‘˜çš„é€Ÿåº¦å’Œæ²¹é—¨ç™¾åˆ†æ¯”æ˜¾è‘—é«˜äºå¹³å‡æ°´å¹³â€”â€”å…·ä½“æ¥è¯´ï¼Œæ‰€æœ‰é©¾é©¶å‘˜çš„å¹³å‡é€Ÿåº¦ä¸º6.40 m/sï¼Œå¹³å‡æ²¹é—¨ç™¾åˆ†æ¯”ä¸º23.09%ï¼Œè€Œè¿™3åé©¾é©¶å‘˜çš„å¹³å‡é€Ÿåº¦åˆ†åˆ«è¾¾åˆ°7.73
    m/sï¼ˆæ¯”å¹³å‡æ°´å¹³é«˜å‡º20.78%ï¼‰ã€7.50 m/sï¼ˆæ¯”å¹³å‡æ°´å¹³é«˜å‡º17.19%ï¼‰å’Œ7.41 m/sï¼ˆæ¯”å¹³å‡æ°´å¹³é«˜å‡º15.78%ï¼‰ï¼Œæ²¹é—¨ç™¾åˆ†æ¯”åˆ†åˆ«è¾¾åˆ°29.09%ï¼ˆæ¯”å¹³å‡æ°´å¹³é«˜å‡º25.99%ï¼‰ã€24.42%ï¼ˆæ¯”å¹³å‡æ°´å¹³é«˜å‡º5.76%ï¼‰å’Œ24.37%ï¼ˆæ¯”å¹³å‡æ°´å¹³é«˜å‡º5.54%ï¼‰â€”â€”è¿™äº›æ•°æ®ä¸ä»–ä»¬åœ¨é—®å·ä¸­è‡ªæŠ¥çš„â€˜å†’é™©å’Œé«˜é€Ÿâ€™é©¾é©¶é£æ ¼ä¸€è‡´ã€‚ç›¸åï¼Œå¦å¤–2åé©¾é©¶å‘˜çš„æŒ‡æ ‡è¾ƒä½â€”â€”é€Ÿåº¦åˆ†åˆ«ä¸º5.15
    m/sï¼ˆæ¯”å¹³å‡æ°´å¹³ä½19.53%ï¼‰å’Œ5.28 m/sï¼ˆæ¯”å¹³å‡æ°´å¹³ä½17.50%ï¼‰ï¼Œæ²¹é—¨ç™¾åˆ†æ¯”åˆ†åˆ«ä¸º21.00%ï¼ˆæ¯”å¹³å‡æ°´å¹³ä½9.05%ï¼‰å’Œ21.34%ï¼ˆæ¯”å¹³å‡æ°´å¹³ä½7.58%ï¼‰â€”â€”è¿™äº›æ•°æ®ä¸ä»–ä»¬åœ¨é—®å·ä¸­è‡ªæŠ¥çš„â€˜è€å¿ƒå’Œè°¨æ…â€™é©¾é©¶é£æ ¼ä¸€è‡´ã€‚æ­¤å¤–ï¼Œä¸€äº›åœ¨é—®å·ä¸­æŠ¥å‘Šæœ‰ç‰¹å®šé©¾é©¶é£æ ¼çš„é©¾é©¶å‘˜åœ¨é©¾é©¶æ•°æ®æˆ–è®¿è°ˆè®°å½•ä¸­æœªæ˜¾ç¤ºå‡ºæ˜æ˜¾çš„è¶‹åŠ¿ã€‚
- en: 'Therefore, we identified two basic driving styles: â€™riskyâ€™ and â€™high-velocityâ€™
    were merged into â€™risky,â€™ while â€™patientâ€™ and â€™carefulâ€™ were combined into â€™cautious.â€™
    We reviewed the interview data of drivers with risky driving styles and those
    with cautious driving styles, selecting representative decision-making processes
    that exemplify each driving style. Then, we organized each process according to
    the decision sequence into the format of â€™Situationâ€™, â€™Reasoningâ€™ and â€™Actionâ€™,
    forming the final Demonstrations for alignment with humans.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬ç¡®å®šäº†ä¸¤ç§åŸºæœ¬çš„é©¾é©¶é£æ ¼ï¼šå°†â€™å†’é™©â€™å’Œâ€™é«˜é€Ÿâ€™åˆå¹¶ä¸ºâ€™å†’é™©â€™ï¼Œè€Œâ€™è€å¿ƒâ€™å’Œâ€™å°å¿ƒâ€™åˆå¹¶ä¸ºâ€™è°¨æ…â€™ã€‚æˆ‘ä»¬å®¡æŸ¥äº†å†’é™©é©¾é©¶é£æ ¼å’Œè°¨æ…é©¾é©¶é£æ ¼çš„å¸æœºçš„è®¿è°ˆæ•°æ®ï¼Œé€‰æ‹©äº†ä»£è¡¨æ€§çš„å†³ç­–è¿‡ç¨‹æ¥ç¤ºèŒƒæ¯ç§é©¾é©¶é£æ ¼ã€‚ç„¶åï¼Œæˆ‘ä»¬æŒ‰ç…§å†³ç­–é¡ºåºå°†æ¯ä¸ªè¿‡ç¨‹ç»„ç»‡ä¸ºâ€™Situationâ€™ï¼Œâ€™Reasoningâ€™å’Œâ€™Actionâ€™çš„æ ¼å¼ï¼Œå½¢æˆæœ€ç»ˆçš„æ¼”ç¤ºï¼Œä»¥ä¾¿ä¸äººç±»å¯¹é½ã€‚
- en: IV Experiment
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV å®éªŒ
- en: 'In this section, we validated the proposed Multi-alignment Framework by exploring
    the following questions:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æ¢ç´¢ä»¥ä¸‹é—®é¢˜éªŒè¯äº†æå‡ºçš„å¤šé‡å¯¹é½æ¡†æ¶ï¼š
- en: â€¢
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Can Driver Agents with different driving styles be constructed using human think-aloud
    data?
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ˜¯å¦å¯ä»¥ä½¿ç”¨äººç±»æ€ç»´è¿‡ç¨‹æ•°æ®æ„å»ºå…·æœ‰ä¸åŒé©¾é©¶é£æ ¼çš„é©¾é©¶ä»£ç†ï¼Ÿ
- en: â€¢
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Which alignment method can efficiently achieve human alignment of driving styles?
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å“ªç§å¯¹é½æ–¹æ³•å¯ä»¥é«˜æ•ˆå®ç°é©¾é©¶é£æ ¼çš„äººç±»å¯¹é½ï¼Ÿ
- en: To this end, we implemented the Multi-alignment Framework on CARLAâ€”a high-fidelity
    traffic simulator. A simulation experiment was carried out under urban driving
    conditions, upon which we further conducted a user experiment to collect human
    evaluations of its performance.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæˆ‘ä»¬åœ¨CARLAâ€”â€”ä¸€ä¸ªé«˜ä¿çœŸåº¦çš„äº¤é€šæ¨¡æ‹Ÿå™¨ä¸Šå®æ–½äº†å¤šé‡å¯¹é½æ¡†æ¶ã€‚æˆ‘ä»¬åœ¨åŸå¸‚é©¾é©¶æ¡ä»¶ä¸‹è¿›è¡Œäº†æ¨¡æ‹Ÿå®éªŒï¼Œå¹¶è¿›ä¸€æ­¥è¿›è¡Œäº†ç”¨æˆ·å®éªŒï¼Œä»¥æ”¶é›†å¯¹å…¶æ€§èƒ½çš„äººç±»è¯„ä»·ã€‚
- en: IV-A Conditions
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A æ¡ä»¶
- en: '![Refer to caption](img/b3b17ff62b998d04a62d63d0fa610805.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒè¯´æ˜](img/b3b17ff62b998d04a62d63d0fa610805.png)'
- en: 'Figure 2: Experiment conditions'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 2ï¼šå®éªŒæ¡ä»¶
- en: 'The experiment adopts an approximate 3 Ã— 3 with-in subject design with two
    main variables: Driving Style [cautiousÂ (C), riskyÂ (R)and not-alignedÂ (N)] and
    Alignment Method [demonstrationsÂ (D), feedbackÂ (F)and multi-alignmentÂ (M)]. Fig.
    [2](#S4.F2 "Figure 2 â€£ IV-A Conditions â€£ IV Experiment â€£ Driving Style Alignment
    for LLM-powered Driver Agent") shows the general design of different conditions.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å®éªŒé‡‡ç”¨äº†è¿‘ä¼¼çš„3 Ã— 3è¢«è¯•è®¾è®¡ï¼Œæœ‰ä¸¤ä¸ªä¸»è¦å˜é‡ï¼šé©¾é©¶é£æ ¼ [è°¨æ…ï¼ˆCï¼‰ï¼Œå†’é™©ï¼ˆRï¼‰å’Œæœªå¯¹é½ï¼ˆNï¼‰] å’Œå¯¹é½æ–¹æ³• [æ¼”ç¤ºï¼ˆDï¼‰ï¼Œåé¦ˆï¼ˆFï¼‰å’Œå¤šé‡å¯¹é½ï¼ˆMï¼‰]ã€‚å›¾
    [2](#S4.F2 "å›¾ 2 â€£ IV-A æ¡ä»¶ â€£ IV å®éªŒ â€£ é©¾é©¶é£æ ¼å¯¹é½çš„LLMé©±åŠ¨ä»£ç†") æ˜¾ç¤ºäº†ä¸åŒæ¡ä»¶çš„ä¸€èˆ¬è®¾è®¡ã€‚
- en: In terms of Driving Style, we compared the effects of using cautiousÂ driving
    demonstrations, riskyÂ driving demonstrations, and no demonstrations (i.e., not-aligned).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é©¾é©¶é£æ ¼æ–¹é¢ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†ä½¿ç”¨è°¨æ…é©¾é©¶æ¼”ç¤ºã€å†’é™©é©¾é©¶æ¼”ç¤ºå’Œä¸æä¾›æ¼”ç¤ºï¼ˆå³æœªå¯¹é½ï¼‰çš„æ•ˆæœã€‚
- en: Alignment Method was organized in an ablation format, with conditions including
    demonstrations, feedback, and multi-alignmentÂ (i.e., the full alignment framework).
    The demonstrationsÂ condition involves Driver Agents provided with demonstrations,
    and the feedbackÂ condition involves Driver Agents without demonstrations and Coach
    Agents that were provided with demonstrations, while in the multi-alignmentÂ condition,
    both Driver Agent and Coach Agent were provided with demonstrations.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹é½æ–¹æ³•ä»¥æ¶ˆèæ ¼å¼ç»„ç»‡ï¼Œæ¡ä»¶åŒ…æ‹¬æ¼”ç¤ºã€åé¦ˆå’Œå¤šé‡å¯¹é½ï¼ˆå³å®Œæ•´å¯¹é½æ¡†æ¶ï¼‰ã€‚æ¼”ç¤ºæ¡ä»¶æ¶‰åŠæä¾›æ¼”ç¤ºçš„é©¾é©¶ä»£ç†ï¼Œè€Œåé¦ˆæ¡ä»¶æ¶‰åŠæ²¡æœ‰æ¼”ç¤ºçš„é©¾é©¶ä»£ç†å’Œæä¾›æ¼”ç¤ºçš„æ•™ç»ƒä»£ç†ï¼Œè€Œåœ¨å¤šé‡å¯¹é½æ¡ä»¶ä¸‹ï¼Œé©¾é©¶ä»£ç†å’Œæ•™ç»ƒä»£ç†éƒ½æä¾›äº†æ¼”ç¤ºã€‚
- en: IV-B CARLA Simulation
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B CARLAæ¨¡æ‹Ÿ
- en: IV-B1 Set-up
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B1 è®¾ç½®
- en: The simulation experiment setup involved a ThundeRobot Zero desktop computer
    as the hardware foundation. The simulation environment was built upon the CARLA
    simulator, specifically, version 0.9.14Â³Â³3[http://carla.org/2022/12/23/release-0.9.14/](http://carla.org/2022/12/23/release-0.9.14/)
    and operated on Python 3.7 with Unreal Engine 4â´â´4[https://docs.unrealengine.com/4.27/en-US/](https://docs.unrealengine.com/4.27/en-US/).
    We use the map Town10, a typical urban driving scene, with both the number of
    other vehicles and pedestrians in the scenario set to 60\. And Audi TT was the
    designated vehicle for all experiments, with fixed starting and continuously,
    randomly generated ending points for its path (After a vehicle is generated at
    a predefined fixed point, a random endpoint is generated. Upon reaching the endpoint,
    another endpoint is randomly generated, and so on.).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡æ‹Ÿå®éªŒè®¾ç½®åŒ…æ‹¬äº†ä¸€ä¸ªThundeRobot Zeroæ¡Œé¢è®¡ç®—æœºä½œä¸ºç¡¬ä»¶åŸºç¡€ã€‚æ¨¡æ‹Ÿç¯å¢ƒå»ºç«‹åœ¨CARLAæ¨¡æ‹Ÿå™¨ä¸Šï¼Œå…·ä½“ä¸ºç‰ˆæœ¬0.9.14Â³Â³3[http://carla.org/2022/12/23/release-0.9.14/](http://carla.org/2022/12/23/release-0.9.14/)
    å¹¶ä¸”åœ¨Python 3.7ä¸Unreal Engine 4â´â´4[https://docs.unrealengine.com/4.27/en-US/](https://docs.unrealengine.com/4.27/en-US/)
    ä¸Šè¿è¡Œã€‚æˆ‘ä»¬ä½¿ç”¨Town10åœ°å›¾ï¼Œè¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„åŸå¸‚é©¾é©¶åœºæ™¯ï¼Œåœºæ™¯ä¸­çš„å…¶ä»–è½¦è¾†å’Œè¡Œäººæ•°é‡éƒ½è®¾å®šä¸º60ã€‚æ‰€æœ‰å®éªŒæŒ‡å®šçš„è½¦è¾†ä¸ºAudi TTï¼Œè·¯å¾„æœ‰å›ºå®šçš„èµ·ç‚¹å’Œä¸æ–­éšæœºç”Ÿæˆçš„ç»ˆç‚¹ï¼ˆè½¦è¾†åœ¨é¢„å®šä¹‰çš„å›ºå®šç‚¹ç”Ÿæˆåï¼Œä¼šç”Ÿæˆä¸€ä¸ªéšæœºç»ˆç‚¹ã€‚åˆ°è¾¾ç»ˆç‚¹åï¼Œå†ç”Ÿæˆå¦ä¸€ä¸ªéšæœºç»ˆç‚¹ï¼Œä»¥æ­¤ç±»æ¨ã€‚ï¼‰ã€‚
- en: We leverage OpenAIâ€™s GPT-4âµâµ5[https://openai.com/gpt-4](https://openai.com/gpt-4)
    APIs for constructing both the Driver Agent and the Coach Agent. However, it takes
    several seconds for GPT to generate a response, which is too long in a driving
    context for making immediate decisions. Therefore, we slowed down CARLAâ€™s simulation
    time based on the required token count by setting a fixed time-step of 0.0008-0.0015
    seconds.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆ©ç”¨äº†OpenAIçš„GPT-4âµâµ5[https://openai.com/gpt-4](https://openai.com/gpt-4) API
    æ¥æ„å»ºDriver Agentå’ŒCoach Agentã€‚ç„¶è€Œï¼ŒGPTç”Ÿæˆå“åº”éœ€è¦å‡ ç§’é’Ÿï¼Œè¿™åœ¨é©¾é©¶æƒ…å¢ƒä¸‹å¯¹äºåšå‡ºå³æ—¶å†³ç­–æ¥è¯´æ—¶é—´å¤ªé•¿ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åŸºäºæ‰€éœ€çš„ä»¤ç‰Œæ•°é‡å°†CARLAçš„æ¨¡æ‹Ÿæ—¶é—´å‡æ…¢ï¼Œè®¾ç½®äº†å›ºå®šçš„æ—¶é—´æ­¥é•¿ä¸º0.0008-0.0015ç§’ã€‚
- en: Each simulation process is recorded on video. Additionally, to collect vehicle
    status information during the simulation, we initiated a log-collector thread
    to accumulate log on collisions, speed, throttle percentage, and brake percentage
    from the agent vehicle on a second-by-second basis.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ¨¡æ‹Ÿè¿‡ç¨‹éƒ½è¢«å½•åˆ¶ä¸ºè§†é¢‘ã€‚æ­¤å¤–ï¼Œä¸ºäº†åœ¨æ¨¡æ‹Ÿè¿‡ç¨‹ä¸­æ”¶é›†è½¦è¾†çŠ¶æ€ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯åŠ¨äº†ä¸€ä¸ªæ—¥å¿—æ”¶é›†çº¿ç¨‹ï¼Œä»¥æ¯ç§’é’Ÿä¸ºå•ä½ç§¯ç´¯æ¥è‡ªä»£ç†è½¦è¾†çš„ç¢°æ’ã€é€Ÿåº¦ã€æ²¹é—¨ç™¾åˆ†æ¯”å’Œåˆ¹è½¦ç™¾åˆ†æ¯”çš„æ—¥å¿—ã€‚
- en: IV-B2 Metrics
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B2 æŒ‡æ ‡
- en: 'Here, we introduce three metrics to evaluate the driving performance of the
    Driver Agent: collision rate, speed, throttle percentage, and brake percentage.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸‰ä¸ªæŒ‡æ ‡æ¥è¯„ä¼°Driver Agentçš„é©¾é©¶è¡¨ç°ï¼šç¢°æ’ç‡ã€é€Ÿåº¦ã€æ²¹é—¨ç™¾åˆ†æ¯”å’Œåˆ¹è½¦ç™¾åˆ†æ¯”ã€‚
- en: â€¢
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'Collision rate: The number of collisions can be obtained from the log, with
    distance traveled being cumulative up to the last collision. The calculating formula
    is $1$2'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¢°æ’ç‡ï¼šç¢°æ’æ¬¡æ•°å¯ä»¥ä»æ—¥å¿—ä¸­è·å¾—ï¼Œè¡Œé©¶è·ç¦»æ˜¯ç´¯ç§¯åˆ°æœ€åä¸€æ¬¡ç¢°æ’çš„ã€‚è®¡ç®—å…¬å¼æ˜¯ $1$2
- en: â€¢
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'Speed: The statistical measures for speed include the average speed of the
    agent vehicle during each simulation and the segmented average speed per minute
    (simulator time). All calculations of average speed exclude zero values to minimize
    the impact of the agent vehicle waiting at traffic signals and in traffic jams.'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é€Ÿåº¦ï¼šé€Ÿåº¦çš„ç»Ÿè®¡æŒ‡æ ‡åŒ…æ‹¬æ¯æ¬¡æ¨¡æ‹ŸæœŸé—´ä»£ç†è½¦è¾†çš„å¹³å‡é€Ÿåº¦å’Œæ¯åˆ†é’Ÿï¼ˆæ¨¡æ‹Ÿæ—¶é—´ï¼‰çš„åˆ†æ®µå¹³å‡é€Ÿåº¦ã€‚æ‰€æœ‰å¹³å‡é€Ÿåº¦è®¡ç®—å‡ä¸åŒ…æ‹¬é›¶å€¼ï¼Œä»¥å‡å°‘ä»£ç†è½¦è¾†åœ¨äº¤é€šä¿¡å·ç¯å’Œäº¤é€šæ‹¥å µä¸­ç­‰å¾…çš„å½±å“ã€‚
- en: â€¢
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'Throttle percentage & brake percentage: The statistics for throttle and brake
    percentages are also divided into overall average values and segmented average
    values per minute. Similarly, all calculations exclude data from when the agent
    vehicle is stationary.'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ²¹é—¨ç™¾åˆ†æ¯” & åˆ¹è½¦ç™¾åˆ†æ¯”ï¼šæ²¹é—¨å’Œåˆ¹è½¦ç™¾åˆ†æ¯”çš„ç»Ÿè®¡ä¹Ÿåˆ†ä¸ºæ•´ä½“å¹³å‡å€¼å’Œæ¯åˆ†é’Ÿçš„åˆ†æ®µå¹³å‡å€¼ã€‚ç±»ä¼¼åœ°ï¼Œæ‰€æœ‰è®¡ç®—å‡ä¸åŒ…æ‹¬ä»£ç†è½¦è¾†é™æ­¢æ—¶çš„æ•°æ®ã€‚
- en: IV-B3 Results
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B3 ç»“æœ
- en: '![Refer to caption](img/52b42b10ae333ff6242b5f16f4cb1e9c.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜](img/52b42b10ae333ff6242b5f16f4cb1e9c.png)'
- en: (a) Collision rates per meter (with increased incidences of abrupt maneuvers
    by surrounding vehicles and pedestrians).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: (a) æ¯ç±³ç¢°æ’ç‡ï¼ˆå‘¨å›´è½¦è¾†å’Œè¡Œäººçªç„¶åŠ¨ä½œå¢åŠ çš„æƒ…å†µä¸‹ï¼‰ã€‚
- en: '![Refer to caption](img/47e235384fcae6e8ede37f9bb6721039.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜](img/47e235384fcae6e8ede37f9bb6721039.png)'
- en: (b) Average throttle percentage (left), brake percentage (middle), and speed
    (right) of the agent vehicle, with all calculations excluding data from when the
    agent vehicle was stationary (the speed limit is km/h).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: (b) ä»£ç†è½¦è¾†çš„å¹³å‡æ²¹é—¨ç™¾åˆ†æ¯”ï¼ˆå·¦ï¼‰ï¼Œåˆ¹è½¦ç™¾åˆ†æ¯”ï¼ˆä¸­ï¼‰ï¼Œå’Œé€Ÿåº¦ï¼ˆå³ï¼‰ï¼Œæ‰€æœ‰è®¡ç®—å‡ä¸åŒ…æ‹¬ä»£ç†è½¦è¾†é™æ­¢æ—¶çš„æ•°æ®ï¼ˆé€Ÿåº¦é™åˆ¶ä¸ºkm/hï¼‰ã€‚
- en: 'Figure 3: Simulation experiment results for predefined metrics.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 3ï¼šé¢„å®šä¹‰æŒ‡æ ‡çš„ä»¿çœŸå®éªŒç»“æœã€‚
- en: We conducted approximately 50.3 hours of simulation experiments under various
    conditions, which corresponds to an average of about 6.7 minutes of driving per
    condition for the agent vehicle on the simulation platform. The average distance
    the agent vehicle traveled per condition was approximately 1.5 kilometers. Notably,
    we adjusted the algorithms controlling other vehicles and pedestrians to make
    them more prone to sudden maneuvers (e.g. abrupt lane changes, running red lights).
    These edge cases aim to increase the risk level of the driving environment for
    the agent vehicle, making its driving style more observable.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨å„ç§æ¡ä»¶ä¸‹è¿›è¡Œäº†å¤§çº¦ 50.3 å°æ—¶çš„ä»¿çœŸå®éªŒï¼Œç›¸å½“äºæ¯ç§æ¡ä»¶ä¸‹ä»£ç†è½¦è¾†åœ¨ä»¿çœŸå¹³å°ä¸Šçš„å¹³å‡é©¾é©¶æ—¶é—´çº¦ä¸º 6.7 åˆ†é’Ÿã€‚ä»£ç†è½¦è¾†åœ¨æ¯ç§æ¡ä»¶ä¸‹è¡Œé©¶çš„å¹³å‡è·ç¦»çº¦ä¸º
    1.5 å…¬é‡Œã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬è°ƒæ•´äº†æ§åˆ¶å…¶ä»–è½¦è¾†å’Œè¡Œäººçš„ç®—æ³•ï¼Œä½¿å…¶æ›´å®¹æ˜“å‘ç”Ÿçªç„¶çš„æ“ä½œï¼ˆä¾‹å¦‚æ€¥å‰§å˜é“ã€é—¯çº¢ç¯ï¼‰ã€‚è¿™äº›æç«¯æƒ…å†µæ—¨åœ¨æé«˜ä»£ç†è½¦è¾†çš„é©¾é©¶ç¯å¢ƒçš„é£é™©æ°´å¹³ï¼Œä½¿å…¶é©¾é©¶é£æ ¼æ›´å…·å¯è§‚å¯Ÿæ€§ã€‚
- en: Fig. [3(a)](#S4.F3.sf1 "In Figure 3 â€£ IV-B3 Results â€£ IV-B CARLA Simulation
    â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered Driver Agent") displays
    the collision rates per meter for the agent vehicle calculated under different
    conditions. Agents aligned with the riskyÂ driving style overall exhibit higher
    collision rates, while those aligned with the cautiousÂ driving style show lower
    collision rates overall. Additionally, when aligned with cautiousÂ driving style,
    the multi-alignmentÂ method displayed the lowest collision rate while the demonstrationsÂ method
    displayed the highest, and when aligned with riskyÂ driving style, the multi-alignmentÂ method
    showed the highest collision rate while the demonstrationsÂ method displayed the
    highest. When not-aligned, the collision rate for the demonstrationsÂ method is
    higher than that for the feedbackÂ method.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ [3(a)](#S4.F3.sf1 "å›¾ 3 â€£ IV-B3 ç»“æœ â€£ IV-B CARLA ä»¿çœŸ â€£ IV å®éªŒ â€£ LLM é©±åŠ¨ä»£ç†çš„é©¾é©¶é£æ ¼å¯¹é½")
    æ˜¾ç¤ºäº†åœ¨ä¸åŒæ¡ä»¶ä¸‹è®¡ç®—çš„ä»£ç†è½¦è¾†æ¯ç±³ç¢°æ’ç‡ã€‚æ€»ä½“æ¥çœ‹ï¼Œç¬¦åˆé£é™©é©¾é©¶é£æ ¼çš„ä»£ç†æ˜¾ç¤ºå‡ºæ›´é«˜çš„ç¢°æ’ç‡ï¼Œè€Œç¬¦åˆè°¨æ…é©¾é©¶é£æ ¼çš„ä»£ç†åˆ™æ˜¾ç¤ºå‡ºæ›´ä½çš„ç¢°æ’ç‡ã€‚æ­¤å¤–ï¼Œç¬¦åˆè°¨æ…é©¾é©¶é£æ ¼æ—¶ï¼Œå¤šé‡å¯¹é½æ–¹æ³•æ˜¾ç¤ºå‡ºæœ€ä½çš„ç¢°æ’ç‡ï¼Œè€Œæ¼”ç¤ºæ–¹æ³•æ˜¾ç¤ºå‡ºæœ€é«˜çš„ç¢°æ’ç‡ï¼›ç¬¦åˆé£é™©é©¾é©¶é£æ ¼æ—¶ï¼Œå¤šé‡å¯¹é½æ–¹æ³•æ˜¾ç¤ºå‡ºæœ€é«˜çš„ç¢°æ’ç‡ï¼Œè€Œæ¼”ç¤ºæ–¹æ³•ä¹Ÿæ˜¾ç¤ºå‡ºæœ€é«˜çš„ç¢°æ’ç‡ã€‚åœ¨æœªå¯¹é½æ—¶ï¼Œæ¼”ç¤ºæ–¹æ³•çš„ç¢°æ’ç‡é«˜äºåé¦ˆæ–¹æ³•ã€‚
- en: Fig. [3(b)](#S4.F3.sf2 "In Figure 3 â€£ IV-B3 Results â€£ IV-B CARLA Simulation
    â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered Driver Agent") presents
    the average throttle percentage, brake percentage, and speed of the agent vehicle
    during the driving process under different conditions, with all calculations excluding
    data from when the agent vehicle was stationary. When using the same alignment
    method, agents aligned with the riskyÂ driving style had the highest average speed,
    highest throttle percentage, and lowest brake percentage, while agents aligned
    with the cautiousÂ driving style had the lowest speed, lowest throttle percentage,
    and highest brake percentage. When aligned with the cautiousÂ driving style, the
    average speed and throttle percentage decrease while the average brake percentage
    increases across the demonstrations, feedback, and multi-alignment, in that order.
    The opposite trend is observed when aligning with the riskyÂ driving style. When
    not-aligned, the average speed and throttle percentage for the demonstrationsÂ method
    are higher than those for the feedbackÂ method, while the average brake percentage
    is lower.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ [3(b)](#S4.F3.sf2 "å›¾ 3 â€£ IV-B3 ç»“æœ â€£ IV-B CARLA ä»¿çœŸ â€£ IV å®éªŒ â€£ LLM é©±åŠ¨ä»£ç†çš„é©¾é©¶é£æ ¼å¯¹é½")
    å±•ç¤ºäº†åœ¨ä¸åŒæ¡ä»¶ä¸‹ï¼Œä»£ç†è½¦è¾†åœ¨é©¾é©¶è¿‡ç¨‹ä¸­å¹³å‡æ²¹é—¨ç™¾åˆ†æ¯”ã€åˆ¹è½¦ç™¾åˆ†æ¯”å’Œé€Ÿåº¦çš„æƒ…å†µï¼Œæ‰€æœ‰è®¡ç®—å‡ä¸åŒ…æ‹¬ä»£ç†è½¦è¾†é™æ­¢æ—¶çš„æ•°æ®ã€‚åœ¨ä½¿ç”¨ç›¸åŒå¯¹é½æ–¹æ³•æ—¶ï¼Œç¬¦åˆé£é™©é©¾é©¶é£æ ¼çš„ä»£ç†å…·æœ‰æœ€é«˜çš„å¹³å‡é€Ÿåº¦ã€æœ€é«˜çš„æ²¹é—¨ç™¾åˆ†æ¯”å’Œæœ€ä½çš„åˆ¹è½¦ç™¾åˆ†æ¯”ï¼Œè€Œç¬¦åˆè°¨æ…é©¾é©¶é£æ ¼çš„ä»£ç†åˆ™å…·æœ‰æœ€ä½çš„é€Ÿåº¦ã€æœ€ä½çš„æ²¹é—¨ç™¾åˆ†æ¯”å’Œæœ€é«˜çš„åˆ¹è½¦ç™¾åˆ†æ¯”ã€‚åœ¨è°¨æ…é©¾é©¶é£æ ¼å¯¹é½æ—¶ï¼Œæ¼”ç¤ºã€åé¦ˆå’Œå¤šé‡å¯¹é½ä¸­å¹³å‡é€Ÿåº¦å’Œæ²¹é—¨ç™¾åˆ†æ¯”ä¾æ¬¡å‡å°‘ï¼Œè€Œå¹³å‡åˆ¹è½¦ç™¾åˆ†æ¯”åˆ™å¢åŠ ã€‚ä¸é£é™©é©¾é©¶é£æ ¼å¯¹é½æ—¶åˆ™è§‚å¯Ÿåˆ°ç›¸åçš„è¶‹åŠ¿ã€‚åœ¨æœªå¯¹é½æ—¶ï¼Œæ¼”ç¤ºæ–¹æ³•çš„å¹³å‡é€Ÿåº¦å’Œæ²¹é—¨ç™¾åˆ†æ¯”é«˜äºåé¦ˆæ–¹æ³•ï¼Œè€Œå¹³å‡åˆ¹è½¦ç™¾åˆ†æ¯”åˆ™è¾ƒä½ã€‚
- en: IV-B4 Findings
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B4 å‘ç°
- en: Based on the hypothesis that agents with more cautious driving styles are safer,
    agents can exhibit corresponding driving styles by aligning with different driving
    styles. multi-alignmentÂ was the most effective method, displaying the most significant
    differences in collision rates, average throttle, brake, and speed between cautious
    and risky driving styles, while demonstrationsÂ were less effective.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºâ€œæ›´è°¨æ…çš„é©¾é©¶é£æ ¼æ›´å®‰å…¨â€çš„å‡è®¾ï¼Œä»£ç†å¯ä»¥é€šè¿‡ä¸ä¸åŒçš„é©¾é©¶é£æ ¼å¯¹é½æ¥å±•ç¤ºç›¸åº”çš„é©¾é©¶é£æ ¼ã€‚å¤šé‡å¯¹é½Â æ˜¯æœ€æœ‰æ•ˆçš„æ–¹æ³•ï¼Œè¡¨ç°å‡ºè°¨æ…å’Œå†’é™©é©¾é©¶é£æ ¼ä¹‹é—´åœ¨ç¢°æ’ç‡ã€å¹³å‡æ²¹é—¨ã€åˆ¹è½¦å’Œé€Ÿåº¦æ–¹é¢çš„æ˜¾è‘—å·®å¼‚ï¼Œè€Œæ¼”ç¤ºÂ åˆ™æ•ˆæœè¾ƒå·®ã€‚
- en: IV-C Human Evaluation
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C äººå·¥è¯„ä¼°
- en: IV-C1 Procedure
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C1 ç¨‹åº
- en: We designed two survey questionnaires to collect human driversâ€™ evaluations
    of the Driver Agentâ€™s performance, which was presented to participants in the
    questionnaire through video clips of the simulation, with about 30 seconds of
    driving footage captured for each experimental condition.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¾è®¡äº†ä¸¤ä¸ªè°ƒæŸ¥é—®å·æ¥æ”¶é›†äººç±»é©¾é©¶å‘˜å¯¹é©¾é©¶ä»£ç†è¡¨ç°çš„è¯„ä»·ï¼Œè¿™äº›è¯„ä»·é€šè¿‡æ¨¡æ‹Ÿè§†é¢‘ç‰‡æ®µå‘ˆç°ç»™å‚ä¸è€…ï¼Œæ¯ä¸ªå®éªŒæ¡ä»¶ä¸‹æ•æ‰äº†å¤§çº¦30ç§’çš„é©¾é©¶è§†é¢‘ã€‚
- en: In Part I of the first questionnaire, we initially collected basic information
    (e.g. age, gender, whether holding a driving license) from participants. A partial
    MDSI self-assessment was also included, with items covering indicators of risky
    and careful driving styles from the MDSI.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬¬ä¸€ä¸ªé—®å·çš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬æœ€åˆæ”¶é›†äº†å‚ä¸è€…çš„åŸºæœ¬ä¿¡æ¯ï¼ˆå¦‚å¹´é¾„ã€æ€§åˆ«ã€æ˜¯å¦æŒæœ‰é©¾é©¶æ‰§ç…§ï¼‰ã€‚è¿˜åŒ…æ‹¬äº†éƒ¨åˆ†MDSIè‡ªæˆ‘è¯„ä¼°ï¼Œé¡¹ç›®æ¶µç›–äº†MDSIä¸­é£é™©å’Œè°¨æ…é©¾é©¶é£æ ¼çš„æŒ‡æ ‡ã€‚
- en: 'In Part II, the video clips are divided into four groups:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬¬äºŒéƒ¨åˆ†ä¸­ï¼Œè§†é¢‘ç‰‡æ®µè¢«åˆ†ä¸ºå››ç»„ï¼š
- en: â€¢
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'Demonstrations Group: {demonstrationsÂ cautiousÂ (DC), demonstrationsÂ not-alignedÂ (DN),
    demonstrationsÂ riskyÂ (DR)}'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¼”ç¤ºç»„ï¼š{æ¼”ç¤ºÂ è°¨æ…Â (DC)ã€æ¼”ç¤ºÂ ä¸å¯¹é½Â (DN)ã€æ¼”ç¤ºÂ å†’é™©Â (DR)}
- en: â€¢
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'Feedback Group: {feedbackÂ cautiousÂ (FC), feedbackÂ not-alignedÂ (FN), feedbackÂ riskyÂ (FR),
    demonstrationsÂ not-alignedÂ (DN, serving as baseline in this group)}'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åé¦ˆç»„ï¼š{åé¦ˆÂ è°¨æ…Â (FC)ã€åé¦ˆÂ ä¸å¯¹é½Â (FN)ã€åé¦ˆÂ å†’é™©Â (FR)ã€æ¼”ç¤ºÂ ä¸å¯¹é½Â (DNï¼Œä½œä¸ºè¯¥ç»„çš„åŸºçº¿)}
- en: â€¢
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'Cautious Group: {demonstrationsÂ cautiousÂ (DC), feedbackÂ cautiousÂ (FC), multi-alignmentÂ cautiousÂ (MC)}'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è°¨æ…ç»„ï¼š{æ¼”ç¤ºÂ è°¨æ…Â (DC)ã€åé¦ˆÂ è°¨æ…Â (FC)ã€å¤šé‡å¯¹é½Â è°¨æ…Â (MC)}
- en: â€¢
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'Risky Group: {demonstrationsÂ riskyÂ (DR), feedbackÂ riskyÂ (FR), multi-alignmentÂ riskyÂ (MR)}'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å†’é™©ç»„ï¼š{æ¼”ç¤ºÂ å†’é™©Â (DR)ã€åé¦ˆÂ å†’é™©Â (FR)ã€å¤šé‡å¯¹é½Â å†’é™©Â (MR)}
- en: Each group of video clips will appear in a random order, accompanied by a ranking
    question requiring participants to rank the driving styles in the videos according
    to their level of riskiness (a smaller number indicates more risky) and a reason
    question for explaining their rankings.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ç»„è§†é¢‘ç‰‡æ®µå°†ä»¥éšæœºé¡ºåºå‡ºç°ï¼Œå¹¶é™„æœ‰ä¸€ä¸ªæ’åé—®é¢˜ï¼Œè¦æ±‚å‚ä¸è€…æ ¹æ®è§†é¢‘ä¸­çš„é©¾é©¶é£æ ¼çš„é£é™©ç¨‹åº¦å¯¹å…¶è¿›è¡Œæ’åï¼ˆæ•°å­—è¶Šå°è¡¨ç¤ºé£é™©è¶Šå¤§ï¼‰ï¼Œä»¥åŠä¸€ä¸ªè§£é‡Šæ’åçš„ç†ç”±é—®é¢˜ã€‚
- en: Parts I of the second questionnaire are identical to the first questionnaire.
    In Part II, participants were instructed to watch all of the eight videos clips,
    which were also organized in a random order, with three scoring questions respectively
    investigated the intelligence level, riskiness level and human-likeness level
    of the agent vehicle (all from 0 to 10) and a reason question attached below each
    clip.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä¸ªé—®å·çš„ç¬¬ä¸€éƒ¨åˆ†ä¸ç¬¬ä¸€ä¸ªé—®å·ç›¸åŒã€‚åœ¨ç¬¬äºŒéƒ¨åˆ†ä¸­ï¼Œå‚ä¸è€…è¢«è¦æ±‚è§‚çœ‹æ‰€æœ‰å…«ä¸ªè§†é¢‘ç‰‡æ®µï¼Œè¿™äº›ç‰‡æ®µä¹Ÿä»¥éšæœºé¡ºåºç»„ç»‡ï¼Œä¸‰ä¸ªè¯„åˆ†é—®é¢˜åˆ†åˆ«è°ƒæŸ¥äº†ä»£ç†è½¦è¾†çš„æ™ºèƒ½æ°´å¹³ã€é£é™©æ°´å¹³å’Œäººç±»ç›¸ä¼¼åº¦æ°´å¹³ï¼ˆå‡ä¸º0åˆ°10ï¼‰ï¼Œæ¯ä¸ªç‰‡æ®µä¸‹æ–¹é™„æœ‰ä¸€ä¸ªç†ç”±é—®é¢˜ã€‚
- en: Additionally, to filter out carelessly completed questionnaires, we set a minimum
    answering time and included trap questions in the questionnaire, which required
    participants to select a certain option.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œä¸ºäº†ç­›é€‰å‡ºç²—å¿ƒå¡«å†™çš„é—®å·ï¼Œæˆ‘ä»¬è®¾ç½®äº†æœ€ä½å›ç­”æ—¶é—´ï¼Œå¹¶åœ¨é—®å·ä¸­åŠ å…¥äº†é™·é˜±é—®é¢˜ï¼Œè¦æ±‚å‚ä¸è€…é€‰æ‹©ç‰¹å®šçš„é€‰é¡¹ã€‚
- en: IV-C2 Participants
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C2 å‚ä¸è€…
- en: We recruited over 200 participants through a third-party recruitment channel
    provided by the survey platform, offering a compensation of approximately $2.08
    per valid questionnaire completed. Additionally, our team of five researchers
    also shared our questionnaires on social media platforms, recruiting over 60 participants.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡è°ƒæŸ¥å¹³å°æä¾›çš„ç¬¬ä¸‰æ–¹æ‹›è˜æ¸ é“æ‹›å‹Ÿäº†200å¤šåå‚ä¸è€…ï¼Œä¸ºæ¯ä»½æœ‰æ•ˆå¡«å†™çš„é—®å·æä¾›äº†å¤§çº¦$2.08çš„è¡¥å¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„äº”åç ”ç©¶äººå‘˜è¿˜åœ¨ç¤¾äº¤åª’ä½“å¹³å°ä¸Šåˆ†äº«äº†é—®å·ï¼Œæ‹›å‹Ÿäº†60å¤šåå‚ä¸è€…ã€‚
- en: All 270 participants verified in the questionnaire that they possess a driving
    license. Among them, there were 141 male participants, accounting for 52.22%,
    and 129 female participants, accounting for 47.78%, with ages ranging from 19
    to 54 years old.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰270åå‚ä¸è€…åœ¨é—®å·ä¸­ç¡®è®¤ä»–ä»¬æŒæœ‰é©¾é©¶æ‰§ç…§ã€‚å…¶ä¸­ï¼Œç”·æ€§å‚ä¸è€…141äººï¼Œå 52.22%ï¼Œå¥³æ€§å‚ä¸è€…129äººï¼Œå 47.78%ï¼Œå¹´é¾„èŒƒå›´ä»19å²åˆ°54å²ã€‚
- en: IV-C3 Data Analysis
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C3 æ•°æ®åˆ†æ
- en: For both questionnaires, we first categorized participantsâ€™ driving styles based
    on the results from Section I. The formula for calculating the driving style score
    is $S_{driving\ style}=\Sigma o_{risky}-\Sigma o_{cautious}$ represents the option
    for each cautious indicator (with two negative indicators within, where options
    are included as negative values). The higher the driving style score, the more
    a participantâ€™s driving style tends towards being risky.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¸¤ä»½é—®å·ï¼Œæˆ‘ä»¬é¦–å…ˆæ ¹æ®ç¬¬ä¸€éƒ¨åˆ†çš„ç»“æœå¯¹å‚ä¸è€…çš„é©¾é©¶é£æ ¼è¿›è¡Œäº†åˆ†ç±»ã€‚è®¡ç®—é©¾é©¶é£æ ¼è¯„åˆ†çš„å…¬å¼ä¸º $S_{driving\ style}=\Sigma o_{risky}-\Sigma
    o_{cautious}$ï¼Œè¡¨ç¤ºæ¯ä¸ªè°¨æ…æŒ‡æ ‡çš„é€‰é¡¹ï¼ˆå…¶ä¸­åŒ…å«ä¸¤ä¸ªè´Ÿé¢æŒ‡æ ‡ï¼Œé€‰é¡¹ä»¥è´Ÿå€¼è®¡ï¼‰ã€‚é©¾é©¶é£æ ¼è¯„åˆ†è¶Šé«˜ï¼Œå‚ä¸è€…çš„é©¾é©¶é£æ ¼è¶Šå€¾å‘äºé£é™©ã€‚
- en: For Part II of the first questionnaire, we calculated the rankings obtained
    by different video clips in the ranking question following each group of video
    clips, as well as the statistical significance between their rankings.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç¬¬ä¸€ä»½é—®å·çš„ç¬¬äºŒéƒ¨åˆ†ï¼Œæˆ‘ä»¬è®¡ç®—äº†æ¯ç»„è§†é¢‘ç‰‡æ®µåçš„æ’åé—®é¢˜æ‰€è·å¾—çš„æ’åï¼Œä»¥åŠå®ƒä»¬ä¹‹é—´çš„ç»Ÿè®¡æ˜¾è‘—æ€§ã€‚
- en: For Part II of the second questionnaire, we separately tallied the results of
    the three scoring questions after each video clip, representing the agent vehicleâ€™s
    intelligence, riskiness, and human-likeness.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç¬¬äºŒä»½é—®å·çš„ç¬¬äºŒéƒ¨åˆ†ï¼Œæˆ‘ä»¬åˆ†åˆ«ç»Ÿè®¡äº†æ¯ä¸ªè§†é¢‘ç‰‡æ®µåçš„ä¸‰é¡¹è¯„åˆ†é—®é¢˜çš„ç»“æœï¼Œä»£è¡¨ä»£ç†è½¦è¾†çš„æ™ºèƒ½ã€é£é™©æ€§å’Œç±»äººæ€§ã€‚
- en: Additionally, we scrutinized all the answers to the reasoning questions in both
    questionnaires, summarizing supports for judging the driving behaviors of the
    agent vehicles.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæˆ‘ä»¬ä»”ç»†å®¡æŸ¥äº†ä¸¤ä»½é—®å·ä¸­çš„æ‰€æœ‰æ¨ç†é—®é¢˜çš„å›ç­”ï¼Œæ€»ç»“äº†åˆ¤æ–­ä»£ç†è½¦è¾†é©¾é©¶è¡Œä¸ºçš„æ”¯æŒä¾æ®ã€‚
- en: IV-C4 Results
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C4 ç»“æœ
- en: '![Refer to caption](img/608a4cefdc2862f11df7c93b2ff524f8.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒè¯´æ˜](img/608a4cefdc2862f11df7c93b2ff524f8.png)'
- en: '(a) Frequency of riskiness rankings in different groups: demonstrations with
    different driving styles (left), feedback with different driving styles (middle-left),
    cautious driving style under different alignment methods (middle-right), and risky
    driving style under different alignment methods (right). Higher rankings indicate
    higher riskiness.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: (a) ä¸åŒç»„åˆ«çš„é£é™©æ€§æ’åé¢‘ç‡ï¼šä¸åŒé©¾é©¶é£æ ¼çš„æ¼”ç¤ºï¼ˆå·¦ï¼‰ã€ä¸åŒé©¾é©¶é£æ ¼çš„åé¦ˆï¼ˆä¸­å·¦ï¼‰ã€ä¸åŒå¯¹é½æ–¹æ³•ä¸‹çš„è°¨æ…é©¾é©¶é£æ ¼ï¼ˆä¸­å³ï¼‰ã€ä»¥åŠä¸åŒå¯¹é½æ–¹æ³•ä¸‹çš„é£é™©é©¾é©¶é£æ ¼ï¼ˆå³ï¼‰ã€‚æ’åè¶Šé«˜ï¼Œé£é™©æ€§è¶Šå¤§ã€‚
- en: '![Refer to caption](img/476435b8c1d24c118898b6e2512adc4b.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒè¯´æ˜](img/476435b8c1d24c118898b6e2512adc4b.png)'
- en: (b) Pearson correlation and significance of scores for agent vehicleâ€™s riskiness
    (R), human-likeness (H), and intelligence (I).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: (b) çš®å°”é€Šç›¸å…³ç³»æ•°åŠä»£ç†è½¦è¾†åœ¨é£é™©æ€§ï¼ˆRï¼‰ã€ç±»äººæ€§ï¼ˆHï¼‰å’Œæ™ºèƒ½ï¼ˆIï¼‰è¯„åˆ†çš„æ˜¾è‘—æ€§ã€‚
- en: 'Figure 4: Human evaluation results.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4ï¼šäººå·¥è¯„ä¼°ç»“æœã€‚
- en: We distributed two questionnaires for 3 days and received a total of 259 valid
    responses after screening, with 198 for the first questionnaire and 59 for the
    second. The driving style statistics in part I are highly diverse. With an average
    score of 0.61, 34 participants scores below -4 (suggesting a cautious driving
    style), while 37 participants scores over 5 (suggesting a risky driving style),
    indicating good representativeness of our results.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆ†å‘äº†ä¸¤ä»½é—®å·ï¼ŒæŒç»­äº†3å¤©ï¼Œç­›é€‰åå…±æ”¶åˆ°259ä»½æœ‰æ•ˆå›å¤ï¼Œå…¶ä¸­ç¬¬ä¸€ä»½é—®å·198ä»½ï¼Œç¬¬äºŒä»½é—®å·59ä»½ã€‚ç¬¬ä¸€éƒ¨åˆ†çš„é©¾é©¶é£æ ¼ç»Ÿè®¡æ•°æ®é«˜åº¦å¤šæ ·åŒ–ã€‚å¹³å‡åˆ†ä¸º0.61ï¼Œå…¶ä¸­34åå‚ä¸è€…çš„å¾—åˆ†ä½äº-4ï¼ˆè¡¨æ˜è°¨æ…é©¾é©¶é£æ ¼ï¼‰ï¼Œè€Œ37åå‚ä¸è€…çš„å¾—åˆ†é«˜äº5ï¼ˆè¡¨æ˜é£é™©é©¾é©¶é£æ ¼ï¼‰ï¼Œæ˜¾ç¤ºäº†æˆ‘ä»¬ç»“æœçš„è‰¯å¥½ä»£è¡¨æ€§ã€‚
- en: Fig. [4(a)](#S4.F4.sf1 "In Figure 4 â€£ IV-C4 Results â€£ IV-C Human Evaluation
    â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered Driver Agent") shows
    the rankings of riskiness for different video clips in each group from the first
    questionnaire, with higher rankings indicating higher riskiness.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ [4(a)](#S4.F4.sf1 "åœ¨å›¾4 â€£ IV-C4 ç»“æœ â€£ IV-C äººå·¥è¯„ä¼° â€£ IV å®éªŒ â€£ é©¾é©¶é£æ ¼å¯¹é½ç”¨äºLLMé©±åŠ¨ä»£ç†")
    æ˜¾ç¤ºäº†ç¬¬ä¸€ä»½é—®å·ä¸­æ¯ç»„ä¸åŒè§†é¢‘ç‰‡æ®µçš„é£é™©æ€§æ’åï¼Œæ’åè¶Šé«˜ï¼Œé£é™©æ€§è¶Šå¤§ã€‚
- en: In both the demonstrations and feedback groups, the rankings for DC and FC were
    significantly lower than those for other videos in the same group, indicating
    that they were perceived as the least risky. One participant explained choosing
    DC as the least risky in the Demonstration Group, noting, â€The car ran stably
    without veering left or right.â€ Another participant cited their reasoning for
    deeming FC the least risky in the Feedback Group, stating, â€It waits for the pedestrian
    ahead to pass by.â€
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¼”ç¤ºå’Œåé¦ˆç»„ä¸­ï¼ŒDCå’ŒFCçš„æ’åæ˜¾è‘—ä½äºåŒç»„å…¶ä»–è§†é¢‘ï¼Œè¡¨æ˜å®ƒä»¬è¢«è®¤ä¸ºæ˜¯é£é™©æœ€ä½çš„ã€‚ä¸€ä½å‚ä¸è€…è§£é‡Šäº†åœ¨æ¼”ç¤ºç»„ä¸­é€‰æ‹©DCä¸ºé£é™©æœ€ä½çš„åŸå› ï¼Œç§°â€œæ±½è½¦ç¨³å®šè¿è¡Œï¼Œæ²¡æœ‰å·¦å³åç¦»ã€‚â€å¦ä¸€ä½å‚ä¸è€…åœ¨åé¦ˆç»„ä¸­å°†FCè®¤ä¸ºæ˜¯é£é™©æœ€ä½çš„ç†ç”±æ˜¯ï¼Œâ€œå®ƒç­‰å¾…å‰é¢çš„è¡Œäººé€šè¿‡ã€‚â€
- en: When not-aligned, the riskiness of FN decreases compared to DN, with multiple
    participants noting DNâ€™s â€Decelerate too slowly when approaching a pedestrian
    crossing.â€ However, DN shows no significant difference when compared to either
    DR or FR, because they â€all look very riskyâ€
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä¸å¯¹é½æ—¶ï¼ŒFNçš„é£é™©æ€§ä½äºDNï¼Œå¤šä¸ªå‚ä¸è€…æŒ‡å‡ºDNçš„â€œåœ¨æ¥è¿‘è¡Œäººè¿‡è·¯ç‚¹æ—¶å‡é€Ÿè¿‡æ…¢ã€‚â€ç„¶è€Œï¼Œä¸DRæˆ–FRç›¸æ¯”ï¼ŒDNæ²¡æœ‰æ˜¾è‘—å·®å¼‚ï¼Œå› ä¸ºå®ƒä»¬â€œçœ‹èµ·æ¥éƒ½éå¸¸æœ‰é£é™©ã€‚â€
- en: In the cautious group, the ranking of riskiness goes significantly as DC  MC, indicating that
    multi-alignmentÂ has the best alignment effect, with demonstrationsÂ being the least
    effective. The majority of participants attributed the rankings to â€Driver x (DC)
    performs lane changes a bit too quickly, whereas driver y (MC) not only waits
    for pedestrians but also yields to other vehicles.â€
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è°¨æ…ç»„ä¸­ï¼Œé£é™©æ’åæ˜¾è‘—ä¸ºDC 
    MCï¼Œè¿™è¡¨æ˜å¤šé‡å¯¹é½å…·æœ‰æœ€ä½³çš„å¯¹é½æ•ˆæœï¼Œè€Œæ¼”ç¤ºæ•ˆæœæœ€å·®ã€‚å¤§å¤šæ•°å‚ä¸è€…å°†æ’åå½’å› äºâ€œé©¾é©¶å‘˜xï¼ˆDCï¼‰å˜é“ç¨å¾®å¤ªå¿«ï¼Œè€Œé©¾é©¶å‘˜yï¼ˆMCï¼‰ä¸ä»…ç­‰å¾…è¡Œäººï¼Œè¿˜ç»™å…¶ä»–è½¦è¾†è®©è·¯ã€‚â€
- en: Similarly, the demonstrationsÂ method also showed the poorest alignment effect
    in the risky group, with MR slightly better than FR but not significant.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·ï¼Œæ¼”ç¤ºæ–¹æ³•åœ¨é£é™©ç»„ä¸­ä¹Ÿæ˜¾ç¤ºå‡ºæœ€å·®çš„å¯¹é½æ•ˆæœï¼ŒMRç•¥å¥½äºFRä½†ä¸æ˜¾è‘—ã€‚
- en: Fig.Â [4(b)](#S4.F4.sf2 "In Figure 4 â€£ IV-C4 Results â€£ IV-C Human Evaluation
    â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered Driver Agent") presents
    the results of the correlation analysis among participantsâ€™ scores for riskiness,
    human-likeness, and intelligence for the same video clip in the second questionnaire.
    It can be observed that humans tend to associate higher riskiness with lower intelligence,
    and higher intelligence with greater human-likeness. Interestingly, despite cautious
    driving being safer, humans still tend to associate higher riskiness with greater
    human-likeness. One participant remarked, â€It (MR) is really like an experienced
    driver who is showing off his driving skills.â€
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾[4(b)](#S4.F4.sf2 "åœ¨å›¾4 â€£ IV-C4 ç»“æœ â€£ IV-C äººç±»è¯„ä¼° â€£ IV å®éªŒ â€£ LLMé©±åŠ¨ä»£ç†äººçš„é©¾é©¶é£æ ¼å¯¹é½")å±•ç¤ºäº†å‚ä¸è€…å¯¹åŒä¸€è§†é¢‘ç‰‡æ®µåœ¨ç¬¬äºŒæ¬¡é—®å·ä¸­çš„é£é™©æ€§ã€äººç±»ç‰¹å¾å’Œæ™ºèƒ½è¯„åˆ†çš„ç›¸å…³æ€§åˆ†æç»“æœã€‚å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œäººä»¬å€¾å‘äºå°†æ›´é«˜çš„é£é™©æ€§ä¸æ›´ä½çš„æ™ºèƒ½ç›¸å…³è”ï¼Œå°†æ›´é«˜çš„æ™ºèƒ½ä¸æ›´é«˜çš„äººç±»ç‰¹å¾ç›¸å…³è”ã€‚æœ‰è¶£çš„æ˜¯ï¼Œå°½ç®¡è°¨æ…é©¾é©¶æ›´å®‰å…¨ï¼Œäººä»¬ä»ç„¶å€¾å‘äºå°†æ›´é«˜çš„é£é™©æ€§ä¸æ›´é«˜çš„äººç±»ç‰¹å¾ç›¸å…³è”ã€‚ä¸€ä½å‚ä¸è€…è¯„è®ºè¯´ï¼Œâ€œå®ƒï¼ˆMRï¼‰ç¡®å®åƒä¸€ä¸ªç»éªŒä¸°å¯Œçš„å¸æœºåœ¨ç‚«è€€ä»–çš„é©¾é©¶æŠ€èƒ½ã€‚â€
- en: IV-C5 Findings
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C5 å‘ç°
- en: The human evaluation results indicated a clear distinction in perceived riskiness
    between different driving styles. Agents aligned with cautious driving were consistently
    rated as less risky, particularly under the multi-alignment condition, which was
    proven to be the most effective for aligning driving styles. Demonstrations alone
    showed the least effectiveness in both cautious and risky conditions. Additionally,
    there is an interesting psychological insight that despite associating cautious
    driving with safety, participants tended to equate higher cautiousness with less
    human-likeness, reflecting a complex perception of human driving behavior.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: äººç±»è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œä¸åŒé©¾é©¶é£æ ¼ä¹‹é—´åœ¨æ„ŸçŸ¥é£é™©æ€§æ–¹é¢æœ‰æ˜æ˜¾åŒºåˆ«ã€‚ä¸è°¨æ…é©¾é©¶å¯¹é½çš„ä»£ç†äººè¢«ä¸€è‡´è¯„ä¸ºé£é™©è¾ƒä½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šé‡å¯¹é½æ¡ä»¶ä¸‹ï¼Œè¿™è¢«è¯æ˜æ˜¯å¯¹é½é©¾é©¶é£æ ¼çš„æœ€æœ‰æ•ˆæ–¹å¼ã€‚ä»…é æ¼”ç¤ºåœ¨è°¨æ…å’Œé£é™©æ¡ä»¶ä¸‹çš„æ•ˆæœæœ€å·®ã€‚æ­¤å¤–ï¼Œå°½ç®¡å°†è°¨æ…é©¾é©¶ä¸å®‰å…¨å…³è”èµ·æ¥ï¼Œå‚ä¸è€…å¾€å¾€å°†æ›´é«˜çš„è°¨æ…ç¨‹åº¦ç­‰åŒäºæ›´å°‘çš„äººç±»ç‰¹å¾ï¼Œè¿™åæ˜ äº†å¯¹äººç±»é©¾é©¶è¡Œä¸ºçš„å¤æ‚æ„ŸçŸ¥ã€‚
- en: V CONCLUSIONS
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V ç»“è®º
- en: This paper presents a novel multi-alignment framework for aligning LLM-powered
    Driver Agents with human driving styles. Through a comprehensive set of experiments
    and evaluations, we successfully demonstrate that Driver Agents can be tailored
    to exhibit distinct driving stylesâ€”risky and cautiousâ€”by leveraging human driving
    data as chain-of-thought prompts. The frameworkâ€™s effectiveness is validated through
    simulation experiments in the CARLA urban traffic simulator and further corroborated
    by human evaluations.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šé‡å¯¹é½æ¡†æ¶ï¼Œç”¨äºå°† LLM é©±åŠ¨çš„é©¾é©¶ä»£ç†ä¸äººç±»é©¾é©¶é£æ ¼å¯¹é½ã€‚é€šè¿‡ä¸€å¥—å…¨é¢çš„å®éªŒå’Œè¯„ä¼°ï¼Œæˆ‘ä»¬æˆåŠŸå±•ç¤ºäº†é€šè¿‡åˆ©ç”¨äººç±»é©¾é©¶æ•°æ®ä½œä¸ºæ€ç»´é“¾æç¤ºï¼Œé©¾é©¶ä»£ç†å¯ä»¥è¢«è°ƒæ•´ä»¥å±•ç°å‡ºä¸åŒçš„é©¾é©¶é£æ ¼â€”â€”å†’é™©å’Œè°¨æ…ã€‚é€šè¿‡
    CARLA åŸå¸‚äº¤é€šæ¨¡æ‹Ÿå™¨çš„ä»¿çœŸå®éªŒéªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œå¹¶é€šè¿‡äººç±»è¯„ä¼°è¿›ä¸€æ­¥è¯å®ã€‚
- en: By illustrating the potential of LLMs in achieving nuanced human-agent alignment,
    this work opens new avenues for research into autonomous driving technologies
    that cater to individual preferences. By encoding the intricacies of human driving
    behaviors in a format accessible to language models, this work paves the way for
    more intuitive and effective human-agent alignment across a broad spectrum of
    applications beyond autonomous driving. Additionally, the insights into human
    perceptions of riskiness and human-likeness in driving styles underscore the complexity
    of aligning autonomous agents with human expectations and behaviors, highlighting
    the importance of further interdisciplinary research in this area.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å±•ç¤ºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®ç°ç»†è‡´çš„äººæœºå¯¹é½ä¸­çš„æ½œåŠ›ï¼Œæœ¬ç ”ç©¶ä¸ºç¬¦åˆä¸ªäººåå¥½çš„è‡ªåŠ¨é©¾é©¶æŠ€æœ¯å¼€è¾Ÿäº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚é€šè¿‡å°†äººç±»é©¾é©¶è¡Œä¸ºçš„å¤æ‚æ€§ç¼–ç æˆè¯­è¨€æ¨¡å‹å¯æ¥è§¦çš„æ ¼å¼ï¼Œæœ¬ç ”ç©¶ä¸ºæ›´ç›´è§‚æœ‰æ•ˆçš„äººæœºå¯¹é½é“ºå¹³äº†é“è·¯ï¼Œé€‚ç”¨äºé™¤è‡ªåŠ¨é©¾é©¶ä¹‹å¤–çš„å¹¿æ³›åº”ç”¨ã€‚æ­¤å¤–ï¼Œå¯¹äººç±»å¯¹é£é™©æ€§å’Œé©¾é©¶é£æ ¼çš„ç±»äººæ€§çš„æ„ŸçŸ¥çš„æ´å¯Ÿçªæ˜¾äº†ä½¿è‡ªåŠ¨é©¾é©¶ä»£ç†ä¸äººç±»æœŸæœ›å’Œè¡Œä¸ºå¯¹é½çš„å¤æ‚æ€§ï¼Œå¼ºè°ƒäº†åœ¨è¿™ä¸€é¢†åŸŸè¿›ä¸€æ­¥è·¨å­¦ç§‘ç ”ç©¶çš„é‡è¦æ€§ã€‚
- en: References
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] C.Â H. Song, J.Â Wu, C.Â Washington, B.Â M. Sadler, W.-L. Chao, and Y.Â Su,
    â€œLlm-planner: Few-shot grounded planning for embodied agents with large language
    models,â€ in *Proceedings of the IEEE/CVF International Conference on Computer
    Vision*, 2023, pp. 2998â€“3009.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] C.Â H. Song, J.Â Wu, C.Â Washington, B.Â M. Sadler, W.-L. Chao, å’Œ Y.Â Su, â€œllm-plannerï¼šå…·æœ‰å¤§å‹è¯­è¨€æ¨¡å‹çš„å…·èº«ä½“ä»£ç†çš„å°‘æ ·æœ¬åŸºç¡€è§„åˆ’ï¼Œâ€
    æ”¶å½•äº *IEEE/CVF å›½é™…è®¡ç®—æœºè§†è§‰å¤§ä¼šè®ºæ–‡é›†*ï¼Œ2023ï¼Œç¬¬ 2998â€“3009 é¡µã€‚'
- en: '[2] J.Â Wei, X.Â Wang, D.Â Schuurmans, M.Â Bosma, F.Â Xia, E.Â Chi, Q.Â V. Le, D.Â Zhou,
    *etÂ al.*, â€œChain-of-thought prompting elicits reasoning in large language models,â€
    *Advances in Neural Information Processing Systems*, vol.Â 35, pp. 24â€‰824â€“24â€‰837,
    2022.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] J.Â Wei, X.Â Wang, D.Â Schuurmans, M.Â Bosma, F.Â Xia, E.Â Chi, Q.Â V. Le, D.Â Zhou,
    *etÂ al.*, â€œæ€ç»´é“¾æç¤ºå¼•å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†ï¼Œâ€ *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬ 35 å·ï¼Œç¬¬ 24â€‰824â€“24â€‰837 é¡µï¼Œ2022ã€‚'
- en: '[3] X.Â Wang, J.Â Wei, D.Â Schuurmans, Q.Â Le, E.Â Chi, S.Â Narang, A.Â Chowdhery,
    and D.Â Zhou, â€œSelf-consistency improves chain of thought reasoning in language
    models,â€ *arXiv preprint arXiv:2203.11171*, 2022.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] X.Â Wang, J.Â Wei, D.Â Schuurmans, Q.Â Le, E.Â Chi, S.Â Narang, A.Â Chowdhery,
    å’Œ D.Â Zhou, â€œè‡ªä¸€è‡´æ€§æå‡è¯­è¨€æ¨¡å‹çš„æ€ç»´é“¾æ¨ç†ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2203.11171*ï¼Œ2022ã€‚'
- en: '[4] S.Â Yao, D.Â Yu, J.Â Zhao, I.Â Shafran, T.Â L. Griffiths, Y.Â Cao, and K.Â Narasimhan,
    â€œTree of thoughts: Deliberate problem solving with large language models,â€ *arXiv
    preprint arXiv:2305.10601*, 2023.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] S.Â Yao, D.Â Yu, J.Â Zhao, I.Â Shafran, T.Â L. Griffiths, Y.Â Cao, å’Œ K.Â Narasimhan,
    â€œæ€æƒ³æ ‘ï¼šä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæ·±æ€ç†Ÿè™‘çš„é—®é¢˜è§£å†³ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2305.10601*ï¼Œ2023ã€‚'
- en: '[5] L.Â Chen, O.Â Sinavski, J.Â HÃ¼nermann, A.Â Karnsund, A.Â J. Willmott, D.Â Birch,
    D.Â Maund, and J.Â Shotton, â€œDriving with llms: Fusing object-level vector modality
    for explainable autonomous driving,â€ *arXiv preprint arXiv:2310.01957*, 2023.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] L.Â Chen, O.Â Sinavski, J.Â HÃ¼nermann, A.Â Karnsund, A.Â J. Willmott, D.Â Birch,
    D.Â Maund, å’Œ J.Â Shotton, â€œä½¿ç”¨ llms é©¾é©¶ï¼šèåˆå¯¹è±¡çº§å‘é‡æ¨¡æ€ä»¥å®ç°å¯è§£é‡Šçš„è‡ªåŠ¨é©¾é©¶ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2310.01957*ï¼Œ2023ã€‚'
- en: '[6] Z.Â Xu, Y.Â Zhang, E.Â Xie, Z.Â Zhao, Y.Â Guo, K.Â K. Wong, Z.Â Li, and H.Â Zhao,
    â€œDrivegpt4: Interpretable end-to-end autonomous driving via large language model,â€
    *arXiv preprint arXiv:2310.01412*, 2023.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Z.Â Xu, Y.Â Zhang, E.Â Xie, Z.Â Zhao, Y.Â Guo, K.Â K. Wong, Z.Â Li, å’Œ H.Â Zhao,
    â€œDrivegpt4ï¼šé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¯è§£é‡Šçš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2310.01412*ï¼Œ2023ã€‚'
- en: '[7] A.Â Hu, L.Â Russell, H.Â Yeo, Z.Â Murez, G.Â Fedoseev, A.Â Kendall, J.Â Shotton,
    and G.Â Corrado, â€œGaia-1: A generative world model for autonomous driving,â€ *arXiv
    preprint arXiv:2309.17080*, 2023.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] A.Â Hu, L.Â Russell, H.Â Yeo, Z.Â Murez, G.Â Fedoseev, A.Â Kendall, J.Â Shotton,
    å’Œ G.Â Corrado, â€œGaia-1ï¼šä¸€ç§ç”¨äºè‡ªåŠ¨é©¾é©¶çš„ç”Ÿæˆä¸–ç•Œæ¨¡å‹ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2309.17080*ï¼Œ2023ã€‚'
- en: '[8] H.Â Shao, Y.Â Hu, L.Â Wang, S.Â L. Waslander, Y.Â Liu, and H.Â Li, â€œLmdrive:
    Closed-loop end-to-end driving with large language models,â€ 2023.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] H.Â Shao, Y.Â Hu, L.Â Wang, S.Â L. Waslander, Y.Â Liu, å’Œ H.Â Li, â€œLmdriveï¼šä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„é—­ç¯ç«¯åˆ°ç«¯é©¾é©¶ï¼Œâ€
    2023ã€‚'
- en: '[9] C.Â Cui, Y.Â Ma, X.Â Cao, W.Â Ye, and Z.Â Wang, â€œDrive as you speak: Enabling
    human-like interaction with large language models in autonomous vehicles,â€ in
    *Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision*,
    2024, pp. 902â€“909.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] C. Cui, Y. Ma, X. Cao, W. Ye, å’Œ Z. Wang, â€œé©¾é©¶å¦‚ä½ æ‰€è¯´: åœ¨è‡ªåŠ¨é©¾é©¶æ±½è½¦ä¸­å®ç°ç±»äººäº’åŠ¨,â€ æ”¶å½•äº
    *IEEE/CVF å†¬å­£è®¡ç®—æœºè§†è§‰åº”ç”¨ä¼šè®®è®ºæ–‡é›†*, 2024, é¡µ 902â€“909ã€‚'
- en: '[10] L.Â Wen, D.Â Fu, X.Â Li, X.Â Cai, T.Â Ma, P.Â Cai, M.Â Dou, B.Â Shi, L.Â He, and
    Y.Â Qiao, â€œDilu: A knowledge-driven approach to autonomous driving with large language
    models,â€ *arXiv preprint arXiv:2309.16292*, 2023.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] L. Wen, D. Fu, X. Li, X. Cai, T. Ma, P. Cai, M. Dou, B. Shi, L. He, å’Œ
    Y. Qiao, â€œDilu: ä¸€ç§åŸºäºçŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹è‡ªä¸»é©¾é©¶æ–¹æ³•,â€ *arXiv é¢„å°æœ¬ arXiv:2309.16292*, 2023ã€‚'
- en: '[11] W.Â Wang, J.Â Xie, C.Â Hu, H.Â Zou, J.Â Fan, W.Â Tong, Y.Â Wen, S.Â Wu, H.Â Deng,
    Z.Â Li, H.Â Tian, L.Â Lu, X.Â Zhu, X.Â Wang, Y.Â Qiao, and J.Â Dai, â€œDrivemlm: Aligning
    multi-modal large language models with behavioral planning states for autonomous
    driving,â€ 2023.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] W. Wang, J. Xie, C. Hu, H. Zou, J. Fan, W. Tong, Y. Wen, S. Wu, H. Deng,
    Z. Li, H. Tian, L. Lu, X. Zhu, X. Wang, Y. Qiao, å’Œ J. Dai, â€œDrivemlm: ä½¿å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸è¡Œä¸ºè§„åˆ’çŠ¶æ€å¯¹é½ä»¥å®ç°è‡ªä¸»é©¾é©¶,â€
    2023ã€‚'
- en: '[12] S.Â Kolekar, J.Â deÂ Winter, and D.Â Abbink, â€œHuman-like driving behaviour
    emerges from a risk-based driver model,â€ *Nature communications*, vol.Â 11, no.Â 1,
    p. 4850, 2020.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] S. Kolekar, J. de Winter, å’Œ D. Abbink, â€œåŸºäºé£é™©çš„é©¾é©¶æ¨¡å‹ä¸­å‡ºç°ç±»äººé©¾é©¶è¡Œä¸º,â€ *è‡ªç„¶é€šè®¯*, å·
    11, æœŸ 1, é¡µ 4850, 2020ã€‚'
- en: '[13] Y.Â Jin, X.Â Shen, H.Â Peng, X.Â Liu, J.Â Qin, J.Â Li, J.Â Xie, P.Â Gao, G.Â Zhou,
    and J.Â Gong, â€œSurrealdriver: Designing generative driver agent simulation framework
    in urban contexts based on large language model,â€ *arXiv preprint arXiv:2309.13193*,
    2023.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Y. Jin, X. Shen, H. Peng, X. Liu, J. Qin, J. Li, J. Xie, P. Gao, G. Zhou,
    å’Œ J. Gong, â€œSurrealdriver: åŸºäºå¤§è¯­è¨€æ¨¡å‹è®¾è®¡çš„åŸå¸‚ç¯å¢ƒç”Ÿæˆå‹é©¾é©¶ä»£ç†æ¨¡æ‹Ÿæ¡†æ¶,â€ *arXiv é¢„å°æœ¬ arXiv:2309.13193*,
    2023ã€‚'
- en: '[14] S.Â Hecker, D.Â Dai, and L.Â VanÂ Gool, â€œLearning accurate, comfortable and
    human-like driving,â€ *arXiv preprint arXiv:1903.10995*, 2019.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] S. Hecker, D. Dai, å’Œ L. Van Gool, â€œå­¦ä¹ å‡†ç¡®ã€èˆ’é€‚ä¸”ç±»äººé©¾é©¶,â€ *arXiv é¢„å°æœ¬ arXiv:1903.10995*,
    2019ã€‚'
- en: '[15] A.Â Waytz, J.Â Heafner, and N.Â Epley, â€œThe mind in the machine: Anthropomorphism
    increases trust in an autonomous vehicle,â€ *Journal of experimental social psychology*,
    vol.Â 52, pp. 113â€“117, 2014.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] A. Waytz, J. Heafner, å’Œ N. Epley, â€œæœºå™¨ä¸­çš„æ€ç»´: æ‹ŸäººåŒ–å¢åŠ å¯¹è‡ªåŠ¨é©¾é©¶æ±½è½¦çš„ä¿¡ä»»,â€ *å®éªŒç¤¾ä¼šå¿ƒç†å­¦æ‚å¿—*,
    å· 52, é¡µ 113â€“117, 2014ã€‚'
- en: '[16] J.Â Mao, Y.Â Qian, H.Â Zhao, and Y.Â Wang, â€œGpt-driver: Learning to drive
    with gpt,â€ *arXiv preprint arXiv:2310.01415*, 2023.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] J. Mao, Y. Qian, H. Zhao, å’Œ Y. Wang, â€œGpt-driver: ç”¨ GPT å­¦ä¹ é©¾é©¶,â€ *arXiv
    é¢„å°æœ¬ arXiv:2310.01415*, 2023ã€‚'
- en: '[17] L.Â Ouyang, J.Â Wu, X.Â Jiang, D.Â Almeida, C.Â L. Wainwright, P.Â Mishkin,
    C.Â Zhang, S.Â Agarwal, K.Â Slama, A.Â Ray, *etÂ al.*, â€œTraining language models to
    follow instructions with human feedback, 2022,â€ *URL https://arxiv. org/abs/2203.02155*,
    vol.Â 13, p.Â 1, 2022.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin,
    C. Zhang, S. Agarwal, K. Slama, A. Ray, *ç­‰*, â€œè®­ç»ƒè¯­è¨€æ¨¡å‹ä»¥æŒ‰ç…§äººç±»åé¦ˆæ‰§è¡ŒæŒ‡ä»¤, 2022,â€ *URL https://arxiv.
    org/abs/2203.02155*, å· 13, é¡µ 1, 2022ã€‚'
- en: '[18] D.Â Fu, X.Â Li, L.Â Wen, M.Â Dou, P.Â Cai, B.Â Shi, and Y.Â Qiao, â€œDrive like
    a human: Rethinking autonomous driving with large language models,â€ in *Proceedings
    of the IEEE/CVF Winter Conference on Applications of Computer Vision*, 2024, pp.
    910â€“919.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] D. Fu, X. Li, L. Wen, M. Dou, P. Cai, B. Shi, å’Œ Y. Qiao, â€œåƒäººä¸€æ ·é©¾é©¶: é‡æ–°æ€è€ƒä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹çš„è‡ªä¸»é©¾é©¶,â€
    æ”¶å½•äº *IEEE/CVF å†¬å­£è®¡ç®—æœºè§†è§‰åº”ç”¨ä¼šè®®è®ºæ–‡é›†*, 2024, é¡µ 910â€“919ã€‚'
- en: '[19] A.Â Zhao, D.Â Huang, Q.Â Xu, M.Â Lin, Y.-J. Liu, and G.Â Huang, â€œExpel: Llm
    agents are experiential learners,â€ *arXiv preprint arXiv:2308.10144*, 2023.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] A. Zhao, D. Huang, Q. Xu, M. Lin, Y.-J. Liu, å’Œ G. Huang, â€œExpel: LLM ä»£ç†æ˜¯ç»éªŒå­¦ä¹ è€…,â€
    *arXiv é¢„å°æœ¬ arXiv:2308.10144*, 2023ã€‚'
- en: '[20] N.Â Shinn, F.Â Cassano, A.Â Gopinath, K.Â Narasimhan, and S.Â Yao, â€œReflexion:
    Language agents with verbal reinforcement learning,â€ *Advances in Neural Information
    Processing Systems*, vol.Â 36, 2024.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] N. Shinn, F. Cassano, A. Gopinath, K. Narasimhan, å’Œ S. Yao, â€œReflexion:
    å¸¦æœ‰è¯­è¨€å¼ºåŒ–å­¦ä¹ çš„ä»£ç†,â€ *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*, å· 36, 2024ã€‚'
- en: '[21] W.Â Yao, S.Â Heinecke, J.Â C. Niebles, Z.Â Liu, Y.Â Feng, L.Â Xue, R.Â Murthy,
    Z.Â Chen, J.Â Zhang, D.Â Arpit, *etÂ al.*, â€œRetroformer: Retrospective large language
    agents with policy gradient optimization,â€ *arXiv preprint arXiv:2308.02151*,
    2023.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] W. Yao, S. Heinecke, J. C. Niebles, Z. Liu, Y. Feng, L. Xue, R. Murthy,
    Z. Chen, J. Zhang, D. Arpit, *ç­‰*, â€œRetroformer: ä½¿ç”¨ç­–ç•¥æ¢¯åº¦ä¼˜åŒ–çš„å›é¡¾æ€§å¤§è¯­è¨€ä»£ç†,â€ *arXiv é¢„å°æœ¬
    arXiv:2308.02151*, 2023ã€‚'
- en: '[22] Z.Â Yang, P.Â Li, and Y.Â Liu, â€œFailures pave the way: Enhancing large language
    models through tuning-free rule accumulation,â€ *arXiv preprint arXiv:2310.15746*,
    2023.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Z. Yang, P. Li, å’Œ Y. Liu, â€œå¤±è´¥é“ºå¹³é“è·¯: é€šè¿‡æ— è°ƒä¼˜è§„åˆ™ç§¯ç´¯æå‡å¤§è¯­è¨€æ¨¡å‹,â€ *arXiv é¢„å°æœ¬ arXiv:2310.15746*,
    2023ã€‚'
- en: '[23] X.Â Wang, W.Â Zhu, M.Â Saxon, M.Â Steyvers, and W.Â Y. Wang, â€œLarge language
    models are implicitly topic models: Explaining and finding good demonstrations
    for in-context learning,â€ in *Workshop on Efficient Systems for Foundation Models@
    ICML2023*, 2023.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] X. Wang, W. Zhu, M. Saxon, M. Steyvers, å’Œ W. Y. Wangï¼Œâ€œå¤§å‹è¯­è¨€æ¨¡å‹éšå«çš„ä¸»é¢˜æ¨¡å‹ï¼šè§£é‡Šå’Œå¯»æ‰¾é€‚åˆçš„ä¸Šä¸‹æ–‡å­¦ä¹ ç¤ºä¾‹â€ï¼Œå‘è¡¨äº
    *ICML2023é«˜æ•ˆåŸºç¡€æ¨¡å‹ç³»ç»Ÿç ”è®¨ä¼š*ï¼Œ2023å¹´ã€‚'
- en: '[24] H.Â Caesar, V.Â Bankiti, A.Â H. Lang, S.Â Vora, V.Â E. Liong, Q.Â Xu, A.Â Krishnan,
    Y.Â Pan, G.Â Baldan, and O.Â Beijbom, â€œnuscenes: A multimodal dataset for autonomous
    driving,â€ in *Proceedings of the IEEE/CVF conference on computer vision and pattern
    recognition*, 2020, pp. 11â€‰621â€“11â€‰631.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong, Q. Xu, A. Krishnan,
    Y. Pan, G. Baldan, å’Œ O. Beijbomï¼Œâ€œnuscenesï¼šä¸€ä¸ªç”¨äºè‡ªåŠ¨é©¾é©¶çš„å¤šæ¨¡æ€æ•°æ®é›†â€ï¼Œå‘è¡¨äº *IEEE/CVFè®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«ä¼šè®®è®ºæ–‡é›†*ï¼Œ2020å¹´ï¼Œç¬¬11,621â€“11,631é¡µã€‚'
- en: '[25] J.Â Geyer, Y.Â Kassahun, M.Â Mahmudi, X.Â Ricou, R.Â Durgesh, A.Â S. Chung,
    L.Â Hauswald, V.Â H. Pham, M.Â MÃ¼hlegg, S.Â Dorn, *etÂ al.*, â€œA2d2: Audi autonomous
    driving dataset,â€ *arXiv preprint arXiv:2004.06320*, 2020.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] J. Geyer, Y. Kassahun, M. Mahmudi, X. Ricou, R. Durgesh, A. S. Chung,
    L. Hauswald, V. H. Pham, M. MÃ¼hlegg, S. Dorn, *ç­‰*ï¼Œâ€œA2d2ï¼šå¥¥è¿ªè‡ªä¸»é©¾é©¶æ•°æ®é›†â€ï¼Œ*arXivé¢„å°æœ¬ arXiv:2004.06320*ï¼Œ2020å¹´ã€‚'
- en: '[26] X.Â Huang, X.Â Cheng, Q.Â Geng, B.Â Cao, D.Â Zhou, P.Â Wang, Y.Â Lin, and R.Â Yang,
    â€œThe apolloscape dataset for autonomous driving,â€ in *Proceedings of the IEEE
    conference on computer vision and pattern recognition workshops*, 2018, pp. 954â€“960.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] X. Huang, X. Cheng, Q. Geng, B. Cao, D. Zhou, P. Wang, Y. Lin, å’Œ R. Yangï¼Œâ€œApolloScapeæ•°æ®é›†ç”¨äºè‡ªåŠ¨é©¾é©¶â€ï¼Œå‘è¡¨äº
    *IEEEè®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«ä¼šè®®ç ”è®¨ä¼šè®ºæ–‡é›†*ï¼Œ2018å¹´ï¼Œç¬¬954â€“960é¡µã€‚'
- en: '[27] W.Â Zhan, L.Â Sun, D.Â Wang, H.Â Shi, A.Â Clausse, M.Â Naumann, J.Â Kummerle,
    H.Â Konigshof, C.Â Stiller, A.Â deÂ LaÂ Fortelle, *etÂ al.*, â€œInteraction dataset: An
    international, adversarial and cooperative motion dataset in interactive driving
    scenarios with semantic maps,â€ *arXiv preprint arXiv:1910.03088*, 2019.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] W. Zhan, L. Sun, D. Wang, H. Shi, A. Clausse, M. Naumann, J. Kummerle,
    H. Konigshof, C. Stiller, A. de La Fortelle, *ç­‰*ï¼Œâ€œäº’åŠ¨æ•°æ®é›†ï¼šä¸€ä¸ªå›½é™…æ€§ã€å¯¹æŠ—æ€§å’Œåˆä½œæ€§çš„äº’åŠ¨é©¾é©¶åœºæ™¯è¯­ä¹‰åœ°å›¾æ•°æ®é›†â€ï¼Œ*arXivé¢„å°æœ¬
    arXiv:1910.03088*ï¼Œ2019å¹´ã€‚'
- en: '[28] T.Â Li, A.Â Alhilal, A.Â Zhang, M.Â A. Hoque, D.Â Chatzopoulos, Z.Â Xiao, Y.Â Li,
    and P.Â Hui, â€œDriving big data: A first look at driving behavior via a large-scale
    private car dataset,â€ in *2019 IEEE 35th International Conference on Data Engineering
    Workshops (ICDEW)*.Â Â Â IEEE, 2019, pp. 61â€“68.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] T. Li, A. Alhilal, A. Zhang, M. A. Hoque, D. Chatzopoulos, Z. Xiao, Y.
    Li, å’Œ P. Huiï¼Œâ€œå¤§æ•°æ®é©±åŠ¨ï¼šé€šè¿‡å¤§è§„æ¨¡ç§äººæ±½è½¦æ•°æ®é›†é¦–æ¬¡å®¡è§†é©¾é©¶è¡Œä¸ºâ€ï¼Œå‘è¡¨äº *2019 IEEEç¬¬35å±Šå›½é™…æ•°æ®å·¥ç¨‹ç ”è®¨ä¼š (ICDEW)*ã€‚IEEEï¼Œ2019å¹´ï¼Œç¬¬61â€“68é¡µã€‚'
- en: '[29] X.Â Hu, Z.Â Zheng, D.Â Chen, X.Â Zhang, and J.Â Sun, â€œProcessing, assessing,
    and enhancing the waymo autonomous vehicle open dataset for driving behavior research,â€
    *Transportation Research Part C: Emerging Technologies*, vol. 134, p. 103490,
    2022.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] X. Hu, Z. Zheng, D. Chen, X. Zhang, å’Œ J. Sunï¼Œâ€œå¤„ç†ã€è¯„ä¼°å’Œæå‡Waymoè‡ªåŠ¨é©¾é©¶å¼€æ”¾æ•°æ®é›†ä»¥è¿›è¡Œé©¾é©¶è¡Œä¸ºç ”ç©¶â€ï¼Œ*è¿è¾“ç ”ç©¶Céƒ¨åˆ†ï¼šæ–°å…´æŠ€æœ¯*ï¼Œç¬¬134å·ï¼Œç¬¬103490é¡µï¼Œ2022å¹´ã€‚'
- en: '[30] M.Â Martin, A.Â Roitberg, M.Â Haurilet, M.Â Horne, S.Â ReiÃŸ, M.Â Voit, and R.Â Stiefelhagen,
    â€œDrive&act: A multi-modal dataset for fine-grained driver behavior recognition
    in autonomous vehicles,â€ in *Proceedings of the IEEE/CVF International Conference
    on Computer Vision*, 2019, pp. 2801â€“2810.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] M. Martin, A. Roitberg, M. Haurilet, M. Horne, S. ReiÃŸ, M. Voit, å’Œ R.
    Stiefelhagenï¼Œâ€œDrive&actï¼šä¸€ä¸ªç”¨äºç»†ç²’åº¦é©¾é©¶è¡Œä¸ºè¯†åˆ«çš„å¤šæ¨¡æ€æ•°æ®é›†â€ï¼Œå‘è¡¨äº *IEEE/CVFå›½é™…è®¡ç®—æœºè§†è§‰ä¼šè®®è®ºæ–‡é›†*ï¼Œ2019å¹´ï¼Œç¬¬2801â€“2810é¡µã€‚'
- en: '[31] T.Â Brown, B.Â Mann, N.Â Ryder, M.Â Subbiah, J.Â D. Kaplan, P.Â Dhariwal, A.Â Neelakantan,
    P.Â Shyam, G.Â Sastry, A.Â Askell, *etÂ al.*, â€œLanguage models are few-shot learners,â€
    *Advances in neural information processing systems*, vol.Â 33, pp. 1877â€“1901, 2020.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A.
    Neelakantan, P. Shyam, G. Sastry, A. Askell, *ç­‰*ï¼Œâ€œè¯­è¨€æ¨¡å‹æ˜¯å°‘æ ·æœ¬å­¦ä¹ è€…â€ï¼Œ*ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬33å·ï¼Œç¬¬1877â€“1901é¡µï¼Œ2020å¹´ã€‚'
- en: '[32] O.Â Taubman-Ben-Ari, M.Â Mikulincer, and O.Â Gillath, â€œThe multidimensional
    driving style inventoryâ€”scale construct and validation,â€ *Accident Analysis &
    Prevention*, vol.Â 36, no.Â 3, pp. 323â€“332, 2004.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] O. Taubman-Ben-Ari, M. Mikulincer, å’Œ O. Gillathï¼Œâ€œå¤šç»´é©¾é©¶é£æ ¼æ¸…å•â€”â€”é‡è¡¨æ„å»ºä¸éªŒè¯â€ï¼Œ*äº‹æ•…åˆ†æä¸é¢„é˜²*ï¼Œç¬¬36å·ï¼Œç¬¬3æœŸï¼Œç¬¬323â€“332é¡µï¼Œ2004å¹´ã€‚'
