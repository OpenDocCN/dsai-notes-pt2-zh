- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:38:23'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Interactive Agents: Simulating Counselor-Client Psychological Counseling via
    Role-Playing LLM-to-LLM Interactions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.15787](https://ar5iv.labs.arxiv.org/html/2408.15787)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Huachuan Qiu [1234-5678-9012](https://orcid.org/1234-5678-9012 "ORCID identifier")
    ¹ Zhejiang University² School of Engineering, Westlake UniversityHangzhouZhejiangChina
    [qiuhuachuan@westlake.edu.cn](mailto:qiuhuachuan@westlake.edu.cn)  and  Zhenzhong
    Lan [1234-5678-9012](https://orcid.org/1234-5678-9012 "ORCID identifier") School
    of Engineering, Westlake UniversityHangzhouZhejiangChina [lanzhenzhong@westlake.edu.cn](mailto:lanzhenzhong@westlake.edu.cn)(2024)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Virtual counselors powered by large language models (LLMs) aim to create interactive
    support systems that effectively assist clients struggling with mental health
    challenges. To replicate counselor-client conversations, researchers have built
    an online mental health platform that allows professional counselors to provide
    clients with text-based counseling services for about an hour per session. Notwithstanding
    its effectiveness, challenges exist as human annotation is time-consuming, cost-intensive,
    privacy-protected, and not scalable. To address this issue and investigate the
    applicability of LLMs in psychological counseling conversation simulation, we
    propose a framework that employs two LLMs via role-playing for simulating counselor-client
    interactions. Our framework involves two LLMs, one acting as a client equipped
    with a specific and real-life user profile and the other playing the role of an
    experienced counselor, generating professional responses using integrative therapy
    techniques. We implement both the counselor and the client by zero-shot prompting
    the GPT-4 model. In order to assess the effectiveness of LLMs in simulating counselor-client
    interactions and understand the disparities between LLM- and human-generated conversations,
    we evaluate the synthetic data from various perspectives. We begin by assessing
    the client’s performance through automatic evaluations. Next, we analyze and compare
    the disparities between dialogues generated by the LLM and those generated by
    professional counselors. Furthermore, we conduct extensive experiments to thoroughly
    examine the performance of our LLM-based counselor trained with synthetic interactive
    dialogues by benchmarking against state-of-the-art models for mental health.
  prefs: []
  type: TYPE_NORMAL
- en: 'Interactive Agents, LLM Simulation, Dialogue System, Role-playing, Synthetic
    Data, Dialogue Evaluation, Psychological Counseling^†^†copyright: rightsretained^†^†journalyear:
    2024^†^†doi: XXXXXXX.XXXXXXX^†^†conference: WSDM; June 03–05, 2024; Woodstock,
    NY^†^†isbn: 978-1-4503-XXXX-X/24/06^†^†ccs: Computing methodologies Discourse,
    dialogue and pragmatics'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since the birth of ELIZA (Weizenbaum, [1966](#bib.bib47)), the community of
    conversational agents (CAs) (Li et al., [2023b](#bib.bib25)) has strived to create
    interactive and supportive AI that effectively assists clients struggling with
    mental health challenges. Recent advancements (Liu et al., [2023](#bib.bib27);
    Qiu et al., [2023a](#bib.bib35), [b](#bib.bib37)) in dialogue systems for psychological
    counseling have been successful to some extent in achieving this goal by generating
    helpful and safe responses and engaging in back-and-forth interactions with clients
    to facilitate exploration, gain insight, take action, and ultimately heal themselves.
    Existing work has built an online mental health platform that allows professional
    counselors to provide clients with text-based counseling services (Li et al.,
    [2023a](#bib.bib23)). Furthermore, research efforts attempted to explore transforming
    long-text single-turn counseling dialogues or anonymized psychological counseling
    reports into multi-turn ones (Qiu et al., [2023a](#bib.bib35); Zhang et al., [2024a](#bib.bib52);
    Chen et al., [2023](#bib.bib10)).
  prefs: []
  type: TYPE_NORMAL
- en: Challenge. Despite the effectiveness of previous efforts in this domain, several
    drawbacks exist. One major challenge (Liu et al., [2023](#bib.bib27); Li et al.,
    [2023a](#bib.bib23)) in real-life counselor-client interactions is maintaining
    a large team of counselors and clients to generate a substantial number of conversations.
    Such a process can be time-consuming, cost-intensive, privacy-sensitive, and not
    scalable. Additionally, in many cases, the counselor cannot effectively help clients
    tackle their mental health issues that are outside of their background knowledge
    (Hill, [2020](#bib.bib17)). For example, a counselor who has never experienced
    a love affair before cannot explore love affair issues as effectively as a counselor
    who has. Another challenge (Zhang et al., [2024a](#bib.bib52); Qiu et al., [2023a](#bib.bib35);
    Chen et al., [2023](#bib.bib10)) is that even though many research efforts utilize
    LLMs to transform long-text single-turn counseling dialogues or anonymized psychological
    counseling reports into multi-turn ones, this exciting approach ignores real-life
    interactions between the counselor and the client. Furthermore, the LLM prematurely
    knows all the client’s mental health problems from a god’s-eye view rather than
    exploring and understanding the client’s issues gradually, as in an actual counseling
    scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Motivation. Interactive simulacra (Park et al., [2023](#bib.bib32); Dai et al.,
    [2024](#bib.bib11); Grossmann et al., [2023](#bib.bib16); Abbasiantaeb et al.,
    [2024](#bib.bib2)) is an important emerging research frontier for back-and-forth
    interaction development and evaluation. The motivation for developing a framework
    utilizing LLMs to simulate counselor-client interactions stems from the need to
    address significant challenges faced by existing research efforts. By leveraging
    LLMs, the proposed framework aims to create a scalable, efficient, and privacy-conscious
    solution that can simulate professional counseling sessions. The innovative approach
    of using two LLMs in a role-playing scenario—one as the client with a specific
    and real-life user profile and the other as an experienced counselor employing
    integrative therapy techniques—presents a promising method to generate synthetic
    data. This data can be used to benchmark and enhance the performance of AI-driven
    mental health support systems. The ultimate goal is to offer a viable alternative
    to traditional methods, ensuring broader access to practical mental health support
    while maintaining the quality and depth of human-generated interactions. Therefore,
    it is crucial to explore automatic approaches that can generate simulated dialogues,
    reducing the dependency on human participants and making the process more efficient
    and scalable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our Approach. In this work, we aim to explore LLMs’ effectiveness in simulating
    a psychological counseling session between an experienced counselor and a client
    seeking help for a mental disorder, problem, or chief complaint, wherein the client
    is predefined with a user profile in a conversational setting. To this aim, we
    replicate the counselor-client conversational simulation by replacing both human
    participants with interactive agents, enabling us to effectively evaluate and
    compare the performance of LLMs with human participants. This work leads us to
    our first research question, RQ1: How can we employ LLMs to generate such simulated
    conversations effectively and automatically? We answer this question by proposing
    a role-playing LLM-to-LLM interaction framework where an LLM-based client aims
    to seek help, and the LLM-based counselor helps the client explore their own values
    and beliefs, gain insight, and make positive changes in their lives. We implement
    both counselor and client by zero-shot prompting the GPT-4 model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using interactive agents in this setting leads us to the following two questions:
    RQ2: How can we evaluate the role of LLMs in a counselor-client simulation? Moreover,
    RQ3: How do LLM- and human-generated dialogues compare? To address these questions:'
  prefs: []
  type: TYPE_NORMAL
- en: (1) We first conduct an extensive independent evaluation of the client, measuring
    its fidelity of role-playing and group diversity. To this aim, we conduct a comparison
    analysis of role-following, discovering that the user profile significantly influences
    the client’s generated utterances. Further, we find that simulated clients’ diversity
    is comparable to actual clients.
  prefs: []
  type: TYPE_NORMAL
- en: (2) We then evaluate the performance of the counselor. To this aim, we adopt
    the widely used Observer-rated Short version of the Working Alliance Inventory
    (WAI-O-S) (Form et al., [2000](#bib.bib14); Bayerl et al., [2022](#bib.bib6))
    to assess the dialogue quality generated by counselor guidance.
  prefs: []
  type: TYPE_NORMAL
- en: (3) Finally, we conduct extensive experiments to thoroughly examine the performance
    of the dialogue system fine-tuned with our synthetic data by benchmarking against
    state-of-the-art models for mental health. We find that our dialogue system significantly
    outperforms existing state-of-the-art models, even including the model trained
    with real-life counseling dialogues.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our Contributions. Importantly, LLM-generated dialogues are of high quality.
    In sum, our contributions can be presented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We prompt LLMs to mimic counselor-client interaction in psychological counseling
    in a zero-shot prompting paradigm and propose an LLM-generated dataset called
    SimPsyDial.¹¹1Code, data, and models are available at [https://github.com/qiuhuachuan/interactive-agents](https://github.com/qiuhuachuan/interactive-agents)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We propose and perform a comprehensive automatic evaluation framework for evaluating
    the effectiveness of LLM-based counselor-client simulation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We fine-tune two popular open-source large language models with 7B parameters.
    We compare our dialogue systems with existing state-of-the-art models for mental
    health and find out that our dialogue model achieves the best performance among
    them. Meanwhile, we open-source our dialogue models to enhance the community development
    in mental health.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2\. Method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1\. Problem Definition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our experimental setup primarily focuses on simulating a psychological counseling
    dialogue, where an LLM-based counselor interacts with an LLM-based client seeking
    help to overcome mental health issues. First, we define the LLM-based client as
    $\Omega$ and initiated by the LLM-based client.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. Task Formulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To evaluate the planning capability and counseling depth of LLM-based counselors,
    we propose to simulate the entire conversation between an LLM-based counselor
    and an LLM-based client. Here, we leverage long descriptions of client mental
    health issues collected from a publicly accessible online platform to simulate
    LLM-based clients using large language models. For each client’s description of
    a mental health issue, we provide it as a user profile to a large language model
    and ask it to simulate a client with a provided mental health issue talking to
    an LLM-based counselor in a simulator environment. The LLM-based client mimics
    an actual client who maintains the same conversational style, stating specific
    topics and concerns and discussing life events and emotions. Then, we generate
    a conversation between this LLM-based client and the LLM-based counselor. For
    convenience, we start the generation by picking the client to go first with the
    utterance of ”Hello.” We let them talk for up to 50 turns, which is larger than
    the average conversation turns during a formal counseling session, or until the
    LLM-based counselor outputs an end token that we predefined.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/596b630333cb6324e167b9663a9a03ca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1\. The overall architecture of our simulation framework. Left panel:
    construction of client pool. Middle panel: data collection with interactive simulation.
    Right panel: model training.'
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall architecture of our simulation framework. Left panel: construction
    of client pool. Middle panel: data collection with interactive simulation. Right
    panel: model training.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.3\. Simulation Framework Overview
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In order to have a better understanding of RQ1, we propose an LLM-based simulation
    framework. Figure [1](#S2.F1 "Figure 1 ‣ 2.2\. Task Formulation ‣ 2\. Method ‣
    Interactive Agents: Simulating Counselor-Client Psychological Counseling via Role-Playing
    LLM-to-LLM Interactions") illustrates the overall architecture of our simulation
    method, showcasing the interactions between the two LLMs. Once we finish data
    collection, we can verify RQ2\. After that, we can train our dialogue systems,
    as shown in the right panel in Figure [1](#S2.F1 "Figure 1 ‣ 2.2\. Task Formulation
    ‣ 2\. Method ‣ Interactive Agents: Simulating Counselor-Client Psychological Counseling
    via Role-Playing LLM-to-LLM Interactions"), to further analyze RQ3.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8c85ab67a8fda6c56587d6753e9205e3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2\. The prompt for client simulation. For the Chinese version, please
    refer to our GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: Prompt for client simulation.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7c56282f39efd4633369ef10903916bf.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3\. The prompt for counselor simulation. For the Chinese version, please
    refer to our GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: Prompt for counselor simulation.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4\. Client Simulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Generally, different clients often have different user profiles, which mainly
    reflect on their mental health issues. Therefore, the first step we need to do
    is to construct a pool of clients with different mental health issues. Here, the
    user profile $P^{\Omega}$ denotes the description of mental health issues, a detailed
    statement describing the client’s disorder, symptom, problem, and chief complaint.
    To this aim, we propose to extract the user’s long post from an open-sourced single-turn
    dialogue dataset, PsyQA (Sun et al., [2021](#bib.bib41)), which is collected from
    an online professional psychological platform²²2https://www.xinli001.com/qa, and
    only retain the user post exceeding 300 Chinese characters. The left panel in
    Figure [1](#S2.F1 "Figure 1 ‣ 2.2\. Task Formulation ‣ 2\. Method ‣ Interactive
    Agents: Simulating Counselor-Client Psychological Counseling via Role-Playing
    LLM-to-LLM Interactions") shows the construction of the client pool. This article
    presents the client simulation prompt in Figure [2](#S2.F2 "Figure 2 ‣ 2.3\. Simulation
    Framework Overview ‣ 2\. Method ‣ Interactive Agents: Simulating Counselor-Client
    Psychological Counseling via Role-Playing LLM-to-LLM Interactions"). To validate
    the research questions proposed in our paper, we set 1000 different user posts
    as the client pool. In addition, we establish another 100 different user posts
    as the help-out test set for assessing dialogue systems.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.5\. Counselor Simulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Research has shown that all mainstream types of psychotherapy are equally effective
    (Wampold, [2013](#bib.bib43)), and no differences have been found between individual
    and group treatments (Piper, [2008](#bib.bib34); Hill, [2020](#bib.bib17)). This
    conclusion is humorously called the ”dodo bird verdict,” meaning all therapies
    are winners. Therefore, we propose to build an experienced counselor based on
    the three-stage model with integrative therapy, which facilitates exploration,
    insight, and action. The theoretical foundation of counselor simulation in this
    paper is heavily influenced by integrating diverse therapeutic principles as conceptualized
    by Hill (Hill, [2020](#bib.bib17)). The theory of the three-stage model, including
    exploration, insight, and action, corresponds to client-centered therapy (Rogers,
    [1946](#bib.bib38)), psychodynamic therapy (Warren, [1998](#bib.bib46)), and cognitive
    behavioral therapy (Hofmann et al., [2012](#bib.bib18)), respectively. This integrative
    therapy framework, grounded in philosophical consistency, ensures that our simulations
    are robust, multifaceted, and responsive to the varied needs of clients. Hence,
    this three-stage model is the cornerstone of our counselor simulation framework.
    Each stage is aligned with a different therapeutic approach, providing a structured
    yet adaptable pathway for client engagement and progress. The present paper presents
    the prompt for counselor simulation in Figure [3](#S2.F3 "Figure 3 ‣ 2.3\. Simulation
    Framework Overview ‣ 2\. Method ‣ Interactive Agents: Simulating Counselor-Client
    Psychological Counseling via Role-Playing LLM-to-LLM Interactions").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Ending Interaction. To avoid infinite interactions between the LLM-based client
    and counselor and ensure the quality of the simulated dialogues, we propose a
    set of criteria for ending interaction, which is presented in the dashed box in
    Figure [1](#S2.F1 "Figure 1 ‣ 2.2\. Task Formulation ‣ 2\. Method ‣ Interactive
    Agents: Simulating Counselor-Client Psychological Counseling via Role-Playing
    LLM-to-LLM Interactions"). During each interaction, we check whether the LLM-based
    counselor’s response meets the ending interaction criteria in each turn.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Response Refinement. To ensure that a response generated by the LLM-based counselor
    is naturally and structurally sound, we employ a validation step called $\sigma^{\Psi}$
    is supposed to be concise and quickly understood in our setting, sometimes the
    LLM-based counselor generates a lengthy response in one go, unlike in a real-life
    setting. To address this issue, we consider a response if it adheres to the following
    criteria: (i) it should not exceed 200 Chinese characters in length, and (ii)
    it should not contain a newline character or enumerated items (e.g., 1, 2, 3).
    This simple yet effective validation helps to filter lengthy and superabundant
    responses.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.6\. Experimental Setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In our experiments, we adopt GPT-4³³3The model we use is gpt-4-1106-preview,
    with training data up to Apr 2023. as our base LLM for simulating client and counselor.
    In our preliminary experiments, we explore using other LLMs, such as GPT-3.5 (Brown
    et al., [2020](#bib.bib9)), GLM-4 (GLM et al., [2024](#bib.bib15)), DeepSeek-V2-Chat
    (DeepSeek-AI, [2024b](#bib.bib13)), and Qwen1.5-110B-Chat (Bai et al., [2023](#bib.bib4)),
    as client and counselor. However, we find that GPT-4 (OpenAI, [2024](#bib.bib30))
    is the only LLM that can better mimic the client and counselor in a human-like
    way. Other models fail in this task by generating either lengthy utterances or
    short interaction turns, which fall far short of real-world settings. In our simulation
    framework, we set the patience parameter, $\sigma_{T}$, to a fixed value of 50,
    which means the interaction breaks after a maximum of 50 turns.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Simulation Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'SimPsyDial Dataset. We first introduce our dataset, SimPsyDial, for simulation
    evaluation using the simulation framework described in $\S$[2.3](#S2.SS3 "2.3\.
    Simulation Framework Overview ‣ 2\. Method ‣ Interactive Agents: Simulating Counselor-Client
    Psychological Counseling via Role-Playing LLM-to-LLM Interactions"). To collect
    SimPsyDial, we use GPT-4 to implement LLM-based counselor and client. SimPsyDial
    consists of 1000 dialogues with an average of 13 turns per conversation. This
    paper presents statistics of SimPsyDial in Table [1](#S3.T1 "Table 1 ‣ 3\. Simulation
    Evaluation ‣ Interactive Agents: Simulating Counselor-Client Psychological Counseling
    via Role-Playing LLM-to-LLM Interactions"), alongside those of the real counselor-client
    conversations, RealPsyDial. Next, we will answer RQ2 from the perspective of the
    client and counselor point by point.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 1\. Statistics of the collected dialogues by simulating counselor-client
    psychological counseling with the LLM-based counselor and client.
  prefs: []
  type: TYPE_NORMAL
- en: '|  | RealPsyDial | SimPsyDial |'
  prefs: []
  type: TYPE_TB
- en: '| # Conversations | 550 | 1000 |'
  prefs: []
  type: TYPE_TB
- en: '| Avg. Turns per Conversation | 40 | 13 |'
  prefs: []
  type: TYPE_TB
- en: '| # Client Utterances | 22253 | 12948 |'
  prefs: []
  type: TYPE_TB
- en: '| # Counselor Utterances | 22418 | 12948 |'
  prefs: []
  type: TYPE_TB
- en: '| Avg. Len. of Client Utterances | 34.5 | 54.1 |'
  prefs: []
  type: TYPE_TB
- en: '| Avg. Len. of Counselor Utterances | 26.1 | 70.8 |'
  prefs: []
  type: TYPE_TB
- en: 3.1\. Client Evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Generally, any clients who seek help to overcome mental health issues are good
    clients, even if they do not show any resistance in the counseling session. The
    simulated clients are expected to behave consistently with their user profiles
    and emulate real clients in counseling sessions. We analyze the simulated clients’
    behaviors from two aspects: vocabulary overlap rate and semantic consistency.
    Furthermore, we present the diversity between simulated clients and real clients.
    Next, we will elaborate on these aspects one by one.'
  prefs: []
  type: TYPE_NORMAL
- en: Vocabulary Overlap Rate. Given a user profile $P^{\Omega}$, the LLM-based client
    will interact with the LLM-based counselor and thus produce a dialogue session.
    Therefore, considering such a generated counseling session, the following equation
    computes the vocabulary overlap rate between the client’s utterance and the corresponding
    user profile.
  prefs: []
  type: TYPE_NORMAL
- en: '| (1) |  | $\frac{\left&#124;\mathrm{Set}(V(S^{\Omega}))\cap\mathrm{Set}(V(P^{\Omega}))\right&#124;}{\left&#124;\mathrm{Set}(V(P^{\Omega}))\right&#124;}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $V(S^{\Omega})$ is an operation that removes duplicate elements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Results. The distribution of vocabulary overlap rates is presented in Figure
    [4](#S3.F4 "Figure 4 ‣ 3.1\. Client Evaluation ‣ 3\. Simulation Evaluation ‣ Interactive
    Agents: Simulating Counselor-Client Psychological Counseling via Role-Playing
    LLM-to-LLM Interactions")a. We observe that the mapping group (mean = 0.406; std
    = 0.083) has a significantly larger vocabulary overlap rate (two-tailed t-test;
    $p$-value ¡ 0.001) than the random group (mean = 0.284; std = 0.060). These results
    suggest that the LLM-based client can better follow its user profile when conversing
    with the LLM-based counselor.'
  prefs: []
  type: TYPE_NORMAL
- en: Semantic Consistency. To further evaluate the degree of client simulation, we
    propose to use semantic consistency. We utilize text embeddings for quantitative
    analysis. To obtain the text embedding of a given string, we use the BAAI/bge-m3
    model⁴⁴4https://huggingface.co/BAAI/bge-m3, which accepts a maximum of 8192 tokens.
    Each string is encoded into a 1024-dimensional vector. For example, to compute
    the cosine similarity between two different strings, we can obtain
  prefs: []
  type: TYPE_NORMAL
- en: '| (2) |  | $\mathrm{cos}(P^{\Omega},S^{\Omega})=\frac{e_{p}\cdot e_{s}}{\left\&#124;e_{p}\right\&#124;\left\&#124;e_{s}\right\&#124;}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $e_{p}$ denote the text embeddings of the user profile and the concatenation
    of the client’s utterances, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Results. The distribution of cosine similarity is presented in Figure [4](#S3.F4
    "Figure 4 ‣ 3.1\. Client Evaluation ‣ 3\. Simulation Evaluation ‣ Interactive
    Agents: Simulating Counselor-Client Psychological Counseling via Role-Playing
    LLM-to-LLM Interactions")b. We observe that the mapping group (mean = 0.791; std
    = 0.056) has a significantly larger semantic similarity (two-tailed t-test; $p$-value
    ¡ 0.001) compared to the random group (mean = 0.570; std = 0.059). These results
    further suggest that the LLM-based client significantly depends on its user profile
    when conversing with the LLM-based counselor.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8c485b57cd9c68cec77193b0ff348a4e.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4\. Consistency of client simulation.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: Consistency of client simulation.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/601f3d98b5654e71b2e9f80b5fad3547.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5\. Topic distribution between RealPsyDial and SimPsyDial.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: Topic distribution between RealPsyDial and SimPsyDial.
  prefs: []
  type: TYPE_NORMAL
- en: Diversity of Clients. The diversity of counseling sessions is often determined
    by the diversity of clients. Based on this, we adopt the setting established by
    the RealPsyDial dataset (Li et al., [2023a](#bib.bib23)), which serves as a widely
    recognized dataset collected from real clients and professional counselors. We
    utilize the method proposed by Qiu et al. (Qiu et al., [2023a](#bib.bib35)) that
    prompts Qwen1.5-110B-Chat in a zero-shot prompting paradigm with a collection
    of 60 topics to generate topics related to clients’ chief complaints. To ensure
    the generation result is effective and consistent, we prompt Qwen1.5-110B-Chat
    to produce topics for each concatenation of the client’s utterances through three
    rounds and record the information entropy of topic distribution in each round.
  prefs: []
  type: TYPE_NORMAL
- en: 'Results. The topic distribution between RealPsyDial and SimPsyDial is presented
    in Figure [5](#S3.F5 "Figure 5 ‣ 3.1\. Client Evaluation ‣ 3\. Simulation Evaluation
    ‣ Interactive Agents: Simulating Counselor-Client Psychological Counseling via
    Role-Playing LLM-to-LLM Interactions"). We observe that the information entropy
    of topics of clients’ chief complaints in SimPsyDial (mean = 4.526; std = 0.009)
    is slightly lower (two-tailed t-test; avg. $p$-value = 0.055 ¿ 0.05) than that
    in RealPsyDial (mean = 4.875; std = 0.020). Furthermore, we find that the topic
    distribution (topic and its corresponding frequency) between RealPsyDial and SimPsyDial
    is almost similar, demonstrating that our SimPsyDial is close to RealPsyDial with
    respective of the client side.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2\. Counselor Evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Motivated by the prevalence and effectiveness of using an LLM as a judge and
    quality assessment of psychological counseling sessions with the Working Alliance
    Inventory (WAI), we propose to use LLMs as observers to evaluate the quality of
    counseling sessions. The prompt for WAI assessment is presented in Figure [6](#S3.F6
    "Figure 6 ‣ 3.2\. Counselor Evaluation ‣ 3\. Simulation Evaluation ‣ Interactive
    Agents: Simulating Counselor-Client Psychological Counseling via Role-Playing
    LLM-to-LLM Interactions"). For questionnaires and guidelines we use in our paper,
    please refer to previous research work (Form et al., [2000](#bib.bib14); Bayerl
    et al., [2022](#bib.bib6)). To ensure that the generation result is effective
    and consistent, we prompt Qwen1.5-110B-Chat to produce scores for each conversation
    through three rounds and calculate the average score of three rounds per questionnaire.'
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S3.F6.1.1.1.1.1.1.pic1" class="ltx_picture" height="218.72" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,218.72) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject width="556.69"
    height="191.16" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">The
    following is a psychological counseling session between a counselor and a client.
    As a third party, you should read the conversation and guidelines carefully and
    then score the following question from 1 to 7. Start of the conversation
  prefs: []
  type: TYPE_NORMAL
- en: '{conversation}'
  prefs: []
  type: TYPE_NORMAL
- en: 'End of the conversation Questionnaire: {questionnaire}'
  prefs: []
  type: TYPE_NORMAL
- en: Start of guidelines for the questionnaire
  prefs: []
  type: TYPE_NORMAL
- en: '{guidelines}'
  prefs: []
  type: TYPE_NORMAL
- en: End of guidelines for the questionnaire You should answer the questionnaire
    and provide a score that should be exactly a number from 1 to 7\. Your score is</foreignobject></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6\. Prompt for scoring the dialogue with the LLM as a judge.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: Prompt for scoring the dialogue with the LLM as a judge.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5e94997bcc777b5fb05428884a965560.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7\. Comparisons of WAI-O-S scores between RealPsyDial and SimPsyDial.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: Comparisons of WAI-O-S scores between RealPsyDial and SimPsyDial.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/24b3ecdd2c6a2a5d16bae932baa2c3d7.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8\. Snippet examples of dialogue sessions between RealPsyDial and SimPsyDial.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: Snippet examples of dialogue sessions between RealPsyDial and SimPsyDial.
  prefs: []
  type: TYPE_NORMAL
- en: 'Results. We present the comparisons of WAI-O-S scores between RealPsyDial and
    SimPsyDial, as shown in Figure [7](#S3.F7 "Figure 7 ‣ 3.2\. Counselor Evaluation
    ‣ 3\. Simulation Evaluation ‣ Interactive Agents: Simulating Counselor-Client
    Psychological Counseling via Role-Playing LLM-to-LLM Interactions"). The goal
    score for SimPsyDial dataset (mean = 6.045; std = 0.265) is significantly higher
    ($p$-value ¡ 0.001) than that for RealPsyDial dataset (mean = 5.807; std = 0.507).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The simPsyDial dataset exhibits higher mean scores in goal, task, and bond
    categories than the RealPsyDial dataset, indicating superior and more consistent
    performance. The SimPsyDial dataset shows significantly lower standard deviations
    across all three categories, suggesting the data quality with reduced variability
    and more concentration. Furthermore, we present examples of dialogue session between
    RealPsyDial and SimPsyDial, as shown in Figure [8](#S3.F8 "Figure 8 ‣ 3.2\. Counselor
    Evaluation ‣ 3\. Simulation Evaluation ‣ Interactive Agents: Simulating Counselor-Client
    Psychological Counseling via Role-Playing LLM-to-LLM Interactions").'
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Dialogue System
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 4.1\. Mathematical Formulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To train a dialogue system for psychological counseling, we need to split each
    full dialogue $d\sim\mathcal{D}$ using supervised learning, i.e., maximum likelihood
    estimates (MLE):'
  prefs: []
  type: TYPE_NORMAL
- en: '| (3) |  | $J_{\mathrm{SFT}}(\theta)=\mathbb{E}_{(h_{t},u_{t}^{\Psi})\sim\mathcal{D}}\left[\log\pi_{\theta}(u_{t}^{\Psi}\mid
    h_{t})\right]$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\pi_{\theta}$.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2\. Experimental Setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Comparison Models. MeChat (Qiu et al., [2023a](#bib.bib35)) is a model trained
    on the SmileChat dataset, which is generated by rewriting single-turn dialogues
    into multi-turn ones using ChatGPT. SoulChat (Chen et al., [2023](#bib.bib10))
    is a model trained on the SoulChatCorpus (multi-turn) dataset, which is generated
    by rewriting the single-turn SoulChatCorpus into multi-turn dialogues using ChatGPT
    and GPT-4\. PsyChat (Qiu et al., [2024](#bib.bib36)) is a model trained on RealPsyDial
    with Low-Rank Adaptation fine-tuning. CPsyCounX (Zhang et al., [2024b](#bib.bib53))
    is a model trained on CPsyCounD, a dataset generated from psychological counseling
    reports.
  prefs: []
  type: TYPE_NORMAL
- en: Backbone Model. To validate the dialogue quality of our collected dataset, we
    conduct fine-tuning experiments on two popular large language models, including
    Qwen2-7B-Instruct (Yang et al., [2024](#bib.bib50)) and deepseek-llm-7b-chat (DeepSeek-AI,
    [2024a](#bib.bib12)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Format of Training Data. To meet the data format requirements for instruction-based
    fine-tuning, we split the dialogue into multiple training samples, each concluding
    with the counselor’s last utterance. Additionally, we incorporate the system prompt
    (as detailed in Figure [3](#S2.F3 "Figure 3 ‣ 2.3\. Simulation Framework Overview
    ‣ 2\. Method ‣ Interactive Agents: Simulating Counselor-Client Psychological Counseling
    via Role-Playing LLM-to-LLM Interactions")) as a prefix to the dialogue messages,
    adhering to OpenAI’s data format.'
  prefs: []
  type: TYPE_NORMAL
- en: Full Fine-tuning. Considering that enough data and compute resources are available,
    full fine-tuning can achieve the best performance for the target task since every
    parameter can be optimized. Therefore, our paper uses full fine-tuning to train
    the dialogue system.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameters. In this paper, all experiments are conducted on the NVIDIA
    A100 80G GPUs for model training. During model fine-tuning, we use 4 GPUs, set
    the training batch size to 1 per device, and set the step of gradient accumulation
    to 2, meaning that the gradient from every two steps would be accumulated and
    then used for parameter update. The learning rate is 1e-5\. We adopt the cosine-type
    learning rate scheduler to adjust the learning rate throughout the training process.
    The entire training will span across two epochs. To accelerate the training and
    balance model performance, we also enable using 16-bit half-precision floating
    point numbers. To avoid errors in the evaluation stage, we set the size of the
    validation set as 0.001\. This paper implements the fine-tuning based on LLaMA
    Factory (Zheng et al., [2024b](#bib.bib58)), an efficient model-tuning framework.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1bfd29a90ec3536bf1b50e7d6709e097.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9\. Interaction with multiple counselors.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: An illustration of interaction with multiple counselors.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3\. Interaction with Multiple Counselors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Automatic evaluation cannot faithfully reflect the quality of dialogue systems,
    especially in psychological counseling. Human evaluation is still more widely
    used and acknowledged. However, recruiting professional counselors to assess various
    virtual counselors is costly and not reproducible for the evaluation community.
    Therefore, to ensure high-quality evaluation, we consider human annotators and
    LLMs as judges (Zheng et al., [2023](#bib.bib56)) to evaluate model responses
    given a dialogue history. Nevertheless, effectively and efficiently identifying
    the optimal model among many remains a challenge. Motivated by a previous study
    (Zhang et al., [2023](#bib.bib54)), we designed an evaluation platform to interact
    with multiple virtual counselors simultaneously, as shown in Figure [9](#S4.F9
    "Figure 9 ‣ 4.2\. Experimental Setup ‣ 4\. Dialogue System ‣ Interactive Agents:
    Simulating Counselor-Client Psychological Counseling via Role-Playing LLM-to-LLM
    Interactions"). We randomly select two comparison models and one of our fine-tuned
    models as evaluation targets. We also present a set of evaluation standards for
    human and LLM annotators. For more details, please refer to our GitHub repository.'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation Platform. Asking human annotators to act as clients is a challenging
    and costly task. To address this, we propose to directly adopt virtual clients
    powered by GPT-4\. For assessing each counseling session, a virtual client is
    randomly selected from the test set containing 100 different clients. This client
    will interact with three virtual counselors, with the only intervention being
    selecting the best response from among the candidates. A chatbot is considered
    to have superior performance if its responses are chosen over those of others
    more frequently. To ensure a fair comparison, we maintain the same dialogue history
    for all the chatbots at each turn. To facilitate this process, we record each
    turn’s message from the annotator and the selected response in the dialogue history.
    It is important to note that the chatbot’s name is not disclosed to annotators,
    and the order of the messages is shuffled before being displayed on the platform
    to prevent potential annotation bias.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2\. Automatic evaluation with an LLM as a judge. We use DeepSeek-V2-Chat
    as our LLM judge.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | # Dialogues | # Total Selection | Avg. Score ($\uparrow$) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| MeChat | 300 | 560 | 1.87 | 792.04 |'
  prefs: []
  type: TYPE_TB
- en: '| SoulChat | 300 | 253 | 0.84 | 724.26 |'
  prefs: []
  type: TYPE_TB
- en: '| PsyChat | 300 | 427 | 1.42 | 729.20 |'
  prefs: []
  type: TYPE_TB
- en: '| CPsyCounX | 300 | 722 | 2.41 | 1187.81 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; SimPsyBot &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; (backbone model: &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; deepseek-llm-7b-chat) &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 600 | 5185 | 8.64 | 1895.27 |'
  prefs: []
  type: TYPE_TB
- en: '| MeChat | 300 | 618 | 2.06 | 869.60 |'
  prefs: []
  type: TYPE_TB
- en: '| SoulChat | 300 | 243 | 0.81 | 772.16 |'
  prefs: []
  type: TYPE_TB
- en: '| PsyChat | 300 | 474 | 1.58 | 803.46 |'
  prefs: []
  type: TYPE_TB
- en: '| CPsyCounX | 300 | 760 | 2.53 | 1288.04 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; SimPsyBot &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; (backbone model: &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Qwen2-7B-Instruct) &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 600 | 4773 | 7.96 | 1758.05 |'
  prefs: []
  type: TYPE_TB
- en: Table 3\. Human evaluation with 5 experts as judges.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | # Dialogues | # Total Selection | Avg. Score ($\uparrow$) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| MeChat | 96 | 264 | 2.75 | 1352.80 |'
  prefs: []
  type: TYPE_TB
- en: '| SoulChat | 95 | 200 | 2.11 | 1221.64 |'
  prefs: []
  type: TYPE_TB
- en: '| PsyChat | 102 | 333 | 3.26 | 1355.53 |'
  prefs: []
  type: TYPE_TB
- en: '| CPsyCounX | 107 | 167 | 1.56 | 1113.52 |'
  prefs: []
  type: TYPE_TB
- en: '| SimPsyBot | 200 | 1570 | 7.85 | 1871.97 |'
  prefs: []
  type: TYPE_TB
- en: For human evaluation, we recruit five professional counselors and require them
    to use our designed evaluation platform to assess which one is the best among
    the three generated responses given a shared dialogue history. By clicking the
    ”Start” button, the platform will randomly select a user profile to instantiate
    a virtual client from the help-out test set. For convenience, we start the conversation
    by picking the client to go first with the utterance of ”Hello.” Subsequently,
    three shuffled responses will be generated by three virtual counselors. The professional
    counselor is required to pick the best response. Once selected, the virtual client
    will continue the conversation, and another three responses will be displayed
    on the platform for the professional counselor to select. The professional counselor
    may use the ”Terminate” button to stop the current conversation, or the selected
    response meets the criteria for ending the interaction. Each professional counselor
    is required to evaluate 40 different dialogues, and each dialogue lasts more than
    five turns.
  prefs: []
  type: TYPE_NORMAL
- en: For automatic evaluation, the response selector is just replaced by the LLM
    as a judge. Therefore, the whole process will automatically proceed without any
    human intervention until the selected response meets the criteria for ending the
    interaction.
  prefs: []
  type: TYPE_NORMAL
- en: The average number of response selections per dialogue by professional counselors
    determines each chatbot’s score, which is determined as $score_{\mathrm{avg}}=\frac{\mathrm{\#\
    Total\ Selection}}{\mathrm{\#\ Dialogue}}$. Furthermore, we also adopt the Elo
    rating to evaluate the model performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Advantages. The proposed evaluation has two main advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Centered conversation and comparative voting. Conversing with each chatbot independently
    will inevitably, therefore, have some bias. In addition, a conversation history
    often has one-to-many responses, so traditional automatic metrics are unsuitable
    for this situation. Therefore, to address these challenges, our proposed simultaneous
    chat with multiple chatbots not only accelerates the conversation model evaluation
    and reduces the cost of the annotators but also mitigates the evaluation bias
    and improves the fairness of the evaluation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comprehensive assessment. Rather than considering conventional multi-dimensional
    metrics like empathy, informativeness, and helpfulness (e.g., because not every
    response needs to be empathetic), determining which response is more suitable
    for the dialogue history among many is a more comprehensive, efficient, and effective
    evaluation method.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Results. We present the results of automatic and human evaluation in Table
    [2](#S4.T2 "Table 2 ‣ 4.3\. Interaction with Multiple Counselors ‣ 4\. Dialogue
    System ‣ Interactive Agents: Simulating Counselor-Client Psychological Counseling
    via Role-Playing LLM-to-LLM Interactions") and [3](#S4.T3 "Table 3 ‣ 4.3\. Interaction
    with Multiple Counselors ‣ 4\. Dialogue System ‣ Interactive Agents: Simulating
    Counselor-Client Psychological Counseling via Role-Playing LLM-to-LLM Interactions"),
    respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: SimPsyBot vs. Other Models. SimPsyBot consistently outperforms other models
    in both automatic and human evaluations, demonstrating strong conversational abilities
    and high user satisfaction. In automatic evaluations, its average scores (8.64
    and 7.96) and Elo ratings (1895.27 and 1758.05) significantly exceed those of
    other models. Similarly, in human evaluations, it leads with an impressive average
    score of 7.85 and an Elo rating of 1871.97\. These results indicate that SimPsyBot
    has a comprehensive advantage in dialogue tasks and is the best choice from both
    a system perspective and in terms of human feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Automatic vs. Human Evaluations. Some models exhibit differences in performance
    between automatic and human evaluations. For example, PsyChat performs significantly
    better in human evaluations (3.26) than automatic evaluations (1.42 and 1.58).
    This result suggests that automatic scoring may not fully capture PsyChat’s capabilities,
    whereas it excels under human expert judgment. In contrast, SimPsyBot maintains
    a leading position in both types of evaluations, showcasing its consistently superior
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. RELATED WORK
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 5.1\. Interactive Simulacra
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Large language models have already entered the interactive simulacra era (Park
    et al., [2023](#bib.bib32); Xie et al., [2024](#bib.bib48); Park et al., [2022](#bib.bib33);
    Bernard and Balog, [2024b](#bib.bib8); Lu et al., [2024](#bib.bib28)). Interactive
    agents have been extensively studied within the fields of information retrieval
    (IR) and conversational agents (CA) (Tu et al., [2023](#bib.bib42); Owoicho et al.,
    [2023](#bib.bib31); Balog and Zhai, [2024](#bib.bib5)), enabling users to engage
    in multi-turn dialogues with agents to clarify and refine their queries and retrieve
    pertinent information. Due to the powerful potential of LLMs, such as generating
    coherent and contextually appropriate language similar to how humans communicate,
    interactive agents are ideal for human simulation in the natural language paradigm.
    Therefore, a myriad of research efforts of human simulation has been proposed
    to model human behaviors in various applications, including education (Hu et al.,
    [2024](#bib.bib19); Lee et al., [2023](#bib.bib22), [2024](#bib.bib21); Zhang
    et al., [2024c](#bib.bib55); Tu et al., [2023](#bib.bib42)), recommender systems
    (Afzali et al., [2023](#bib.bib3); Bernard and Balog, [2024a](#bib.bib7); Huang
    et al., [2024](#bib.bib20)), social science (Xie et al., [2024](#bib.bib48); Dai
    et al., [2024](#bib.bib11)), medicine (Li et al., [2024a](#bib.bib26); Schmidgall
    et al., [2024](#bib.bib39); Yan et al., [2024](#bib.bib49)), and psychological
    counseling (Li et al., [2023b](#bib.bib25); Wang et al., [2024b](#bib.bib44),
    [a](#bib.bib45)). One such application in education, many researchers are mainly
    focusing on applying LLMs to assist teaching tasks, such as instructional design
    (Hu et al., [2024](#bib.bib19); Zheng et al., [2024a](#bib.bib57)), educational
    assessment (Li et al., [2024b](#bib.bib24); Lee et al., [2024](#bib.bib21)), classroom
    simulation (Sonkar et al., [2023](#bib.bib40); Lee et al., [2023](#bib.bib22);
    Markel et al., [2023](#bib.bib29); Zhang et al., [2024c](#bib.bib55); Tu et al.,
    [2023](#bib.bib42); Yue et al., [2024](#bib.bib51)).
  prefs: []
  type: TYPE_NORMAL
- en: This paper also presents some studies about interactive simulacra in psychological
    counseling. Li et al. (Li et al., [2023b](#bib.bib25)) conducted a systematic
    review and found that AI-based conversational agents can promote mental health
    and well-being. To better assess the performance of LLM-based counselors, Wang
    et al. (Wang et al., [2024b](#bib.bib44)) introduced ClientCAST, a client-centered
    approach for assessing the efficacy of LLM therapists through simulated client
    interactions. Further, Wang et al. (Wang et al., [2024a](#bib.bib45)) introduced
    a patient simulation framework utilizing large language models for training mental
    health professionals in cognitive behavior therapy. To the best of our knowledge,
    our work is the first to utilize LLMs as annotator-free counselor-client simulators
    in psychological counseling, where the client is randomly selected from a real-life
    client pool.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2\. Conversational Agents for Mental Health
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LLMs see extensive use across multiple application domains. LLMs have become
    powerful and intelligent agents across our daily lives, providing vast benefits
    from education (Hu et al., [2024](#bib.bib19); Lee et al., [2023](#bib.bib22),
    [2024](#bib.bib21); Zhang et al., [2024c](#bib.bib55); Tu et al., [2023](#bib.bib42))
    to recommender systems (Afzali et al., [2023](#bib.bib3); Bernard and Balog, [2024a](#bib.bib7);
    Huang et al., [2024](#bib.bib20)), social science (Xie et al., [2024](#bib.bib48))
    to medicine (Li et al., [2024a](#bib.bib26); Schmidgall et al., [2024](#bib.bib39);
    Yan et al., [2024](#bib.bib49)), and mental health (Qiu et al., [2023b](#bib.bib37);
    Li et al., [2023b](#bib.bib25); Wang et al., [2024b](#bib.bib44), [a](#bib.bib45)).
    In this paper, we mainly focus on conversational agents for mental health.
  prefs: []
  type: TYPE_NORMAL
- en: The utilization of LLMs in psychological counseling and mental health support
    is an emerging research area (Qiu et al., [2023a](#bib.bib35); Chen et al., [2023](#bib.bib10);
    Qiu et al., [2024](#bib.bib36); Zhang et al., [2024a](#bib.bib52)). At the very
    beginning, Qiu et al. (Qiu et al., [2023b](#bib.bib37)) introduced a benchmark
    for assessing the safety of model responses in counseling conversations. Subsequently,
    many dialogue models, including English and Chinese, are developed to assist clients
    in healing themselves in mental health. Liu et al. (Liu et al., [2023](#bib.bib27))
    developed ChatCounselor, which is trained with 260 in-depth interviews while focusing
    on English. Furthermore, a series of dialogue models focusing on Chinese is proposed.
    MeChat (Qiu et al., [2023a](#bib.bib35)) is a model trained on the SmileChat dataset,
    which is generated by rewriting single-turn dialogues into multi-turn ones using
    ChatGPT. SoulChat (Chen et al., [2023](#bib.bib10)) is a model trained on the
    SoulChatCorpus (multi-turn) dataset, which is generated by rewriting the single-turn
    SoulChatCorpus into multi-turn dialogues using ChatGPT and GPT-4\. PsyChat (Qiu
    et al., [2024](#bib.bib36)) is a model trained on RealPsyDial with Low-Rank Adaptation
    fine-tuning. CPsyCounX (Zhang et al., [2024b](#bib.bib53)) is a model trained
    on CPsyCounD, a dataset generated from psychological counseling reports. Based
    on these findings, our study will explore the potential of LLM-based counselor-client
    simulation to investigate privacy-free counseling dialogues and facilitate advancements
    in dialogue models in psychological counseling.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Conclusion and Future Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This paper introduces a framework using two LLMs in a role-playing setup to
    simulate counselor-client interactions. One LLM acts as a client with a real-life
    profile, while the other plays an experienced counselor using integrative therapy
    techniques. Both roles are implemented via zero-shot prompting with the GPT-4
    model. We evaluate the effectiveness of these LLMs by comparing their simulated
    dialogues with those of professional counselors. Additionally, we conduct experiments
    to benchmark the LLM-based counselor against state-of-the-art mental health models.
    Our research highlights the potential of LLMs in enhancing psychological counseling
    simulations and client engagement.
  prefs: []
  type: TYPE_NORMAL
- en: In this paper, we identify three main directions for future work. First, we
    plan to incorporate resistance characteristics into client simulation and conduct
    a more comprehensive empirical study to analyze the influence of client resistance
    on generated dialogues. Second, we also plan to simulate a second counselor-client
    counseling session based on the first session and analyze how the client changes
    in the second session. Third, we aim to build a more human-like dialogue dataset.
    To this end, we propose to optimize the prompt and use retrieval-augmented generation
    (RAG) with real-life counseling sessions to construct verisimilar counselors and
    clients.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Ethical Considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Important: Our research is reviewed and approved by the Westlake University
    Institutional Ethics Committee (20211013LZZ001). Our study explores the potential
    of LLMs to simulate counselors and clients in psychological counseling but does
    NOT recommend their use as a substitute for psychological treatment without professional
    supervision.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering the recent great attention on interactive simulacra and vast interest
    in utilizing them for various research directions, we are confident that exploring
    such a direction is meaningful because it unveils the potential of LLMs, while
    at the same time exhibiting their potential ethical considerations. Below, we
    will show some of these concerns that need to be considered and addressed in this
    research area:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Inappropriate advice: LLMs are trained on vast amounts of data and thus have
    somewhat undesirable patterns regarding their training data. The synthetic data
    generated by interactive simulacra could, in turn, carry wrong advice or suggestions
    and further deepen wrong behaviors, including inappropriate or unprofessional
    advice. For example, reading books is good advice for most clients, but this suggestion
    may be inappropriate for a client who has a visual defect.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Client simulation: Due to the training techniques involving instruction-following
    and reinforcement learning from human feedback, using an LLM to simulate clients
    potentially ignores the social impact on clients, such as family, job, and even
    suicide risk, which would lead to increased resistance in counseling for real
    clients.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Counselor simulation: Using LLMs to simulate counselors has a limitation on
    counseling depth. In a real-life setting, the counselor often speaks less than
    the client, and the counselor could explore the client’s cockles of the heart,
    just like peeling onions.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Environmental impact: The training and inference of LLMs involve significant
    computational resources, which leads to energy consumption and potentially has
    a negative environmental impact.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: While simulating counselor-client interactions using LLMs has various advantages,
    we should pay more attention to carefully considering and addressing the potential
    ethical implications in future work.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abbasiantaeb et al. (2024) Zahra Abbasiantaeb, Yifei Yuan, Evangelos Kanoulas,
    and Mohammad Aliannejadi. 2024. Let the LLMs Talk: Simulating Human-to-Human Conversational
    QA via Zero-Shot LLM-to-LLM Interactions. In *Proceedings of the 17th ACM International
    Conference on Web Search and Data Mining* (Merida, Mexico) *(WSDM ’24)*. Association
    for Computing Machinery, New York, NY, USA, 8–17. [https://doi.org/10.1145/3616855.3635856](https://doi.org/10.1145/3616855.3635856)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Afzali et al. (2023) Jafar Afzali, Aleksander Mark Drzewiecki, Krisztian Balog,
    and Shuo Zhang. 2023. UserSimCRS: a user simulation toolkit for evaluating conversational
    recommender systems. In *Proceedings of the Sixteenth ACM International Conference
    on Web Search and Data Mining*. 1160–1163.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bai et al. (2023) Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong
    Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang
    Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui
    Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang,
    Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian
    Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang,
    Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan
    Zhou, and Tianhang Zhu. 2023. Qwen Technical Report. arXiv:2309.16609 [cs.CL]
    [https://arxiv.org/abs/2309.16609](https://arxiv.org/abs/2309.16609)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Balog and Zhai (2024) Krisztian Balog and ChengXiang Zhai. 2024. Tutorial on
    User Simulation for Evaluating Information Access Systems on the Web. In *Companion
    Proceedings of the ACM on Web Conference 2024*. 1254–1257.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayerl et al. (2022) Sebastian P Bayerl, Gabriel Roccabruna, Shammur Absar Chowdhury,
    Tommaso Ciulli, Morena Danieli, Korbinian Riedhammer, and Giuseppe Riccardi. 2022.
    What can speech and language tell us about the working alliance in psychotherapy.
    *arXiv preprint arXiv:2206.08835* (2022).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bernard and Balog (2024a) Nolwenn Bernard and Krisztian Balog. 2024a. Identifying
    Breakdowns in Conversational Recommender Systems using User Simulation. In *Proceedings
    of the 6th ACM Conference on Conversational User Interfaces*. 1–10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bernard and Balog (2024b) Nolwenn Bernard and Krisztian Balog. 2024b. Towards
    a Formal Characterization of User Simulation Objectives in Conversational Information
    Access. In *Proceedings of the 2024 ACM SIGIR International Conference on Theory
    of Information Retrieval*. 185–193.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
    Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario
    Amodei. 2020. Language Models are Few-Shot Learners. arXiv:2005.14165 [cs.CL]
    [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2023) Yirong Chen, Xiaofen Xing, Jingkai Lin, Huimin Zheng, Zhenyu
    Wang, Qi Liu, and Xiangmin Xu. 2023. Soulchat: Improving llms’ empathy, listening,
    and comfort abilities through fine-tuning with multi-turn empathy conversations.
    In *Findings of the Association for Computational Linguistics: EMNLP 2023*. 1170–1183.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dai et al. (2024) Gordon Dai, Weijia Zhang, Jinhan Li, Siqi Yang, Chidera Onochie
    lbe, Srihas Rao, Arthur Caetano, and Misha Sra. 2024. Artificial Leviathan: Exploring
    Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory.
    arXiv:2406.14373 [cs.AI] [https://arxiv.org/abs/2406.14373](https://arxiv.org/abs/2406.14373)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DeepSeek-AI (2024a) DeepSeek-AI. 2024a. DeepSeek LLM: Scaling Open-Source Language
    Models with Longtermism. arXiv:2401.02954 [cs.CL] [https://arxiv.org/abs/2401.02954](https://arxiv.org/abs/2401.02954)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DeepSeek-AI (2024b) DeepSeek-AI. 2024b. DeepSeek-V2: A Strong, Economical,
    and Efficient Mixture-of-Experts Language Model. arXiv:2405.04434 [cs.CL] [https://arxiv.org/abs/2405.04434](https://arxiv.org/abs/2405.04434)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Form et al. (2000) Working Alliance Inventory-Observer Form, IV Revision, Andrew
    Darchuk, Victor Wang, David Weibel, Jennifer Fende, Timothy Anderson, and Adam
    Horvath. 2000. Department of Psychology Ohio University December 11, 2000. (2000).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GLM et al. (2024) Team GLM, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang,
    Da Yin, Diego Rojas, Guanyu Feng, Hanlin Zhao, Hanyu Lai, Hao Yu, Hongning Wang,
    Jiadai Sun, Jiajie Zhang, Jiale Cheng, Jiayi Gui, Jie Tang, Jing Zhang, Juanzi
    Li, Lei Zhao, Lindong Wu, Lucen Zhong, Mingdao Liu, Minlie Huang, Peng Zhang,
    Qinkai Zheng, Rui Lu, Shuaiqi Duan, Shudan Zhang, Shulin Cao, Shuxun Yang, Weng Lam
    Tam, Wenyi Zhao, Xiao Liu, Xiao Xia, Xiaohan Zhang, Xiaotao Gu, Xin Lv, Xinghan
    Liu, Xinyi Liu, Xinyue Yang, Xixuan Song, Xunkai Zhang, Yifan An, Yifan Xu, Yilin
    Niu, Yuantao Yang, Yueyan Li, Yushi Bai, Yuxiao Dong, Zehan Qi, Zhaoyu Wang, Zhen
    Yang, Zhengxiao Du, Zhenyu Hou, and Zihan Wang. 2024. ChatGLM: A Family of Large
    Language Models from GLM-130B to GLM-4 All Tools. arXiv:2406.12793'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grossmann et al. (2023) Igor Grossmann, Matthew Feinberg, Dawn C Parker, Nicholas A
    Christakis, Philip E Tetlock, and William A Cunningham. 2023. AI and the transformation
    of social science research. *Science* 380, 6650 (2023), 1108–1109.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hill (2020) Clara E Hill. 2020. *Helping skills: Facilitating exploration,
    insight, and action*. American Psychological Association.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hofmann et al. (2012) Stefan G Hofmann, Anu Asnaani, Imke JJ Vonk, Alice T
    Sawyer, and Angela Fang. 2012. The efficacy of cognitive behavioral therapy: A
    review of meta-analyses. *Cognitive therapy and research* 36 (2012), 427–440.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hu et al. (2024) Bihao Hu, Longwei Zheng, Jiayi Zhu, Lishan Ding, Yilei Wang,
    and Xiaoqing Gu. 2024. Teaching Plan Generation and Evaluation With GPT-4: Unleashing
    the Potential of LLM in Instructional Design. *IEEE Transactions on Learning Technologies*
    17 (2024), 1471–1485. [https://doi.org/10.1109/TLT.2024.3384765](https://doi.org/10.1109/TLT.2024.3384765)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2024) Chen Huang, Peixin Qin, Yang Deng, Wenqiang Lei, Jiancheng
    Lv, and Tat-Seng Chua. 2024. Concept–An Evaluation Protocol on Conversation Recommender
    Systems with System-and User-centric Factors. *arXiv preprint arXiv:2404.03304*
    (2024).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee et al. (2024) Unggi Lee, Jiyeong Bae, Dohee Kim, Sookbun Lee, Jaekwon Park,
    Taekyung Ahn, Gunho Lee, Damji Stratton, and Hyeoncheol Kim. 2024. Language Model
    Can Do Knowledge Tracing: Simple but Effective Method to Integrate Language Model
    and Knowledge Tracing Task. arXiv:2406.02893 [cs.CL] [https://arxiv.org/abs/2406.02893](https://arxiv.org/abs/2406.02893)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee et al. (2023) Unggi Lee, Sanghyeok Lee, Junbo Koh, Yeil Jeong, Haewon Jung,
    Gyuri Byun, Jewoong Moon, Jieun Lim, and † HyeoncheolKim. 2023. Generative Agent
    for Teacher Training: Designing Educational Problem-Solving Simulations with Large
    Language Model-based Agents for Pre-Service Teachers. In *NeurIPS’23 Workshop
    on Generative AI for Education (GAIED)*. NeurIPS. [https://api.semanticscholar.org/CorpusID:266874743](https://api.semanticscholar.org/CorpusID:266874743)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2023a) Anqi Li, Lizhi Ma, Yaling Mei, Hongliang He, Shuai Zhang,
    Huachuan Qiu, and Zhenzhong Lan. 2023a. Understanding Client Reactions in Online
    Mental Health Counseling. In *Proceedings of the 61st Annual Meeting of the Association
    for Computational Linguistics (Volume 1: Long Papers)*, Anna Rogers, Jordan Boyd-Graber,
    and Naoaki Okazaki (Eds.). Association for Computational Linguistics, Toronto,
    Canada, 10358–10376. [https://doi.org/10.18653/v1/2023.acl-long.577](https://doi.org/10.18653/v1/2023.acl-long.577)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2024b) Haoxuan Li, Jifan Yu, Yuanxin Ouyang, Zhuang Liu, Wenge Rong,
    Juanzi Li, and Zhang Xiong. 2024b. Explainable Few-shot Knowledge Tracing. arXiv:2405.14391 [cs.AI]
    [https://arxiv.org/abs/2405.14391](https://arxiv.org/abs/2405.14391)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2023b) Han Li, Renwen Zhang, Yi-Chieh Lee, Robert E Kraut, and David C
    Mohr. 2023b. Systematic review and meta-analysis of AI-based conversational agents
    for promoting mental health and well-being. *NPJ Digital Medicine* 6, 1 (2023),
    236.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2024a) Junkai Li, Siyu Wang, Meng Zhang, Weitao Li, Yunghwei Lai,
    Xinhui Kang, Weizhi Ma, and Yang Liu. 2024a. Agent hospital: A simulacrum of hospital
    with evolvable medical agents. *arXiv preprint arXiv:2405.02957* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023) June M Liu, Donghao Li, He Cao, Tianhe Ren, Zeyi Liao, and
    Jiamin Wu. 2023. Chatcounselor: A large language models for mental health support.
    *arXiv preprint arXiv:2309.15461* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2024) Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff
    Clune, and David Ha. 2024. The AI Scientist: Towards Fully Automated Open-Ended
    Scientific Discovery. arXiv:2408.06292 [cs.AI] [https://arxiv.org/abs/2408.06292](https://arxiv.org/abs/2408.06292)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Markel et al. (2023) Julia M Markel, Steven G Opferman, James A Landay, and
    Chris Piech. 2023. Gpteach: Interactive ta training with gpt-based students. In
    *Proceedings of the tenth acm conference on learning@ scale*. 226–236.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI (2024) OpenAI. 2024. GPT-4 Technical Report. arXiv:2303.08774 [cs.CL]
    [https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Owoicho et al. (2023) Paul Owoicho, Ivan Sekulic, Mohammad Aliannejadi, Jeffrey
    Dalton, and Fabio Crestani. 2023. Exploiting simulated user feedback for conversational
    search: Ranking, rewriting, and beyond. In *Proceedings of the 46th International
    ACM SIGIR Conference on Research and Development in Information Retrieval*. 632–642.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Park et al. (2023) Joon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S. Bernstein. 2023. Generative Agents: Interactive
    Simulacra of Human Behavior. arXiv:2304.03442 [cs.HC] [https://arxiv.org/abs/2304.03442](https://arxiv.org/abs/2304.03442)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Park et al. (2022) Joon Sung Park, Lindsay Popowski, Carrie J. Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S. Bernstein. 2022. Social Simulacra: Creating
    Populated Prototypes for Social Computing Systems. arXiv:2208.04024 [cs.HC] [https://arxiv.org/abs/2208.04024](https://arxiv.org/abs/2208.04024)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Piper (2008) William E Piper. 2008. Underutilization of short-term group therapy:
    Enigmatic or understandable? *Psychotherapy Research* 18, 2 (2008), 127–138.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qiu et al. (2023a) Huachuan Qiu, Hongliang He, Shuai Zhang, Anqi Li, and Zhenzhong
    Lan. 2023a. Smile: Single-turn to multi-turn inclusive language expansion via
    chatgpt for mental health support. *arXiv preprint arXiv:2305.00450* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qiu et al. (2024) Huachuan Qiu, Anqi Li, Lizhi Ma, and Zhenzhong Lan. 2024.
    PsyChat: A Client-Centric Dialogue System for Mental Health Support. In *2024
    27th International Conference on Computer Supported Cooperative Work in Design
    (CSCWD)*. 2979–2984. [https://doi.org/10.1109/CSCWD61410.2024.10580641](https://doi.org/10.1109/CSCWD61410.2024.10580641)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qiu et al. (2023b) Huachuan Qiu, Tong Zhao, Anqi Li, Shuai Zhang, Hongliang
    He, and Zhenzhong Lan. 2023b. A benchmark for understanding dialogue safety in
    mental health support. In *CCF International Conference on Natural Language Processing
    and Chinese Computing*. Springer, 1–13.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rogers (1946) Carl R Rogers. 1946. Significant aspects of client-centered therapy.
    *American psychologist* 1, 10 (1946), 415–422.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schmidgall et al. (2024) Samuel Schmidgall, Rojin Ziaei, Carl Harris, Eduardo
    Reis, Jeffrey Jopling, and Michael Moor. 2024. AgentClinic: a multimodal agent
    benchmark to evaluate AI in simulated clinical environments. *arXiv preprint arXiv:2405.07960*
    (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sonkar et al. (2023) Shashank Sonkar, Naiming Liu, Debshila Mallick, and Richard
    Baraniuk. 2023. CLASS: A Design Framework for Building Intelligent Tutoring Systems
    Based on Learning Science principles. In *Findings of the Association for Computational
    Linguistics: EMNLP 2023*, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association
    for Computational Linguistics, Singapore, 1941–1961. [https://doi.org/10.18653/v1/2023.findings-emnlp.130](https://doi.org/10.18653/v1/2023.findings-emnlp.130)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2021) Hao Sun, Zhenru Lin, Chujie Zheng, Siyang Liu, and Minlie
    Huang. 2021. Psyqa: A chinese dataset for generating long counseling text for
    mental health support. *arXiv preprint arXiv:2106.01702* (2021).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tu et al. (2023) Shangqing Tu, Zheyuan Zhang, Jifan Yu, Chunyang Li, Siyu Zhang,
    Zijun Yao, Lei Hou, and Juanzi Li. 2023. LittleMu: Deploying an Online Virtual
    Teaching Assistant via Heterogeneous Sources Integration and Chain of Teach Prompts.
    In *Proceedings of the 32nd ACM International Conference on Information and Knowledge
    Management*. 4843–4849.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wampold (2013) Bruce E Wampold. 2013. *The great psychotherapy debate: Models,
    methods, and findings*. Routledge.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2024b) Jiashuo Wang, Yang Xiao, Yanran Li, Changhe Song, Chunpu
    Xu, Chenhao Tan, and Wenjie Li. 2024b. Towards a Client-Centered Assessment of
    LLM Therapists by Client Simulation. *arXiv preprint arXiv:2406.12266* (2024).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2024a) Ruiyi Wang, Stephanie Milani, Jamie C. Chiu, Jiayin Zhi,
    Shaun M. Eack, Travis Labrum, Samuel M. Murphy, Nev Jones, Kate Hardy, Hong Shen,
    Fei Fang, and Zhiyu Zoey Chen. 2024a. PATIENT-$\Psi$: Using Large Language Models
    to Simulate Patients for Training Mental Health Professionals. arXiv:2405.19660 [cs.CL]
    [https://arxiv.org/abs/2405.19660](https://arxiv.org/abs/2405.19660)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Warren (1998) C Seth Warren. 1998. Models of brief psychodynamic therapy: A
    comparative approach. *Psychology* (1998).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weizenbaum (1966) Joseph Weizenbaum. 1966. ELIZA—a computer program for the
    study of natural language communication between man and machine. *Commun. ACM*
    9, 1 (jan 1966), 36–45. [https://doi.org/10.1145/365153.365168](https://doi.org/10.1145/365153.365168)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xie et al. (2024) Chengxing Xie, Canyu Chen, Feiran Jia, Ziyu Ye, Kai Shu, Adel
    Bibi, Ziniu Hu, Philip Torr, Bernard Ghanem, and Guohao Li. 2024. Can Large Language
    Model Agents Simulate Human Trust Behaviors? arXiv:2402.04559 [cs.AI] [https://arxiv.org/abs/2402.04559](https://arxiv.org/abs/2402.04559)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yan et al. (2024) Weixiang Yan, Haitian Liu, Tengxiao Wu, Qian Chen, Wen Wang,
    Haoyuan Chai, Jiayi Wang, Weishan Zhao, Yixin Zhang, Renjun Zhang, et al. 2024.
    ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the
    Real World. *arXiv preprint arXiv:2406.13890* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2024) An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang
    Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran
    Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang,
    Jianxin Ma, Jianxin Yang, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang
    Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni,
    Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai
    Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng,
    Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Xuejing Liu,
    Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui,
    Zhenru Zhang, Zhifang Guo, and Zhihao Fan. 2024. Qwen2 Technical Report. arXiv:2407.10671 [cs.CL]
    [https://arxiv.org/abs/2407.10671](https://arxiv.org/abs/2407.10671)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yue et al. (2024) Murong Yue, Wijdane Mifdal, Yixuan Zhang, Jennifer Suh, and
    Ziyu Yao. 2024. MathVC: An LLM-Simulated Multi-Character Virtual Classroom for
    Mathematics Education. arXiv:2404.06711 [cs.CL] [https://arxiv.org/abs/2404.06711](https://arxiv.org/abs/2404.06711)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2024a) Chenhao Zhang, Renhao Li, Minghuan Tan, Min Yang, Jingwei
    Zhu, Di Yang, Jiahao Zhao, Guancheng Ye, Chengming Li, and Xiping Hu. 2024a. CPsyCoun:
    A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for
    Chinese Psychological Counseling. arXiv:2405.16433 [cs.CL] [https://arxiv.org/abs/2405.16433](https://arxiv.org/abs/2405.16433)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2024b) Chenhao Zhang, Renhao Li, Minghuan Tan, Min Yang, Jingwei
    Zhu, Di Yang, Jiahao Zhao, Guancheng Ye, Chengming Li, and Xiping Hu. 2024b. CPsyCoun:
    A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for
    Chinese Psychological Counseling. arXiv:2405.16433 [cs.CL] [https://arxiv.org/abs/2405.16433](https://arxiv.org/abs/2405.16433)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2023) Jing Zhang, Xiaokang Zhang, Daniel Zhang-Li, Jifan Yu,
    Zijun Yao, Zeyao Ma, Yiqi Xu, Haohua Wang, Xiaohan Zhang, Nianyi Lin, Sunrui Lu,
    Juanzi Li, and Jie Tang. 2023. GLM-Dialog: Noise-tolerant Pre-training for Knowledge-grounded
    Dialogue Generation. In *Proceedings of the 29th ACM SIGKDD Conference on Knowledge
    Discovery and Data Mining* (Long Beach, CA, USA) *(KDD ’23)*. Association for
    Computing Machinery, New York, NY, USA, 5564–5575. [https://doi.org/10.1145/3580305.3599832](https://doi.org/10.1145/3580305.3599832)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2024c) Zheyuan Zhang, Daniel Zhang-Li, Jifan Yu, Linlu Gong, Jinchang
    Zhou, Zhiyuan Liu, Lei Hou, and Juanzi Li. 2024c. Simulating Classroom Education
    with LLM-Empowered Agents. *arXiv preprint arXiv:2406.19226* (2024).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zheng et al. (2023) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, Hao Zhang,
    Joseph E. Gonzalez, and Ion Stoica. 2023. Judging LLM-as-a-Judge with MT-Bench
    and Chatbot Arena. In *Thirty-seventh Conference on Neural Information Processing
    Systems Datasets and Benchmarks Track*. [https://openreview.net/forum?id=uccHPGDlao](https://openreview.net/forum?id=uccHPGDlao)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zheng et al. (2024a) Ying Zheng, Xueyi Li, Yaying Huang, Qianru Liang, Teng
    Guo, Mingliang Hou, Boyu Gao, Mi Tian, Zitao Liu, and Weiqi Luo. 2024a. Automatic
    Lesson Plan Generation via Large Language Models with Self-critique Prompting.
    In *International Conference on Artificial Intelligence in Education*. Springer,
    163–178.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zheng et al. (2024b) Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye,
    Zheyan Luo, Zhangchi Feng, and Yongqiang Ma. 2024b. LlamaFactory: Unified Efficient
    Fine-Tuning of 100+ Language Models. arXiv:2403.13372 [cs.CL] [https://arxiv.org/abs/2403.13372](https://arxiv.org/abs/2403.13372)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
