- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:53:33'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2401.17163](https://ar5iv.labs.arxiv.org/html/2401.17163)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: John Chen Northwestern UniversityEvanston, ILUnited States of America [civitas@u.northwestern.edu](mailto:civitas@u.northwestern.edu)
    ,  Xi Lu University of California, IrvineIrvine, CAUnited States of America [xlu30@uci.edu](mailto:xlu30@uci.edu)
    ,  David Du Northwestern UniversityEvanston, ILUnited States of America [duyuzhou2013@gmail.com](mailto:duyuzhou2013@gmail.com)
    ,  Michael Rejtig University of Massachusetts BostonBoston, MAUnited States of
    America [michael.rejtig001@umb.edu](mailto:michael.rejtig001@umb.edu) ,  Ruth
    Bagley Northwestern UniversityEvanston, ILUnited States of America [ruth.bagley@northwestern.edu](mailto:ruth.bagley@northwestern.edu)
    ,  Michael S. Horn Northwestern UniversityEvanston, ILUnited States of America
    [michael-horn@northwestern.edu](mailto:michael-horn@northwestern.edu)  and  Uri
    J. Wilensky Northwestern UniversityEvanston, ILUnited States of America [uri@northwestern.edu](mailto:uri@northwestern.edu)(2024;
    14 September 2023; 12 December 2023; 19 January 2024)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) have the potential to fundamentally change the
    way people engage in computer programming. Agent-based modeling (ABM) has become
    ubiquitous in natural and social sciences and education, yet no prior studies
    have explored the potential of LLMs to assist it. We designed NetLogo Chat to
    support the learning and practice of NetLogo, a programming language for ABM.
    To understand how users perceive, use, and need LLM-based interfaces, we interviewed
    30 participants from global academia, industry, and graduate schools. Experts
    reported more perceived benefits than novices and were more inclined to adopt
    LLMs in their workflow. We found significant differences between experts and novices
    in their perceptions, behaviors, and needs for human-AI collaboration. We surfaced
    a knowledge gap between experts and novices as a possible reason for the benefit
    gap. We identified guidance, personalization, and integration as major needs for
    LLM-based interfaces to support the programming of ABM.
  prefs: []
  type: TYPE_NORMAL
- en: '^†^†copyright: none^†^†journalyear: 2024^†^†doi: 10.1145/3613904.3642377^†^†conference:
    Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI ’24);
    May 11–16, 2024, Honolulu, HI, USA; ^†^†ccs: Human-centered computing Empirical
    studies in HCI^†^†ccs: Human-centered computing Natural language interfaces^†^†ccs:
    Computing methodologies Simulation support systems'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The advent of coding-capable Large Language Models (LLMs) has the potential
    to fundamentally change the way people engage in computer programming(Eloundou
    et al., [2023](#bib.bib26)). As LLM-based programming interfaces (e.g. GitHub
    Copilot; ChatGPT) become increasingly popular(Lau and Guo, [2023](#bib.bib47)),
    some studies started to study their user perceptions(Vaithilingam et al., [2022](#bib.bib85)).
    However, the research on their potential learning impacts is still limited. Many
    prior studies only focus on impressions of educators(Lau and Guo, [2023](#bib.bib47))
    or students(Yilmaz and Yilmaz, [2023](#bib.bib101)), with little empirical data
    on the actual learning usage of these tools. On the other hand, a few studies
    started to explore how LLM-based interfaces can be designed to facilitate programming
    education, indicating potential advantages for learners. Notably, these studies
    suggest that learners with more prior programming experience tend to benefit more(Nam
    et al., [2023](#bib.bib58); Kazemitabaar et al., [2023](#bib.bib43)). While a
    recent study identifies some challenges for novice learners with LLM-based interfaces(Zamfirescu-Pereira
    et al., [2023](#bib.bib102)), there is a gap in understanding why experienced
    programmers seem to gain more learning benefits from these tools.
  prefs: []
  type: TYPE_NORMAL
- en: In this paper, we present the design of a novel LLM-based interface, NetLogo
    Chat, for the learning and practice of NetLogo. NetLogo is a widely used programming
    language for agent-based modeling (ABM), which applies simple rules on multiple
    individual agents to simulate complex systems(Wilensky, [1997](#bib.bib95)). It
    is particularly powerful in capturing emergent phenomena, e.g., the spread of
    viruses or predator-prey systems(Wilensky and Rand, [2015](#bib.bib94)). It is
    an important methodology in computational modeling across scientific disciplines
    and education from K-12 to postgraduate levels(Weintrop et al., [2016](#bib.bib89)),
    where scientists and educators are highly in need of LLM-based interfaces(Pal
    et al., [2023](#bib.bib60); Cooper, [2023](#bib.bib22)). As an important part
    of computational modeling, the priorities of ABM differ from general programming(Pylyshyn,
    [1978](#bib.bib66)). A modeler needs to verify that their conceptual design of
    individual rules matches the real-world patterns (e.g. a predator needs food to
    survive), the code matches the design (i.e. there are no unexpected or implicit
    assumptions), and the aggregated outcome matches real-world phenomena (e.g. if
    all prey die out, predators die too)(Fleischmann and Wallace, [2009](#bib.bib29)).
    As most LLM-related studies on computer programming work on general-purpose languages
    that LLMs perform best (e.g. Python or Javascript), no LLM-related studies have
    explored ABM or other forms of computational modeling at this point.
  prefs: []
  type: TYPE_NORMAL
- en: NetLogo Chat was designed with constructionist learning principles and incorporated
    known best practices for ABM and computer programming. Constructionism advocates
    for the design of learning experiences where learners construct their understanding
    of the world (e.g. knowledge of ABM) through building personally meaningful artifacts
    (e.g. an agent-based model around learners’ interests)(Papert and Harel, [1991](#bib.bib62)).
    Similar to GitHub Copilot Chat(noa, [[n. d.]](#bib.bib2)), NetLogo Chat was integrated
    into an integrated development environment (IDE). Different from previous designs,
    it aims to give users more control over the human-AI collaboration processes,
    strives to incorporate authoritative sources, and tries to provide more support
    for troubleshooting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using both ChatGPT and NetLogo Chat as a probe(Zamfirescu-Pereira et al., [2023](#bib.bib102)),
    we conducted a qualitative study to highlight the different perceptions, behaviors,
    and needs of experts and novices during open-ended modeling sessions. We interviewed
    30 expert and novice participants from academia, industry, and graduate schools
    around the world. Participants proposed diverse NetLogo tasks from their disciplines
    and worked toward their modeling goals. We asked interview questions before, during,
    and after their interaction with each design. We answered the research questions:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What perceptions - strengths, weaknesses, and adoption plans - do expert and
    novice users perceive LLM-driven interfaces to support their NetLogo learning
    and practice?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do expert and novice users use LLM-driven interfaces to support their NetLogo
    learning and practice?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are expert and novice users’ needs for LLM-based interfaces to support
    their NetLogo learning and practice?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Learners generally agreed with our design principles and suggested additional
    features for future designs. As in other studies, experts reported more perceived
    benefits than novices. Comparing the different interaction patterns between experts
    and novices, our study reveals a behavioral gap that might explain the gap in
    benefits. We found that experts collaborated with LLM-based interfaces with more
    human judgment in all activities than novices, helping them overcome AI hallucinations,
    while novices struggled with evaluating and debugging AI responses. From there,
    we identified components of a knowledge gap between novices and experts. We reported
    experts’ and novices’ needs in LLM-based interfaces in three key themes: guidance
    (from LLMs); personalization (of LLMs); and integration (into modeling environments),
    many of which confirm and develop the design decisions of NetLogo Chat. The contributions
    of this paper include:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The design and implementation of NetLogo Chat, an LLM-based system that supports
    learning and practice of NetLogo, a widely-used programming language for ABM;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An empirical study that contributes to the understanding of how novices and
    experts perceive, use, and express needs for LLM-based programming interfaces
    in different ways;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A theorization of the knowledge gap between experts and novices that might lead
    to the behavioral gap, and suggestions of potential design interventions;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (4)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The design discussion and suggestions for building LLM-based programming interfaces
    that benefit both experts and novices in agent-based modeling more equitably.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2\. Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1\. LLMs for Computational Programming and Modeling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Researchers have been exploring natural-language-based interfaces for programming
    for decades, yet early attempts were mostly exploratory, being limited in capabilities.
    NaturalJava(Price et al., [2000](#bib.bib65)) required users to follow a strict
    pattern when prompting, while later systems (e.g. NaLIX(Li et al., [2005](#bib.bib48))
    or Eviza(Setlur et al., [2016](#bib.bib74))) asked for a specific set of English
    expressions. This created difficulties for users and system designers, as they
    felt “a main challenge of NLP interfaces is in communicating to the user what
    inputs are supported.”(Setlur et al., [2016](#bib.bib74)) Without the capability
    to generate natural languages, those interfaces were also constrained to one-off
    interactions.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, a new generation of LLMs demonstrated the capability to understand
    and generate both natural languages and computer languages. GPT-3 was examined
    in writing code explanations(MacNeil et al., [2022](#bib.bib53)), documentation(Khan
    and Uddin, [2022](#bib.bib45)), and providing feedback for assignments(Balse et al.,
    [2023](#bib.bib4)). Soon, educators started to believe that Codex could be used
    to solve simple programming problems(Finnie-Ansley et al., [2022](#bib.bib28);
    Wermelinger, [2023](#bib.bib91)). Embedded in ChatGPT, GPT-3.5-turbo and GPT-4
    demonstrated even stronger capabilities in programming. More and more LLMs have
    started to gain the capability of coding (e.g. PALM 2; Claude 2; CodeLLaMA 2),
    ushering in a new era of natural language interfaces for programming.
  prefs: []
  type: TYPE_NORMAL
- en: Even the most powerful LLMs suffer from hallucinations and may misunderstand
    human intentions. Early users of ChatGPT complained about incorrect responses
    and struggled to prompt ChatGPT for a desired output(Skjuve et al., [2023](#bib.bib75)).
    While LLMs might outperform average humans in specific, structured tasks(OpenAI,
    [2023](#bib.bib59)), the evaluation criteria might have been flawed(Liu et al.,
    [2023](#bib.bib51)), as LLMs struggled to combine existing solutions for a novel
    challenge(Dakhel et al., [2023](#bib.bib24)). A study suggested that developers
    should not rely on ChatGPT when dealing with new problems (Tian et al., [2023](#bib.bib82)).
  prefs: []
  type: TYPE_NORMAL
- en: 'LLMs are naturally less prepared in low-resource programming languages (LRPL).
    Here, our working definition for LRPL is similar to that of natural languages:
    with relatively scarce online resources and have been less studied by the AI field(Magueresse
    et al., [2020](#bib.bib54)). LRPLs are not less important: NetLogo, the most widely
    used programming language for agent-based modeling (ABM)(Thiele et al., [2011](#bib.bib81)),
    is used by hundreds of thousands of scientists, educators, and students for computational
    modeling. Using simple computational rules for individual agents, ABM could simulate
    complicated emergent phenomena. It has been frequently used in different scientific
    disciplines(Wilensky and Rand, [2015](#bib.bib94)) and science education(Hutchins
    et al., [2020](#bib.bib36)) for recent decades. With considerably fewer online
    resources to train on, LLMs are much more prone to errors and/or hallucinations
    with LRPLs(Tarassow, [2023](#bib.bib80)).'
  prefs: []
  type: TYPE_NORMAL
- en: A few studies attempted to improve LLMs’ performance with LRPLs in two directions.
    First, some studies fine-tuned foundational LLMs with LRPL datasets(Chen et al.,
    [2022](#bib.bib13)). While this approach demands considerable datasets and computational
    power, it has not been applied to generative tasks yet(Gong et al., [2022](#bib.bib32)).
    Second, some studies used prompt engineering techniques. For example, aiming at
    simple tasks, a study creates sets of grammar rules for LLMs to fill in(Wang et al.,
    [2023](#bib.bib87)). Another study leveraged compiler outputs, allowing LLMs to
    iteratively improve their Rust code, but was only tested in a smaller number of
    fixed tasks(Wu et al., [2023](#bib.bib98)). The potential of LLMs in scientific
    disciplines, including in computational modeling, is rarely explored. At this
    point, the only study targeted at STEM helps with a very specific engineering
    task (Kumar et al., [2023](#bib.bib46)).
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. User Perception and Behaviors with LLM-based Programming Interfaces
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Two strands of user perception and behaviors studies informed our design and
    study: studies of conversational agents (CAs); and of LLM-based programming interfaces.
    For education, CAs were used to develop learners’ writing(Wambsganss et al., [2021](#bib.bib86)),
    self-talk(Fu et al., [2023](#bib.bib30)), and programming skills(Winkler et al.,
    [2020](#bib.bib96)). Many of them are pedagogical conversational agents (PCA)
    with the aim to adaptively mimic the behaviors of human tutors(Winkler and Söllner,
    [2018](#bib.bib97)). PCAs could serve in multiple roles, such as tutors(Wambsganss
    et al., [2021](#bib.bib86)), motivators(Caballé and Conesa, [2019](#bib.bib12)),
    peer players(Gero et al., [2020](#bib.bib31)), or learning companions(Fu et al.,
    [2023](#bib.bib30)).'
  prefs: []
  type: TYPE_NORMAL
- en: Prior research of CAs underscored the importance of understanding user perception
    and behaviors(Gero et al., [2020](#bib.bib31)), yet the technical boundaries of
    the pre-LLM era limited the freedom of designers. Previous studies have explored
    aspects such as trust, mutual understanding, perceived roles(Clark et al., [2009](#bib.bib19)),
    privacy(Sannon et al., [2020](#bib.bib70)), human-likeness(Jeong et al., [2019](#bib.bib37)),
    utilitarian benefits, and user-related factors(Ling et al., [2021](#bib.bib50))
    to understand users’ acceptance and willingness to use CAs. However, many CAs
    before LLMs had to use pre-programmed responses(Wang et al., [2021](#bib.bib88)),
    and simply emulating functional rules from human speech failed to deliver people’s
    high expectations of CAs(Clark et al., [2019](#bib.bib20)). Without the capability
    to read or write code, pre-LLM CAs for computing education were largely limited
    to providing relevant knowledge(Winkler et al., [2020](#bib.bib96)) or supporting
    conceptual understanding of programming(Lin et al., [2020](#bib.bib49)).
  prefs: []
  type: TYPE_NORMAL
- en: Recent studies have started to understand user perception and behaviors with
    LLM-based programming interfaces. In education, early studies focused on instructors’
    and students’ perceptions of LLM-based interfaces for programming. Computer science
    students self-reported many potential benefits of using ChatGPT and were less
    inclined to report potential drawbacks(Yilmaz and Yilmaz, [2023](#bib.bib101)).
    On the other hand, computer science instructors were significantly concerned over
    students’ widespread usage of ChatGPT(Lau and Guo, [2023](#bib.bib47)). While
    some instructors went as far as banning ChatGPT altogether, others suggested exposing
    students to the capabilities and limitations of AI tools, leveraging mistakes
    in generated code for learning opportunities. Both instructors and students expressed
    the need to adapt to a new, LLM-era way of teaching and learning(Zastudil et al.,
    [2023](#bib.bib103)).
  prefs: []
  type: TYPE_NORMAL
- en: For professionals, challenges and opportunities co-exist with LLM-based programming
    interfaces. Recent studies found programmers preferred to use Copilot(Vaithilingam
    et al., [2022](#bib.bib85)) and finished tasks faster with Copilot(Peng et al.,
    [2023](#bib.bib63)). Yet, Copilot struggled with more complicated problems, providing
    buggy or non-reproducible solutions(Dakhel et al., [2023](#bib.bib24)). Professional
    programmers faced difficulties in understanding and debugging Copilot-generated
    code, which hinders their task-solving effectiveness(Vaithilingam et al., [2022](#bib.bib85)).
    Programmers who trusted AI were prone to write insecure code with AI(Perry et al.,
    [2022](#bib.bib64)). For conversational interfaces, despite inputs being in natural
    languages, users felt that they needed to learn LLM’s “syntax”(Jiang et al., [2022](#bib.bib38);
    Fiannaca et al., [2023](#bib.bib27)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Our understanding of user perception and behaviors with LLM-based interfaces
    during (the learning of) computer programming is still very limited. As the field
    just started exploring this direction, previous studies mostly focused on general
    user impressions(Zastudil et al., [2023](#bib.bib103)), or conducted behavioral
    tasks on pre-scripted, close-ended tasks(Peng et al., [2023](#bib.bib63)). While
    close-ended settings made it easier to assess objective metrics(Blikstein, [2011](#bib.bib8)),
    open-ended contexts open a wider window to understanding users’ learning patterns,
    behaviors, perceptions, and preferences(Blikstein et al., [2014](#bib.bib9)).
    For example, a recent study observed two modes that professional programmers interact
    in open-ended tasks with Copilot: acceleration, where the programmer already knows
    what they want to do next; and exploration, where the programmer uses AI to explore
    their options(Barke et al., [2023](#bib.bib5)). Another study on professionals’
    prompt engineering shed light on their struggles, challenges, and potential sources
    of behaviors(Zamfirescu-Pereira et al., [2023](#bib.bib102)).'
  prefs: []
  type: TYPE_NORMAL
- en: Still, we noticed two gaps in previous studies. First, a majority of studies
    chose professional programmers or computer science instructors/students as participants,
    while LLM-based interfaces are also used by millions of people without a CS background
    for programming tasks. Second, as HCI studies mostly focus on languages that LLMs
    are known to perform best, e.g. Python or HTML, little is known about user perceptions
    and behaviors when computational modeling or LRPLs are involved.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3\. LLM-based Interfaces for Learning Programming and Modeling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While LLMs have shown promising potential in supporting human-AI collaboration
    in programming, most design studies were preliminary, and LLM-based interfaces
    for computational modeling remained understudied. For example, the Programmer’s
    Assistant integrated a chat window into an IDE(Ross et al., [2023](#bib.bib69)).
    Going beyond simple integrations, GitHub Copilot Chat(noa, [[n. d.]](#bib.bib2))
    provided in-context support within code editors, yet its user studies were still
    preliminary(Bull and Kharrufa, [2023](#bib.bib11)). A similar design was done
    on XCode without a user study(Tan et al., [2023](#bib.bib79)). Another study explored
    the integration between computational notebooks with LLMs and emphasized the role
    of the domain (in this case, data science) on LLM-based interface design(McNutt
    et al., [2023](#bib.bib56)).
  prefs: []
  type: TYPE_NORMAL
- en: LLMs have gained much attention among programming educators, but the design
    study is insufficient. Recent studies tested LLMs on introductory programming
    tasks and achieved unsurprisingly high scores(Savelka et al., [2023](#bib.bib71);
    Chen et al., [2023a](#bib.bib17)). This prospect leads to great concerns among
    computer science instructors as they observed the widespread usage of ChatGPT
    among students(Lau and Guo, [2023](#bib.bib47)). Yet, only a few LLM-based design
    studies targeted programming learning. Using a Wizard of Oz prototype, a study
    underscored the importance of supporting students’ varied degrees of prior expertise(Robe
    and Kuttal, [2022](#bib.bib68)). A design study reported positive short-term performance
    gains when young, novice programming learners engaged with Codex(Kazemitabaar
    et al., [2023](#bib.bib43)). Another study also found LLMs’ benefits for novice
    programmers(Nam et al., [2023](#bib.bib58)). Both studies found that more experienced
    programmers tended to benefit more, yet the reason was still unclear.
  prefs: []
  type: TYPE_NORMAL
- en: In this study, we invoke the learning theory of Constructionism(Papert and Harel,
    [1991](#bib.bib62)) to inform our LLM-based system and empirical study design.
    While there is no rigid definition for Constructionism, it argues that learning
    happens most felicitously when learners ”consciously engage in constructing a
    public entity”(Papert and Harel, [1991](#bib.bib62)). In the context of computer
    programming, it means learning happens naturally through programming computers,
    as it iteratively externalizes learners’ internal understanding of the world in
    code, and then allows learners to improve their understanding through watching
    how the code runs(Papert, [1980](#bib.bib61)). Moreover, it argues that computer
    programming is not as abstract or formal as it appears; individual programmers’
    approaches are often concrete and personal, in pluralistic ways(Turkle and Papert,
    [1990](#bib.bib84)). However, the pluralism in thoughts is more difficult to capture
    by close-ended tasks (such as a problem set) and objective metrics (such as completion
    rate/time)(Blikstein et al., [2014](#bib.bib9)). As such, constructionist learning
    studies often prefer open-ended tasks (e.g. making games(Kafai and Burke, [2015](#bib.bib41)),
    designing instructional software(Harel and Papert, [1990](#bib.bib33)), creating
    agent-based models in NetLogo(Blikstein et al., [2014](#bib.bib9))) and qualitative
    studies, as they open windows into the nuances of learners’ perceptions and behaviors
    in more natural and realistic settings.
  prefs: []
  type: TYPE_NORMAL
- en: The Logo programming language and its descendants (e.g. Scratch; Alice; NetLogo)
    succeeded in supporting multiple ways of knowing and thinking in computing education
    and in scientific research(Solomon et al., [2020](#bib.bib76)), yet to our knowledge,
    no published studies have explored their synergy with LLMs. Many prominent constructionist
    design principles could be applied to AI-based interfaces(Kahn and Winters, [2021](#bib.bib42))
    and inspired the design of NetLogo Chat. For instance, “low floor, high ceiling,
    wide walls” asks learning environments to provide 1) an easy entrance for novices
    (low floor); 2) the possibility for experts to work on sophisticated projects
    (high ceiling); 3) the support of a wide range of different explorations (wide
    walls); 4) the support of many learning paths and styles(Resnick and Silverman,
    [2005](#bib.bib67)). We also learned from previous design studies that stress
    the importance of adaptive scaffolding(Chen et al., [2023b](#bib.bib15); Sengupta
    et al., [2013](#bib.bib73)) and support debugging(Brady et al., [2020](#bib.bib10))
    for novices to learn NetLogo. Hence, we contributed to the field one of the first
    design studies of LLM-based interfaces for learning programming that follow the
    constructionist tradition.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. NetLogo Chat System
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'NetLogo Chat is an LLM-based system for learning and programming with NetLogo.
    It comprises two main parts: a web-based interface integrated with Turtle Universe
    (a version of NetLogo)(Chen and Wilensky, [2021](#bib.bib14)) (See [3.1](#S3.SS1
    "3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat")); and an LLM-based workflow that improves the quality of AI responses
    and powers the interface (See [3.2](#S3.SS2 "3.2\. Technical Implementation ‣
    3\. NetLogo Chat System ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")).
    We iteratively designed the system by:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Based on authors’ experiences in teaching NetLogo, we created a design prototype
    based on the constructionist learning theory (see [2.3](#S2.SS3 "2.3\. LLM-based
    Interfaces for Learning Programming and Modeling ‣ 2\. Related Work ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat")), with a focus on supporting users
    iteratively build up their prompts and smaller code snippets before working on
    entire models. We developed a proof-of-concept system, using prompt engineering
    techniques to interact with GPT-3.5-turbo-0314.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We internally evaluated the proof-of-concept with a group of NetLogo experts.
    During this process, we encountered frequent hallucinations with NetLogo (grammatical
    or conceptual mistakes; inventing keywords that do not exist; etc). For the system
    to provide guidance, we realized that authoritative sources are necessary for
    LLMs’ performance;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We incorporated the official NetLogo documentation and code examples into the
    system using prompt engineering techniques (see [3.2](#S3.SS2 "3.2\. Technical
    Implementation ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat")), evaluated other LLMs’ potential, and then conducted pilot interviews
    to evaluate the system with three external NetLogo experts invited from NetLogo’s
    mailing lists. The interviews used a protocol similar to the one we formally used
    (see [4.2](#S4.SS2 "4.2\. Interviews ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat")), with more flexibility and open-endedness;'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (4)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Based on the external feedback, we identified the need for supporting troubleshooting,
    leading to the design decision [3.1.3](#S3.SS1.SSS3 "3.1.3\. Integrate with the
    IDE and Enhance Troubleshooting ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat"). We upgraded the underlying
    LLM to GPT-3.5-turbo-0613, fixed many minor usability issues, and finalized the
    prototype that we used in the empirical study.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 3.1\. Design Overview
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/12e391832eef8d51cc0123f3dd453820.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1\. NetLogo Chat asking for details about human’s needs.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: In this figure, the user asked NetLogo Chat ”create a flocking model”. NetLogo
    Chat started by searching for related documentation, provided several example
    models, then asked three follow-up questions to clarify the needs of the user.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/332007986223bec146becf453f809e3f.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2\. ChatGPT assuming details of human’s needs.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: In this figure, the user asked ChatGPT to ”create a flocking model in netlogo”.
    ChatGPT gave a direct response starting with ”Sure, I can help you create a simple
    flocking model in NetLogo”, then gave the user an instruction to open NetLogo,
    create a model, and copy a code snippet.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.1\. Enable users to program the computer, rather than being programmed by
    the computer
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Over-reliance on LLM-based interfaces has become a major concern among both
    educators and some learners, where students blindly follow the instructions given
    by LLMs without attempting to construct their representations of knowledge. Such
    a scenario is antithetical to the constructionist learning tradition, where Seymour
    Papert’s fear of ”computers program children” comes back to life again(Papert,
    [1980](#bib.bib61)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Inspired by the Logo language, the design of NetLogo Chat aims to give control
    back to learners: to suppress LLMs’ tendency to give a quick response that often
    assumes too much about the learner’s inclination, we force it to ask clarification
    questions more often. Fig [1](#S3.F1 "Figure 1 ‣ 3.1\. Design Overview ‣ 3\. NetLogo
    Chat System ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat") and Fig [2](#S3.F2
    "Figure 2 ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") provide an exemplary comparison between NetLogo
    Chat and ChatGPT’s reaction to a simple modeling request. Here, ChatGPT immediately
    assumes details of the user’s needs and generates an entire model for the user
    to copy and paste. Whereas, NetLogo Chat attempts to first clarify the user’s
    needs by asking follow-up questions and suggesting exemplar answers. The suggestions
    in Fig [1](#S3.F1 "Figure 1 ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") serve as both an inspiration,
    in case learners get confused about what to write; and a shortcut, in case learners
    find any suggestions immediately usable.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this feature to work effectively, it is essential to ask questions with
    quality. To achieve this, we used a few-shot approach and crafted templates for
    LLMs to follow. We conducted an informal evaluation of LLM’s generated questions
    during our development process and empirical study. Across the board, the LLM
    we used was able to generate questions with acceptable quality, similar to the
    one demonstrated in Fig [1](#S3.F1 "Figure 1 ‣ 3.1\. Design Overview ‣ 3\. NetLogo
    Chat System ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat"). A future design
    could embed a larger set of templates and retrieve a few relevant templates when
    needed.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2\. Invoke Authoritative Sources Whenever Possible
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Hallucination is another major concern for LLMs, particularly in an LRPL like
    NetLogo. For example, the code generated by ChatGPT in Fig [2](#S3.F2 "Figure
    2 ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") contains multiple syntax issues and requires human experts
    to address them. More powerful LLMs suffer from the same symptoms. We submitted
    similar sample requests to GPT-4, PaLM2, Anthropic Claude 2, and Falcon-180B:
    none was able to produce syntactically correct code for a classical NetLogo model.'
  prefs: []
  type: TYPE_NORMAL
- en: Following previous examples in related tasks(Joshi et al., [2023](#bib.bib39)),
    we integrated NetLogo’s official documentation and model examples to help improve
    LLMs’ and human performance. Different from previous studies, we not only provided
    related examples to LLMs, but also revealed them to users. By doing so, we seek
    to improve the transparency of LLM’s mechanism, foster trust in the LLM-driven
    system, and provide authoritative guides and examples for users even when LLMs
    might fail to provide precise support.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/de29b250f55dbe659001a3ee10b3b5f1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3\. NetLogo Chat’s embedded editor for generated code.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: This figure demonstrates the interface of Turtle Universe (a version of NetLogo).
    On the left, there is a visualization of a simple model that draws a diagonal
    line. On the top-right, there is a code editor that has the code and a mistake
    introduced by the researcher. The editor shows a linting message and an ”explain”
    button. On the bottom-right is the conversation and interaction history between
    the user and NetLogo Chat.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.3\. Integrate with the IDE and Enhance Troubleshooting
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We seek to integrate NetLogo Chat into NetLogo’s IDE beyond integrating a conversational
    assistant parallel to the code editor. To facilitate a constructionist learning
    experience, the code editor needs to be integrated into the conversational interface,
    where learners can work with smaller snippets of code with more ease. Thus, the
    design might lower the threshold for learners to tinker with the code, a key learning
    process advocated by the constructionist literature (Papert and Harel, [1991](#bib.bib62);
    Turkle and Papert, [1990](#bib.bib84)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Fig [3](#S3.F3 "Figure 3 ‣ 3.1.2\. Invoke Authoritative Sources Whenever Possible
    ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") provides a concrete example, where the embedded editor displays
    a piece of generated code. Instead of having to copy and paste the piece back
    into the main editor, the user could first see if any syntax issues exist in the
    code; run the code within a conversation; and ask follow-up questions or raise
    additional requests, before putting back a working code snippet into their projects.'
  prefs: []
  type: TYPE_NORMAL
- en: To further support the user’s troubleshooting, in addition to error messages,
    NetLogo Chat will display extra debugging options for users. Users could choose
    to look for an explanation, or ask the LLM to attempt fixing the issue on its
    own, or with the user’s ideas. During the process, the system will attempt to
    find documentation and related code examples to reduce hallucinations. Building
    on the literature on error messages’ impact on learning(Becker et al., [2019](#bib.bib6)),
    we also clarified many messages to provide a better context for humans and both
    LLM-based systems used in the study.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2\. Technical Implementation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7cd5a81d1d67ab3864013313cc2adde7.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4\. A brief outline for NetLogo Chat’s LLM workflow.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 'In this figure, from left to right: User Request =¿ Planning =¿ Choose Action
    =¿ Search =¿ Documentation; Respond; Clarify =¿ User Input =¿ Planning =¿ …'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since OpenAI started to provide fine-tuning on GPT-3.5-turbo (the version also
    used in ChatGPT Free) only after we concluded the main study in July, NetLogo
    Chat was implemented with prompt engineering techniques. We built our project
    on ReAct(Yao et al., [2022](#bib.bib100)), a prompt-based framework that could
    reduce hallucination, improve human interpretability, and increase the trustworthiness
    of LLMs. By requiring LLMs to generate an action plan and delegate the action
    to a third-party conventional agent (e.g. search for documentation, ask clarification
    questions, conduct a static syntax check, etc.) before composing the final response,
    the framework provides a promising pathway to integrate external inputs (e.g.
    human input, official documentation) into LLM workflows. Fig [4](#S3.F4 "Figure
    4 ‣ 3.2\. Technical Implementation ‣ 3\. NetLogo Chat System ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") depicts a rough outline of NetLogo Chat’s workflow.
    Imagine a user requests to ”create a predation model”:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The LLM is instructed, in the prompt, to first elaborate on the request (planning):
    ”The user intends to create an agent-based biology model related to predation.
    However, it is unclear what exactly the user wants. We need to ask follow-up questions.”'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, the LLM is instructed to choose an action from the list: Ask clarification
    question(s); Search for documentation; Write a response; Say sorry. Here, imagine
    the LLM chooses ”Ask clarification question(s)” based on the planning.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, the LLM needs to generate some questions based on the request. Because
    LLMs are trained on real-world data, it is not difficult for them to come up with
    some ideas. For example, ”What species do you want to put in the model?” The LLM
    is also instructed to provide some examples, e.g. ”Wolf”, ”Sheep”.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (4)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the user replies to the questions, the loop restarts from step (1). Since
    there is sufficient information about the request, the LLM decides to search for
    information, and also generates keywords for the search, e.g. ”Wolf-sheep predation
    model in NetLogo”.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (5)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The system conducts a semantic search on a pre-assembled database of NetLogo’s
    official documentation and code examples. The system returns the search result,
    use it as a new round of input, and restarts from step (1).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (6)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With inputs from both the user, who clarified the request; and the database,
    which supplies the example; the LLM plans again, chooses to write a response,
    and generates its final response.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the example, we initiated three requests with the LLM, each with a prompt
    template that results in a structured response(Yao et al., [2022](#bib.bib100))
    (e.g. any response needs to have a Plan, an Action, and a Parameter). Each request
    could use a different LLM that works best for the specific request. Using this
    approach, the system has the potential to balance cost, performance, speed, and
    privacy. For example, a future iteration of NetLogo Chat could leverage a fine-tuned
    local LLM to probe the user’s intentions and search for documentation. Then, with
    any personal or sensitive information stripped away, the system could forward
    the compiled request to a powerful online LLM (e.g. GPT-4).
  prefs: []
  type: TYPE_NORMAL
- en: For the empirical study, we chose GPT-3.5-turbo-0613 as NetLogo Chat’s LLM backend.
    First, we expect most participants to be using the free version of ChatGPT, driven
    by the same LLM. In this way, we would have a fair playing field for the empirical
    study, where both systems will be used. Second, at the time of our study, the
    response time for GPT-4 was too long to sustain a real-time experience, while
    we had no access to other NetLogo-capable LLMs’ APIs. Although we did observe
    some remarkable improvement when internally evaluating the system (e.g. ChatGPT
    has trouble answering questions for lesser-known NetLogo keywords, while NetLogo
    Chat does not), a more systematic evaluation rubric is needed for future research.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Empirical Study
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 4.1\. Participants
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For the empirical study, we recruited 30 adult participants through NetLogo’s
    official Twitter and mailing lists; and through the Complexity Explorer, a website
    run by Santa Fe Institute (SFI) to distribute learning resources of agent-based
    modeling (ABM). The exact breakdown of participants’ demographic data can be seen
    in Table [1](#S4.T1 "Table 1 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat"). The participant pool largely represented
    the scientific modeling community in NetLogo’s main audience, with a majority
    of participants coming from STEM disciplines. Many participants were also related
    to the educator sector. 6 participants (20%) were instructors who teach or are
    interested in teaching NetLogo in classrooms; 4 (13%) were graduate-level students
    interested in learning NetLogo, making up a third of the population. Participation
    in the study was voluntary. All participants signed an online consent form on
    Qualtrics.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Building on the tradition of understanding the difference between experts and
    novices(Chi et al., [1981](#bib.bib18)), we separated the participants into experts
    and novices using self-reported survey data. To mitigate the effect of inaccurate
    responses, NetLogo experts in the team, who have been core developers and instructors
    of NetLogo, watched every video and decided if a participant greatly overestimated
    or underestimated their capabilities. We considered the participant’s discussions
    with the interviewer, the think-aloud process, and the coding behaviors. A vast
    majority of users’ reports correspond with the experts’ judgment. Then, to simplify
    the analysis, we separated participants (Table [2](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat"))
    by their levels into two main categories: experts, who are either experts in NetLogo
    or programming in general; and novices. In the study, we denote experts by the
    prefix E (E01-E17) and novices by N (N01-N13). 13 experts had previous experience
    with ChatGPT (76%), including programming (65%, n=11). 11 novices (85%) also used
    ChatGPT before, but much less for programming (38%, n=5).'
  prefs: []
  type: TYPE_NORMAL
- en: Table 1\. Overview of Participant Demographics (n=30)
  prefs: []
  type: TYPE_NORMAL
- en: '| Gender | Females: 10 (33%); Male: 19 (63%); Non-binary: 1 (3%) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Geography | Africa: 1 (3%); Asia and Oceania: 5 (17%); Europe: 8 (27%); Latin
    America: 2 (7%); North America: 14 (47%). |'
  prefs: []
  type: TYPE_TB
- en: '| Occupation | Academics: 14 (47%); Professionals: 12 (40%); Students: 4 (13%)
    |'
  prefs: []
  type: TYPE_TB
- en: Table 2\. Participant Information
  prefs: []
  type: TYPE_NORMAL
- en: '| ID | Region | Level (NetLogo) | Level (Programming) | Occupation |'
  prefs: []
  type: TYPE_TB
- en: '| E01 | North America | Expert | Expert | Professional |'
  prefs: []
  type: TYPE_TB
- en: '| E02 | Asia and Oceania | Expert | Intermediate | Academic |'
  prefs: []
  type: TYPE_TB
- en: '| E03 | Latin America | Intermediate | Expert | Academic |'
  prefs: []
  type: TYPE_TB
- en: '| E04 | North America | Expert | Expert | Academic |'
  prefs: []
  type: TYPE_TB
- en: '| E05 | Europe | Intermediate | Expert | Academic |'
  prefs: []
  type: TYPE_TB
- en: '| E06 | North America | Intermediate | Intermediate | Academic |'
  prefs: []
  type: TYPE_TB
- en: '| E07 | Latin America | Intermediate | Intermediate | Professional |'
  prefs: []
  type: TYPE_TB
- en: '| E08 | Asia and Oceania | Intermediate | Intermediate | Professional |'
  prefs: []
  type: TYPE_TB
- en: '| E09 | Asia and Oceania | Intermediate | Expert | Professional |'
  prefs: []
  type: TYPE_TB
- en: '| E10 | North America | Intermediate | Intermediate | Academic |'
  prefs: []
  type: TYPE_TB
- en: '| E11 | Africa | Intermediate | Expert | Academic |'
  prefs: []
  type: TYPE_TB
- en: '| E12 | North America | Intermediate | Intermediate | Academic |'
  prefs: []
  type: TYPE_TB
- en: '| E13 | Europe | Expert | Novice | Academic |'
  prefs: []
  type: TYPE_TB
- en: '| E14 | Europe | Intermediate | Intermediate | Academic |'
  prefs: []
  type: TYPE_TB
- en: '| E15 | Asia and Oceania | Expert | Expert | Student |'
  prefs: []
  type: TYPE_TB
- en: '| E16 | Asia and Oceania | Novice | Expert | Professional |'
  prefs: []
  type: TYPE_TB
- en: '| E17 | Europe | Intermediate | Expert | Academic |'
  prefs: []
  type: TYPE_TB
- en: '| N01 | North America | Novice | Novice | Professional |'
  prefs: []
  type: TYPE_TB
- en: '| N02 | North America | Novice | Novice | Academic |'
  prefs: []
  type: TYPE_TB
- en: '| N03 | North America | Novice | Novice | Professional |'
  prefs: []
  type: TYPE_TB
- en: '| N04 | North America | Novice | Intermediate | Student |'
  prefs: []
  type: TYPE_TB
- en: '| N05 | Europe | Novice | Intermediate | Student |'
  prefs: []
  type: TYPE_TB
- en: '| N06 | Europe | Intermediate | Novice | Student |'
  prefs: []
  type: TYPE_TB
- en: '| N07 | North America | Novice | Intermediate | Professional |'
  prefs: []
  type: TYPE_TB
- en: '| N08 | North America | Novice | Intermediate | Professional |'
  prefs: []
  type: TYPE_TB
- en: '| N09 | North America | Novice | Novice | Professional |'
  prefs: []
  type: TYPE_TB
- en: '| N10 | North America | Novice | Intermediate | Professional |'
  prefs: []
  type: TYPE_TB
- en: '| N11 | Europe | Novice | Intermediate | Academic |'
  prefs: []
  type: TYPE_TB
- en: '| N12 | Europe | Novice | Novice | Academic |'
  prefs: []
  type: TYPE_TB
- en: '| N13 | North America | Intermediate | Novice | Professional |'
  prefs: []
  type: TYPE_TB
- en: 4.2\. Interviews
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our study was conducted in 3 phases:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We pilot interviewed 3 experts invited from NetLogo’s online community. Each
    was asked to comment on LLMs for NetLogo learning, as well as on ChatGPT and an
    early prototype of NetLogo Chat.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We improved the design of NetLogo Chat based on what we learned from the pilot
    interviews and revised the interview protocol accordingly.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We conducted formal interviews with 27 online participants (30 in total).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Each semi-structured interview lasted between 60-90 minutes and was video recorded.
    Prior to each formal interview, participants were asked to come up with a short
    NetLogo task that they were interested in working on. Almost every participant
    brought forward a modeling task from their career domain or personal interest,
    e.g. to model ”how honeybees decide to regulate the temperature of the hive”,
    or ”the spread of conflicting ideas”. Only once, when the task scope was too complicated
    for the session, did we ask the participant to bring another. During any part
    of the interview process, interviewers generally followed the protocol, asking
    follow-up questions when needed. Specifically:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We asked baseline questions, e.g., “What do you think are the potential advantages
    / disadvantages of using LLMs in supporting your learning and programming of NetLogo?”
    (in 2 separate questions)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We asked the participant to work on their task with the help of ChatGPT. Then,
    we asked the same baseline questions again, then asked “What do you like or dislike
    about the interface”. Repeat the procedure with NetLogo Chat;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If time permitted, we further asked about their preferences for learning and/or
    programming with NetLogo and asked which feature they wanted to add/remove from
    either system. Here, the objective was not to strictly compare between the two
    systems, but to elicit more in-depth discussions over LLM-based interfaces.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Since almost all users have already engaged with ChatGPT, we did not randomize
    the order of ChatGPT/NetLogo Chat. Also, 3 participants used the paid version
    (GPT-4) during the task with ChatGPT. While much of the generated data comes from
    the inevitable comparison between the two systems, we chose not to interpret them
    as objective comparisons. Instead, the different design principles underpinning
    the systems presented two objects to think with(Papert, [1980](#bib.bib61)), that
    our participants drew on during their reflections and discussions of LLM-based
    programming interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3\. Data Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our interviews resulted in around 40 hours of video data. Around half of our
    data is behavioral in nature, where participants worked on their tasks and were
    encouraged to think aloud; the other half is more verbal, where participants answered
    questions. As such, each interview was not only transcribed verbatim, but also
    watched by a researcher to create observational notes. The two streams were then
    combined into a single archive for analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on our research questions, we iteratively applied the grounded theory
    approach(Corbin and Strauss, [1990](#bib.bib23)) to analyze our data. During each
    step, the research team fully discussed the discrepancies between each researcher
    and iteratively refined the codebook to improve consistency. The analysis reached
    theoretical saturation at around 50% of interviews, when additional interviews
    no longer revealed unexpected major insights for our research questions. Then,
    we finished the rest of qualitative coding with the finalized codebook (Table
    [3](#S4.T3 "Table 3 ‣ 4.3\. Data Analysis ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat")).'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Four researchers open-coded 2 interviews, one from a novice and one from an
    expert, to summarize the topics mentioned by participants. During this process,
    researchers coded in different tabs to avoid interference. Three broad themes
    emerged from this phase: participants’ approaches to programming; participants’
    interactions with AI systems; and their comments on AI systems.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Taking notes of the emerging themes, the first author created a preliminary
    codebook that categorizes dozens of codes into themes. Each researcher coded another
    2 interviews in different tabs. In this phase, we refined the themes into approaches
    to programming (which also helps to separate experts and novices); perceptions
    and observed behaviors related to AI systems; and comments on AI systems’ abilities.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Based on the coding results, the first author created a formal codebook, with
    definitions clarified based on the discrepancies between researchers (Table [3](#S4.T3
    "Table 3 ‣ 4.3\. Data Analysis ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat")). To reduce the unbalanced influence of subjective interpretation,
    researchers only coded explicit behaviors; or direct comments. To avoid missing
    insights, researchers were instructed to highlight places where existing codes
    are insufficient to cover the topics. During the first two weeks, a few codes
    were created or merged as a result of discussions. We retrospectively revised
    our coding.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Table 3\. An Overview of the Codebook
  prefs: []
  type: TYPE_NORMAL
- en: '| Code | Definition |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Approaches | User’s perceptions about their approach to programming tasks,
    e.g. planning, separating into smaller pieces, or working on it as a whole. |'
  prefs: []
  type: TYPE_TB
- en: '| Learning | How users learn NetLogo or programming in general, or think that
    people should learn. |'
  prefs: []
  type: TYPE_TB
- en: '| Coding | How users organize or write their code, or think that people should
    organize or write. |'
  prefs: []
  type: TYPE_TB
- en: '| Help-seeking | How users seek help in general, or think that people should
    seek help. |'
  prefs: []
  type: TYPE_TB
- en: '| Human-AI | User’s perception and behaviors related to Human-AI relationship.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Prior | Users’ prior experiences with ChatGPT or other AI-based interfaces.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Attitude | Users’ attitudes toward AI in general, or specific AI-based systems.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Effort | AI’s influence on how much, and what kind of, efforts that humans
    made or need to make. |'
  prefs: []
  type: TYPE_TB
- en: '| Abilities | User’s perception related to AI’s abilities. |'
  prefs: []
  type: TYPE_TB
- en: '| Response | AI’s ability to provide desirable responses for humans. |'
  prefs: []
  type: TYPE_TB
- en: '| Support | AI’s ability to support learning/coding of NetLogo. |'
  prefs: []
  type: TYPE_TB
- en: '| Interactivity | AI’s ability to facilitate helpful interactions with humans.
    |'
  prefs: []
  type: TYPE_TB
- en: Based on the codebook, the first author iteratively incorporates themes into
    an outline. To further mitigate individual differences, researchers were asked
    to include as many codes as possible for each quote or observation.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Findings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '5.1\. Perception: Before and After Interaction'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Table 4\. Novices and Experts’ Perceptions on LLM-based Interfaces for NetLogo
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Experts | Novices |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|  | LLMs could save human time and effort, especially in syntax. | LLMs could
    save human time and effort, especially for syntax, and provide emotional benefits.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Before, Positive |  | LLMs could help troubleshooting. |'
  prefs: []
  type: TYPE_TB
- en: '|  | LLMs could mislead humans to suboptimal directions. | While LLMs may make
    mistakes, it is no worse than humans. |'
  prefs: []
  type: TYPE_TB
- en: '|  | LLMs could hinder learning processes. | LLMs may not understand human
    intentions. |'
  prefs: []
  type: TYPE_TB
- en: '| Before, Negative | LLMs could only work on smaller tasks. | LLMs’ responses
    are difficult to understand. |'
  prefs: []
  type: TYPE_TB
- en: '|  | LLMs supported learning or practicing by saving time. | LLMs supported
    learning or practicing by saving time. |'
  prefs: []
  type: TYPE_TB
- en: '| After Interaction | Will continue to use LLMs for learning or practicing
    NetLogo. | Will seek alternative learning resources before continuing to use LLMs.
    |'
  prefs: []
  type: TYPE_TB
- en: '5.1.1\. Before Interaction: Positive Expectations'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Prior to the tasks, both novices and experts had positive expectations of LLM-based
    interfaces for NetLogo, with novices holding higher expectations than experts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Both novices and experts expected LLM-based interfaces to save human time and
    support human effort, especially compared to other help-seeking activities. With
    LLMs, human time and energy could be liberated for more high-level tasks ([E12](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat"), [N03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")). Educators felt that LLMs
    could facilitate more efficient teaching, allowing students to \saymore complicated
    things with relative ease, spiking \saytheir imagination. ([E02](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat")) LLMs can also bring emotional benefits by reducing the fear
    of \saybothering the teachers or the experts ([E14](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat"))
    or asking \saystupid questions ([N06](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\.
    Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Most participants highlighted AI’s potential to help them with NetLogo’s syntax.
    For most participants, NetLogo is not the main programming language they used.
    Before the advent of ChatGPT, [N06](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\.
    Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat") felt that she
    needed to \sayrecite the words (syntax of NetLogo). Yet, the need was eliminated
    when \sayAI can teach you very quickly. Many experts also needed support, as NetLogo
    \sayhas very strict syntax rules ([E07](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣
    4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")) which makes
    writing more difficult.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Novices, in particular, expected that AI could be helpful for troubleshooting.
    [N08](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat"), for instance, felt that LLMs could help him through
    the troubleshooting process by describing \saywhat I’m trying to do and get a
    snippet of code that helps get me past that block. For novices without a background
    in programming, this future looks promising. [N12](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    is interested in the potential to \saymake programming more approachable to students.'
  prefs: []
  type: TYPE_NORMAL
- en: '5.1.2\. Before Interaction: Negative Expectations'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Almost every participant expressed concerns or reservations about LLM-based
    interfaces. Yet, the concerns of novices and experts were conspicuously different.
  prefs: []
  type: TYPE_NORMAL
- en: 'Experts focused on preserving human judgment. [E01](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") believed that AI should not \sayreplace human judgment and ability. Similarly,
    [E06](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") insisted that \say(human) has to do the main thinking
    and ideas and all of that. [E17](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") felt that humans cannot
    let AI \saytake over the main reasoning and emotions, the emotions intervening
    in the decisions. Many educators were also \sayconcerned about learning ([E13](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat")), fearing the tendency to \saydefault to the AI system
    to come up with the answers instead of working through it ourselves ([E12](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat")). Many experts explicitly explained their rationales.
    For example, [E08](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") was concerned that \sayif
    a model points me to a suboptimal direction, I will have no idea, because I haven’t
    considered alternative structure. [E15](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣
    4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat") feared that
    relying on AI responses might \saymake your horizon narrow because she would miss
    learning opportunities when browsing through the models library. For computational
    modeling, AI also might lack \sayin-depth knowledge in a specific field to create
    an entire model ([E05](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")). As such, [E05](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") would only trust AI to \sayfinish a specific task.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Novices were more optimistic and more concerned with their capabilities of
    understanding AI’s responses or making AI understand them. For example, while
    [N04](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") thought \sayone of the hypothetical drawbacks to
    LLMs being \sayconfidently incorrect, they added that \saypeople are like this
    too. On the other hand, [N03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") feared that she would waste
    more time with AI if \sayit didn’t understand me, or if I had difficulty expressing.
    [N02](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") acknowledged that \saythere is a limitation to
    not knowing how to code (on how much AI could help). Without knowledge of NetLogo,
    [N11](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") felt difficult to spot LLM-generated mistakes.'
  prefs: []
  type: TYPE_NORMAL
- en: '5.1.3\. After Interactions: Different Impacts of Hallucination'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'All participants encountered AI hallucinations throughout the sessions. While
    some participants rated NetLogo Chat higher than ChatGPT’s free version, most
    participants had similar changes in perceptions: experts, in general, reported
    more benefits from LLMs than novices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some participants reported more positively about NetLogo Chat’s capabilities.
    Several experts questioned ChatGPT’s training in NetLogo, yet they trusted more
    in NetLogo Chat, for it incorporates authoritative sources (see [3.1.2](#S3.SS1.SSS2
    "3.1.2\. Invoke Authoritative Sources Whenever Possible ‣ 3.1\. Design Overview
    ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based Modeling with
    LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")).
    [E16](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") believed that NetLogo Chat \sayunderstands your
    NetLogo syntax and \saythe basic aspects of NetLogo. [N02](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") thought NetLogo Chat still had bugs but was \saymuch more informative and
    precise than ChatGPT. As NetLogo Chat is designed to support troubleshooting (see
    [3.1.3](#S3.SS1.SSS3 "3.1.3\. Integrate with the IDE and Enhance Troubleshooting
    ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat")), [E04](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") thought NetLogo Chat \saywas
    able to kind of do some better troubleshooting to a certain extent, for it clarifies
    error codes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In both cases, experts understood hallucinations as an inevitable part of human-AI
    collaboration and reacted with more leniency. When [E03](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") first encountered an incorrect response, he exclaimed: \sayVery interesting!
    You’re mistaken. [E05](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") felt that LLMs helped him
    \sayfinish most of the code, though he still needed to \saydebug and see if the
    code makes sense logically. As experts did not rely on LLMs to resolve issues
    but mostly leveraged them as a shortcut, [E06](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    stated that hallucinations were instances \saywhere the programmer needs to use
    own experience and discretion, as risks would escalate if one extrapolates \saywhat
    ChatGPT provides you in a wrong manner.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Novices, on the other hand, reported more obstacles and frustration, as they
    relied more on LLMs for their tasks. [N07](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    emotionally responded to a hallucination that ChatGPT \sayapparently made that
    shit up. [N01](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat") had difficulties to \sayfix the bugs
    that were in it (the generated code). [N08](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")’s
    session ended up \sayhitting a dead end, with the frustration leading him to \saygo
    consult other resources.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Most novices and experts still thought that LLM-based interfaces supported
    their learning or practicing by saving time. Even though [N03](#S4.T2 "Table 2
    ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") had \saylow trust in ChatGPT, she still felt more confident after
    collaboration, for it \saynarrowed down the stuff I have to figure out myself
    and has made me much faster already. As an educator, [N12](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") felt that LLMs facilitated a constructionist learning experience in which
    \sayyou’re being thrown into the culture and have to learn it on the fly. [E13](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") thought he learned a syntax from ChatGPT that would \saysave
    me time in the future and the learning process was \saya lot faster than if I
    were doing it by hand.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As experts reported more perceived benefits, they predominantly intended to
    continue using LLM-based interfaces for NetLogo. After the task, [E11](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") felt confident that \sayI can write anything I want to
    write. Yet, many novices, driven by their frustration with LLMs, sought alternative
    learning resources before considering a return. [N04](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat"), for instance, had a 180-degree turn: expressing great hope before the
    tasks, they now inclined to \saybuild more by myself with my own code, without
    AI. [N13](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat") thought that she would prefer to work
    with \saysomeone who is familiar with the programming language together with LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2\. The Behavioral Gap Between Novices and Experts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Table 5\. Novices and Experts’ Behaviors During Human-AI Collaboration
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Experts | Novices |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|  | Many start by asking LLMs for a smaller aspect of the task. | Most start
    by asking LLMs to work on the entire task. |'
  prefs: []
  type: TYPE_TB
- en: '| Planning & Prompting | ”NetLogo, I would like to spawn 50 turtles” | ”I want
    to use netlogo to help me model how honeybees regulate the temperature in their
    hive. What should I do?” |'
  prefs: []
  type: TYPE_TB
- en: '|  | Focus more on the generated code. | Focus more on the generated instructions.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluating | ”Talks too much. I want the code, not the explanation yet.”
    | ”I am reading the text a little bit and it spits out a bunch of code. So it
    did give me steps, which is nice.” |'
  prefs: []
  type: TYPE_TB
- en: '|  | Most selectively copy and paste code, or write code on their own. | Most
    start by copying and pasting LLM-generated code. |'
  prefs: []
  type: TYPE_TB
- en: '| Coding | ”It’d be that I just take this and see what this does. ” | “This
    time it gives me.. two boxes to copy.” |'
  prefs: []
  type: TYPE_TB
- en: '|  | Debug themselves, or with help from AI. | Debug with (more) help from
    AI. |'
  prefs: []
  type: TYPE_TB
- en: '| Debugging | ”Oh, I didn’t ask him to move. That is my problem.” | ”I’m going
    to ask it the same question, but I’m confused why it said something about patches.”
    |'
  prefs: []
  type: TYPE_TB
- en: 5.2.1\. Behavioral Gap in Planning and Prompting
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: While experts’ and novices’ tasks were similar in terms of complexity, we observed
    differences between how novices and experts plan out their tasks. Since most participants
    gradually adapted their prompting styles, we focused on participants’ first-round
    prompts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two initial prompting patterns, one emphasizing modeling the entire system
    and another focusing on smaller, initial aspects of the task, emerged from our
    interviews. Most novices adopted the first pattern (11/13, 85%), while many experts
    adopted the second pattern (9/17, 53%). Below, we introduce one vignette for each
    pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[N05](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat") started by asking: \sayI need to make
    a model of the bunch of agents who are trying to promote political views to other
    people (…). Although he used GPT-4, the returned code still came with several
    syntax errors. [N05](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") then spent the next 20 minutes
    trying to ask GPT-4 to fix issues without success. He expected to \sayput the
    idea into it and we’ll run the code, but in the end \sayit didn’t happen.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E07](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat") started by asking ChatGPT to \saywrite
    code for drawing a rectangle. When GPT-3.5 failed to further divide the rectangle,
    [E07](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") instantly pivoted to another strategy: \sayI have
    the following code that draws a rectangle. I want you to modify it so the rectangle
    is divided by two. GPT-3.5 still failed, yet it produced working code and did
    \saysomething close to it.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The second prompting pattern involved remarkable mental efforts to decompose
    and plan out the task. For example, [E07](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    described his approach as \sayseparate into small, general tasks you want to do.
    [E04](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") explained that he \sayjust likes to iteratively
    build (the code). On the other hand, in the first pattern, many participants attempted
    to shortcut the efforts by delegating the tasks to AI, as [N05](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") said: \sayI just want to ask it (ChatGPT) to just directly make
    a code for this task and that’s it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of the task, most participants had realized the importance of breaking
    tasks into smaller pieces for coding with AI. Naturally, when an LLM-based interface
    generated code with mistakes, a participant would be (implicitly) guided to ask
    smaller follow-up questions. Soon, many of them realized the benefits. [N01](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") thought it would be better if one \sayworks through real
    small problems first, before getting to more complicated problems. [N10](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") would \saystart with something really basic. Experts
    using the first pattern had similar ideas. For example, [E12](#S4.T2 "Table 2
    ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") decided to restart \saywith something simple and just work with
    it.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.2\. Behavioral Gap in Coding and Debugging
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As most participants engaged with an agent-based modeling task that they never
    worked on, both experts and novices learned some aspects of NetLogo with the help
    of AI - although, in different ways. Experts usually took a much more measured,
    prudent, and critical approach during coding and debugging, while novices mostly
    followed AI’s instructions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most novices focused on reading AI’s explanations and followed AI’s instructions
    during their coding processes. ChatGPT often gives instructions like \sayYou can
    copy and paste this code into NetLogo and run it. Even without this hint, almost
    all novices would copy and paste the generated code without much reading. The
    tendency worried some novices, but they had no choice: \sayI feel like I’m waiting
    for someone to tell me the answer, rather than learning how to solve it. ([N11](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat"))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Experts put more emphasis on the code, often ignoring the explanations provided
    by AI. During their reading, experts evaluated and often criticized the responses,
    planning their next steps along the way. Only a few experts tried copying and
    pasting the code to see if they worked out of the box. Other experts selectively
    copied and pasted parts of the code into their programs, or wrote their programs
    with generated code on the side. Even when they copied and pasted the code, experts
    were more cautious. For example, while [E04](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    decided to \sayjust take this and see what this does, he also realized that AI-generated
    code would override his ideas and manually edited the code.'
  prefs: []
  type: TYPE_NORMAL
- en: 'All participants inevitably had to debug parts of the generated code. Yet,
    novices sought support from AI more frequently and often struggled with AI responses.
    For example, [N12](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") would regularly \saycopy
    the code that doesn’t make sense and go back to AI to see if it can help me. [N09](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") complained that while ChatGPT gave suggestions, \sayit
    obviously requires fiddling around with it. As she had little idea about NetLogo,
    it became a purely trial-and-error experience. Even when AI did solve some errors,
    it was challenging for novices to learn from the process. For example, [N04](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") commented that while NetLogo Chat provided an automated
    process, it was still difficult for him to get the lesson, \saysince I didn’t
    write it myself.'
  prefs: []
  type: TYPE_NORMAL
- en: '5.2.3\. Behind the Behavioral Gap: The Knowledge Gap'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We identified a knowledge gap that may lead to the behavioral gap. When novices
    realized that they needed to spend more effort decomposing the task or vetting
    AI responses, they found themselves lacking the necessary knowledge. We summarized,
    in participants’ own words, the four components of a knowledge gap that novices
    need to overcome when working with AI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Novices reported the need for conceptual knowledge of modeling. For example,
    [N07](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") described his experience as \saylike being adrift
    on an ocean. Without a compass, and without a map. With only a basic understanding
    of agent-based modeling, [N11](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") felt compelled to accept
    ChatGPT’s response as \sayI don’t really know how to interpret some of the output
    from it. Such feelings correspond with novices’ tendency to skim through AI responses.
    Whereas, some novices asked for help from LLMs with different degrees of success.
    [N04](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") first asked: \say(…) Can you tell me what I will
    need to do before we begin? With AI’s suggestions, [N04](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") had some more success asking follow-up questions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The unfamiliarity with the basic concepts of NetLogo and/or coding in general
    further adds to the difficulty in prompting and understanding. After reading a
    guide suggested by NetLogo Chat, [N07](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣
    4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat") realized that
    he \sayprobably wouldn’t have chosen NetLogo to ever begin with for his database-related
    task. Other novices were often confused by NetLogo’s terms, even when they were
    mostly in plain English. [N03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") was confused about \saywhy
    (ChatGPT) said something about patches (note: patches are static agents that form
    NetLogo’s modeling world), and that deepened her reliance on ChatGPT. [N10](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") realized that she \sayonly understand 20% of what I am
    reading, so I can’t vet it myself. When the interviewer asked about adding comments
    into code, [N03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣
    Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") replied that while it might
    be helpful, she was still missing \saythe high-level understanding of how it comes
    together.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Many novices also lack the experience for debugging, leading to more unsuccessful
    attempts and more frustrations. Participants, in particular novices, were often
    confused by error messages from NetLogo. [N01](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    acknowledged that \saywithout background knowledge, it is hard to figure out what
    the bugs are, if (LLM) gives you information that is inaccurate. Without experience
    in debugging, many novices felt frustrated and helpless as previously reported.
    On the other hand, [E12](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") noted that his students
    \saymight not be comfortable with the idea that debugging is a normal part of
    the process. [E01](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") believed that \saythe user
    needs a little practice in debugging their own code before working with LLM-based
    interfaces.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Most novices felt a need to learn to interact with LLMs. After repeated failures,
    [N01](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") felt that he did not \sayeven know what questions
    to ask to get it to, because it is not doing the right thing. [N06](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") thought AI would help a lot if she could \saylearn more about
    how to use AI. [N05](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") realized that he needed
    to use the correct keywords, for otherwise it \saywill never generate a good model.
    This knowledge is relatively easier to acquire though: while [N09](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") felt that \sayhow to ask questions is very important, she believed
    that \sayyou learn by actually doing it.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.3\. Needs for Guidance, Personalization, and Integration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table 6\. Users’ Needs for LLMs: Guidance, Personalization, and Integration'
  prefs: []
  type: TYPE_NORMAL
- en: '| Guidance | Personalization | Integration |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Should provide clear, less technical responses, stay on topic, and give smaller
    pieces of information at a time. | Should provide responses based on users’ preferred
    styles. | Should provide better support for coding chunks and iterative modeling.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Should provide responses based on authoritative sources and in NetLogo’s
    language. | Should provide responses based on the knowledge levels and interests
    of users. | Should support working on existing modeling code. |'
  prefs: []
  type: TYPE_TB
- en: '| Should assume less, clarify more, and stick to user intentions for modeling.
    | Should support human help-seeking preferences in different ways. | Should support
    input and output of computational modeling. |'
  prefs: []
  type: TYPE_TB
- en: 5.3.1\. ”Good” Responses, ”Bad” Responses
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Participants generally appreciate and expect less technical, clear instructions.
    Many of them appreciate NetLogo Chat’s design decisions that include authoritative
    sources in responses (see [3.1.2](#S3.SS1.SSS2 "3.1.2\. Invoke Authoritative Sources
    Whenever Possible ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat")) and ask back clarification questions
    (see [3.1.1](#S3.SS1.SSS1 "3.1.1\. Enable users to program the computer, rather
    than being programmed by the computer ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat
    System ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")). However, participants’
    preferences are also highly personal and situational.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For both designs, some participants explicitly went against excessive or unnecessary
    explanations, particularly when the goal is primarily to accomplish a task at
    hand. For instance, [E09](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") complained that GPT-4 \saytalks
    too much. I want the code, not the explanation yet. [E14](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") complained that while related code samples provided by NetLogo Chat could
    \saycontain a lot of good suggestions, she wanted to move them to \sayanother
    box or an expandable line.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some participants appreciated and hoped that LLMs could stay on topic and give
    smaller pieces of information at a time. [E01](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    thought NetLogo Chat would be more helpful if it only attempted to solve a bug
    \sayone at a time, for users \sayalways overfill their buffer. Novices, in particular,
    prefer concrete, step-by-step responses, given the focus they put on AI-generated
    instructions. [N04](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") wanted to \saytest one by
    one if (LLM) gave me multiple suggestions. Going beyond text responses, [N03](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") hoped that there could be \saya visual to help me better
    understand, or internalize what different elements of the code are, so her learning
    could move to a higher-level understanding of the code’s intention.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For NetLogo Chat, most participants reacted positively to the reference to
    authoritative sources (see [3.1.2](#S3.SS1.SSS2 "3.1.2\. Invoke Authoritative
    Sources Whenever Possible ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat System ‣
    Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")), the usage of NetLogo’s
    language, and the provision of links to sources. [E03](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") believed that \saythe possibility to go directly from this AI to the documentation
    would be helpful for his students. [N10](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    \sayautomatically like (NetLogo Chat’s response) better because it used \sayNetLogo’s
    kind of turtle and patch language. [E12](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    felt \saya little bit more confident in the information I was getting because
    it seemed to be coming from inside of the application. However, sticking too much
    to authoritative explanations might have a downside. [E10](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") complained that NetLogo Chat gave him \saydictionary reference, and \saydictionary
    definitions are not especially helpful.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Many participants, in particular experts, reacted positively when NetLogo Chat
    assumed less about and stuck more to their intentions (e.g. asking questions back,
    see [3.1.1](#S3.SS1.SSS1 "3.1.1\. Enable users to program the computer, rather
    than being programmed by the computer ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat
    System ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")). For example, [E09](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") commented that ChatGPT (GPT-4) \sayassumed what I wanted
    it to do, whereas this one makes you specify your assumptions. He prefers NetLogo
    Chat’s approach, because \sayit makes you think about the code more. [E12](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") felt that NetLogo Chat’s clarification of intention was
    akin to \sayprogressively guiding me towards a better prompt. As transparency
    is a key factor in computational modeling, [N11](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    feared that if \sayanyone can produce an agent-based model, but without actually
    understanding all the parameters, hidden assumptions introduced by ChatGPT could
    be detrimental.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.2\. Need for Personalization
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this section, we break down the strong needs of experts and novices for
    more personalization, besides response styles, into two themes: knowledge levels
    and help-seeking needs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Novices, in particular, felt a strong need for LLM-based interfaces to acknowledge
    their knowledge levels and produce responses accordingly. [N07](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") gave a stringent critique of both systems, feeling both systems
    were \saynot useful at all, for both \saypresumes you know something about NetLogo.
    [N08](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") felt that \sayChatGPT has no idea of how much or
    how little I know about how to code in NetLogo, or how to code in general. Solving
    this issue would require more personalized approaches. Coming from an educational
    background, both [N02](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") and [E03](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") suggested that LLMs should first probe the knowledge level of
    users before providing answers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Participants gave a variety of suggestions that were at times conflicting:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Some participants prefer a guided walkthrough. [N08](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") hoped that LLMs could walk him through the process and provide starting
    points. Both [E14](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") and [N03](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") hoped that LLMs could be used alongside video tutorials, where
    they could first see a successful example of human-AI collaboration and then ask
    follow-up questions.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Some participants prefer contextual recommendations. [N11](#S4.T2 "Table 2
    ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") hoped that LLMs could show related code examples and provide
    \saytwo or three other ways that you might look with. [E10](#S4.T2 "Table 2 ‣
    4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") suggested that LLMs provide in-context explanations if \sayyou
    don’t remember the definition or explanation of a particular command.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Some participants hope that LLMs could support help-seeking from humans. [E01](#S4.T2
    "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of
    Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using
    ChatGPT & NetLogo Chat") hoped that LLMs could help novices \sayexplain my situation
    so that I can paste it to the user group, so human experts could intervene more
    easily when AI fails to unstuck novices. Similarly, [E17](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") suggested that AI could be combined with \saypeer to peer answers and collaboration.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (4)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Some participants believed that incorrect responses could become a learning
    opportunity. [E02](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study
    ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") was concerned that students
    might be \sayexposed to fewer options with AI, compared with \saycoding from scratch.
    [E03](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") feared that a system capable of directly producing
    solutions might deprive students of the debugging process, where they would have
    learned.” Novices also had similar feelings. After many hallucinated responses,
    [N08](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming
    of Agent-based Modeling with LLM Companions: Experiences of Novices and Experts
    Using ChatGPT & NetLogo Chat") thought that ChatGPT \sayforces me to learn as
    opposed to just getting code that’s ready to go. To fully transform the moment
    of mistake into learning opportunities, educators suggest the design not to frame
    mistakes as failures, but rather \sayas a learning moment ([E12](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat")).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 5.3.3\. Need for Integration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Compared with ChatGPT in a separate browser window, most participants appreciated
    the NetLogo Chat interface being an integrated part of the modeling environment.
    They are particularly in favor of the deep integration in NetLogo Chat’s design
    that goes beyond placing a CA and an IDE side-by-side. We further identified many
    participants’ need for a deeper integration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many participants appreciated the integration of a sandbox-like code editor
    in NetLogo Chat, where they can tinker with smaller, AI-generated code chunks
    and execute them on the fly (see [3.1.3](#S3.SS1.SSS3 "3.1.3\. Integrate with
    the IDE and Enhance Troubleshooting ‣ 3.1\. Design Overview ‣ 3\. NetLogo Chat
    System ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")). [N12](#S4.T2 "Table 2
    ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") \saydefinitely liked this feature of being able to go easily
    between the code and see what was changed and what was added. [N04](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") appreciated that one can \saysee the code run in the NetLogo
    IDE, which ChatGPT could not do. [N13](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣
    4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM Companions:
    Experiences of Novices and Experts Using ChatGPT & NetLogo Chat") thought while
    some code generated by ChatGPT was \sayso comprehensive, NetLogo Chat was able
    to break it down and make them \saymore conducive. Participants also expressed
    further needs for iterative modeling. [E13](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    hoped that NetLogo Chat could help him \saymodularize all of my commands by splitting
    the code into many smaller, more manageable chunks. [E12](#S4.T2 "Table 2 ‣ 4.1\.
    Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling
    with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo
    Chat") asked for a comparison feature between versions of code chunks that could
    help him \sayiterative changes quickly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, participants also hoped that LLMs could help them reflect on longer
    pieces of (existing) code. [N02](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat") and [E02](#S4.T2 "Table
    2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based
    Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT
    & NetLogo Chat") wanted AI to support the combination of multiple, smaller code
    chunks into a single, coherent code. As such, LLM-based interfaces should be able
    to work with longer pieces of code. Both [N06](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    and [E08](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical Study ‣ Learning
    Programming of Agent-based Modeling with LLM Companions: Experiences of Novices
    and Experts Using ChatGPT & NetLogo Chat") hoped that NetLogo Chat could \saylook
    at my code and make suggestions based on my code.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Many participants needed adaptive support for modeling more than just coding.
    Many requested AI support in building model interfaces that could be used to take
    in inputs or send out outputs. For example, [N06](#S4.T2 "Table 2 ‣ 4.1\. Participants
    ‣ 4\. Empirical Study ‣ Learning Programming of Agent-based Modeling with LLM
    Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat")
    needed NetLogo for her academic paper, hence plotting became \sayvery important.
    For educators like [E13](#S4.T2 "Table 2 ‣ 4.1\. Participants ‣ 4\. Empirical
    Study ‣ Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat"), while the canvas output
    was \saygood for the three-quarters of a project, it hid \saythe real power of
    agent-based modeling - tracking the emergent properties of the model, rather than
    simply making bits run around the screen. During the modeling processes, many
    interface parts could become necessary or unnecessary depending on situational
    needs. Integrated LLM-based interfaces need to go beyond a \sayside chat window
    and support various spatial configurations for advanced users to decide on.'
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Discussions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our study first reported, in detail, how novices and experts perceive and use
    LLM-based interfaces (ChatGPT & NetLogo Chat) differently to support their learning
    and practice of computational modeling in an open-ended setting. Most participants
    appreciated the design direction NetLogo Chat is heading toward. However, they
    also expressed their needs for improved guidance, personalization, and integration
    which opens up huge design spaces for future improvement.
  prefs: []
  type: TYPE_NORMAL
- en: '6.1\. Guidance: Bridging the Novice-Expert Gap'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/359f95c4c14808c2f48cb631fedf85b2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5\. A preliminary theorization of the novice-expert knowledge gap.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 'This figure summarizes our theorization of the gap. The gap has two parts:
    knowledge to effectively decompose and plan modeling tasks in smaller pieces;
    knowledge to evaluate AI responses and identify potential issues. Both comprise
    two parts: conceptual knowledge of modeling; basic concepts of NetLogo and coding;
    experiences of debugging; and how to interact with LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: For most participants, guidance is what they need most from LLMs in programming.
    While hallucinations from LLMs constantly present a challenge to everyone, with
    a higher frequency to evaluate and debug AI responses, experts suffered less negative
    impact than novices. As a result, experts reported higher levels of perceived
    gains and more optimistic adoption plans than novices. While novices in our study
    also attempt to evaluate and debug AI responses, they are ill-equipped for these
    tasks. Without understanding the knowledge gap between experts and novices, it
    becomes impossible to design effective guidance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on our empirical findings, we theorize the two types of knowledge novices
    might need when collaborating with AI in computational modeling (Fig [5](#S6.F5
    "Figure 5 ‣ 6.1\. Guidance: Bridging the Novice-Expert Gap ‣ 6\. Discussions ‣
    Learning Programming of Agent-based Modeling with LLM Companions: Experiences
    of Novices and Experts Using ChatGPT & NetLogo Chat")). First, the knowledge to
    effectively decompose and plan modeling tasks. Second, the knowledge to evaluate
    AI responses and identify potential issues. We further identified four components
    of knowledge that both novices and experts reported to be essential: conceptual
    knowledge of modeling; basic concepts of NetLogo and coding; experiences of debugging;
    and how to interact with LLMs. To mitigate the impact of currently inevitable
    hallucinations of LLMs, it is essential to help novices get over the knowledge
    gap.'
  prefs: []
  type: TYPE_NORMAL
- en: We propose three learning moments where design intervention might work best.
    The first moment is when users plan their next steps. While most novices started
    by delegating the planning process to AI, most of them eventually planned on their
    own. Here, we follow the constructionist learning theory for a broader understanding
    of planning that includes both rigid, formal plans and ”softer”, ad-hoc exploration
    of problem spaces(Turkle and Papert, [1990](#bib.bib84)). Both planning styles
    should be recognized as legitimate in learning and supported by the design (Turkle
    and Papert, [1990](#bib.bib84)). With our current design, most novices reported
    positive feelings when NetLogo Chat attempted to clarify their intentions and
    produce a plan for their task. Since this phase does not involve any generated
    code, more support could be provided, as novices may have fewer problems reading
    and evaluating natural language responses. They may also feel more comfortable
    asking questions about modeling or programming ideas, relating them to the generated
    code later, without fearing that they cannot (yet) read or write code. Moreover,
    LLMs could expand learners’ visions by suggesting new ideas, proposing new plans,
    or taking notes of human ideas. When novices are confused about basic concepts,
    LLMs could suggest video or textual tutorials and provide Q&A along the way.
  prefs: []
  type: TYPE_NORMAL
- en: The second moment is when users read and evaluate LLM-generated code. Reading
    and understanding code is one of the most important aspects of computing education(Lopez
    et al., [2008](#bib.bib52)). However, novices in our study were neither confident
    nor equipped for reading code. As a result, they intended to skip the code section.
    As predicted by the interest development framework(Michaelis and Weintrop, [2022](#bib.bib57)),
    the lack of skills (knowledge) and confidence (identity) may mutually enhance
    each other. Breaking the feedback loop requires designers to scaffold their reading
    experiences in both directions. By making explanations within code (as comments
    or tooltips) or visualizing the code structures (e.g. (Sorva et al., [2013](#bib.bib77))),
    we might be able to help build novices’ connections between code syntax and real-world
    meanings. To build up learners’ confidence, LLMs should deliver code pieces and
    explanations in adaptive sizes that work for learners. For learners who still
    could not succeed, the interface should further provide ad-hoc support that helps
    novices ask follow-up questions, or lead them to appropriate learning resources.
  prefs: []
  type: TYPE_NORMAL
- en: The third moment is when users need to debug their code. Debugging is considered
    a rich learning opportunity in constructionist learning(Kafai et al., [2020](#bib.bib40)).
    However, it is often associated with negative feelings that both manifested in
    prior literature(Whalley et al., [2021a](#bib.bib92)), as well as our findings.
    Unfortunately, cognitive science has found that negative moods may further impede
    debugging performance(Khan et al., [2011](#bib.bib44)), enlarging the gap between
    novices and experts. Following the suggestions of educators in our study, we suggest
    that LLM-based interfaces could frame bugs in a more positive light, while providing
    a link to a successful human-AI collaborative debugging process for first-time
    learners. Both novices’ and LLMs’ debugging processes are often stuck in loops(Whalley
    et al., [2021b](#bib.bib93); Wu et al., [2023](#bib.bib98)). While such situations
    are inevitable, some expert participants suggest that LLM-based interfaces could
    encourage learners to seek help from another human. Help-seeking is recognized
    as an important part of programming education, yet novices often struggle with
    it(Marwan et al., [2020](#bib.bib55)). In such cases, LLM-based interfaces should
    further help them frame questions for human experts.
  prefs: []
  type: TYPE_NORMAL
- en: '6.2\. Personalization: Beyond “Correctness” of LLMs'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Personalization has been identified as an essential factor for perceived autonomy
    when users interact with conversational agents(Yang and Aurisicchio, [2021](#bib.bib99)),
    for emotional and relational connections(Wellner and Levin, [2023](#bib.bib90)),
    and for various educational benefits(Bernacki et al., [2021](#bib.bib7)). Adding
    to previous literature, we found personalization to be a crucial factor for LLMs
    to facilitate effective guidance for learning, as participants expect LLMs to
    recognize their knowledge levels and react accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: While LLMs might have the potential to further the personalization of learning,
    recent research in LLMs focused on the “objective” capabilities, ignoring the
    personalized aspect of its evaluation. For example, technical reports of LLMs
    all reported benchmarks in whether they could produce functionally correct programs
    (HumanEval)(Chen et al., [2021](#bib.bib16)); if they could correctly answer multi-choice
    questions (MMLU)(Hendrycks et al., [2020](#bib.bib34)); or if they could produce
    the correct answer of grade school mathematical problems (GSM-8K)(Cobbe et al.,
    [2021](#bib.bib21)). While working toward such “correctness” benchmarks is certainly
    crucial for LLMs to reduce hallucination and produce better responses, it becomes
    problematic when the definition of “helpfulness” or “harmfulness” is measured
    with a ubiquitous scale without individual differences (Bai et al., [2022](#bib.bib3)),
    and such a definition has since been adopted by all major players in LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: 'At least in learning and practice programming, we argue that helpfulness cannot
    be a singular metric, but instead varies based on many factors. Corroborating
    with constructionist design principles(Resnick and Silverman, [2005](#bib.bib67)),
    we identified some potentially important factors such as knowledge levels and
    help-seeking preferences, while other factors such as culture, ethnicity, and
    gender could be as important. To support human learning, the full potential of
    LLMs could only be achieved through the recognition of epistemological pluralism(Turkle
    and Papert, [1990](#bib.bib84)): humans have different approaches toward learning,
    and technology needs to be tailored to human needs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Most participants in our study expected or asked for personalization, in the
    sense that LLMs recognize their knowledge levels and help-seeking needs, yet today’s
    designs are still far from that. While it is virtually impossible to fine-tune
    thousands of LLM variants, LLMs’ role-play capabilities and novel prompt-based
    workflows (e.g. the one used by NetLogo Chat, or the concept of GPTs very recently
    released by OpenAI) have shown promising potential. As personalization requires
    the inevitable and sometimes controversial collection of user data, we suggest
    a more upfront approach: only collecting data that directly contributes to a more
    helpful AI (e.g. the knowledge level), only using data for this purpose, and explaining
    the benefits, risks, and privacy processes at the beginning. Alternatively, designers
    could also consider flowing the pathway of cognitive modeling, which deduces learners’
    knowledge levels from known interactions with the system(Sun, [2008](#bib.bib78)).
    On the other hand, our understanding of users’ perceptions, behaviors, and needs
    for LLM-based programming interfaces has just begun, and we call on more studies
    to pursue this direction.'
  prefs: []
  type: TYPE_NORMAL
- en: '6.3\. Integration: LLMs for Computational Modeling'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For most participants, integration between LLM-based interfaces and modeling
    environments goes beyond stitching a chat window into the IDE. While most of them
    appreciated NetLogo Chat’s design directions, they put forward many needs that
    are worth considering in future design. Here, we briefly discuss the two major
    themes: support for troubleshooting; and support for modeling. For troubleshooting:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The capability to work on smaller snippets of code, with the capability to execute,
    explain, and debug code in context. For both humans and LLMs(Hou et al., [2023](#bib.bib35)),
    debugging complicated code is known to be difficult. NetLogo Chat has made the
    first step in reducing the scope to smaller code chunks. As such, it becomes easier
    for both humans to debug and LLMs to support their debugging processes. Whereas,
    more work is needed to bring together the code chunks into coherent full programs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The capability to leverage authoritative NetLogo documentation in generated
    responses, as well as for the user’s own reference. In debugging contexts, LLMs’
    tendency to hallucinate becomes more frustrating. By providing users and LLMs
    with authoritative explanations within the debugging context, NetLogo Chat may
    reduce the effort for users to seek related information, which is also known to
    be difficult for novices(Dorn et al., [2013](#bib.bib25)). More work is needed
    to explain in a more personalized way: for example, pure novices may need explanations
    for every basic term.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The capability to automatically send in contextual information (i.e. code and
    error messages) for LLM to troubleshoot. Users generally appreciated NetLogo Chat’s
    design decision to support troubleshooting. However, the convenience came with
    a potential price: when using NetLogo Chat, users were more likely to ask LLMs
    for help, which might lead to fewer human attempts and learning opportunities.
    Further studies are needed to understand this design balance better.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Many participants also asked for features that specifically support their computational
    modeling tasks, which are known to have different priorities from programming
    in general(Pylyshyn, [1978](#bib.bib66)). Here, two more capabilities are warranted:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The capability to assume less, actively probe, and stick to user intentions.
    In addition to the potential learning opportunities (see Discussion 1), for participants,
    hidden assumptions in scientific modeling are particularly harmful. While users
    appreciate NetLogo Chat’s direction in having LLMs ask questions back, future
    interfaces should be able to facilitate the conversational build-up of plans and
    steps, further supporting users to program computers piece-by-piece rather than
    falling to hidden assumptions made by LLMs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The capability to support modeling practices beyond coding. Building the program
    is only one step; computational modeling also involves design, data visualization,
    and validation(Weintrop et al., [2016](#bib.bib89)). For LLM-based interfaces
    to support modeling practices, future interfaces should go beyond coding to support
    users’ efforts throughout the modeling process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 7\. Limitations and Future Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are limitations to our study that warrant future work. As a widely used
    agent-based modeling language, a deeper understanding of user perceptions, behaviors,
    and needs for LLM-based interfaces around NetLogo may inform us of design choices
    for other modeling environments. Future work should consider computational modeling
    or programming environments that might have different priorities. Since the NetLogo
    language was designed for an audience without a computer science background(Tisue
    and Wilensky, [2004](#bib.bib83)), it becomes more important and meaningful to
    understand how to design for bridging the novice-expert gap in LLM-based interfaces.
    However, it is unclear whether our findings and suggestions would sufficiently
    support novices’ and experts’ learning and practice of NetLogo. Using a more rigid
    rubric to distinguish between experts and novices might improve the rigor of our
    study. A quantitative, controlled study in the future might further (in)validate
    our findings and suggestions. As such, we plan to work on a new iteration of NetLogo
    Chat design and empirical study to fully understand the design implications.
  prefs: []
  type: TYPE_NORMAL
- en: Although we aimed to recruit participants representative of NetLogo’s global
    audience, our participant pool was not as representative as we hoped in two key
    dimensions. First, our participants were mostly professionals, academics, and
    graduate students. While K-12 teachers and learners are another major audience
    for NetLogo and agent-based modeling and may have different priorities and preferences(Sengupta
    et al., [2015](#bib.bib72)), only one K-12 teacher was present in the study. More
    studies are warranted to further the empirical understanding of LLM-based interfaces
    in education contexts. Second, the demographics of our participants skewed towards
    North American and European, highly educated, and male. Such a group of participants,
    recruited voluntarily, might manifest higher than average acceptability toward
    novel technology, e.g. most of our participants have already engaged with ChatGPT.
    For future work, researchers need to recruit a more balanced and diverse group
    of participants, if the goal is for LLM-based programming interfaces to equitably
    support novices and experts throughout the world.
  prefs: []
  type: TYPE_NORMAL
- en: 8\. Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As Large language models (LLMs) have the potential to fundamentally change
    how people learn and practice computational modeling and programming in general,
    it is crucial that we gain a deeper understanding of users’ perceptions, behaviors,
    and needs in a more naturalistic setting. For this purpose, we designed and developed
    NetLogo Chat, a novel LLM-based system that supports and integrates with a version
    of NetLogo IDE. We conducted an interview study with 30 adult participants to
    understand how they perceived, collaborated with, and asked for LLM-based interfaces
    for learning and practice of NetLogo. Consistent with previous studies, experts
    reported more perceived benefits than novices. We found remarkable differences
    between novices and experts in their perceptions, behaviors, and needs. We identified
    a knowledge gap that might have contributed to the differences. We proposed design
    recommendations around participants’ main needs: guidance, personalization, and
    integration. Our findings inform future design of LLM-based programming interfaces,
    especially for computational modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We would like to express our gratitude to the [NetLogo Online community](https://community.netlogo.org/)
    and [Complexity Explorer](https://www.complexityexplorer.org/) for their help
    and support. We are especially thankful to the hundreds of NetLogo users who volunteered
    for the study. We would also like to thank current and former members of our lab
    and anonymous youth users of Turtle Universe, who provided valuable feedback and
    ideas during our design process. Specifically, we want to acknowledge the intellectual
    contributions of Umit Aslan; Aaron Brandes; Jeremy Baker; Jason Bertsche; Matthew
    Berland; Sharona Levy; Jacob Kelter; Leif Rasmussen; David Weintrop; and Lexie
    Zhao. Finally, we appreciate the valuable and actionable feedback from our anonymous
    CHI reviewers, which significantly strengthened the paper.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: noa ([n. d.]) [n. d.]. Using GitHub Copilot Chat. [https://ghdocs-prod.azurewebsites.net/en/copilot/github-copilot-chat/using-github-copilot-chat](https://ghdocs-prod.azurewebsites.net/en/copilot/github-copilot-chat/using-github-copilot-chat)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bai et al. (2022) Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna
    Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas
    Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson
    Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna
    Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack
    Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared Kaplan. 2022. Training
    a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback.
    [https://doi.org/10.48550/arXiv.2204.05862](https://doi.org/10.48550/arXiv.2204.05862)
    arXiv:2204.05862 [cs].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Balse et al. (2023) Rishabh Balse, Bharath Valaboju, Shreya Singhal, Jayakrishnan Madathil
    Warriem, and Prajish Prasad. 2023. Investigating the Potential of GPT-3 in Providing
    Feedback for Programming Assessments. In *Proceedings of the 2023 Conference on
    Innovation and Technology in Computer Science Education V. 1* *(ITiCSE 2023)*.
    Association for Computing Machinery, New York, NY, USA, 292–298. [https://doi.org/10.1145/3587102.3588852](https://doi.org/10.1145/3587102.3588852)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Barke et al. (2023) Shraddha Barke, Michael B. James, and Nadia Polikarpova.
    2023. Grounded copilot: How programmers interact with code-generating models.
    *Proceedings of the ACM on Programming Languages* 7, OOPSLA1 (2023), 85–111. Publisher:
    ACM New York, NY, USA.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Becker et al. (2019) Brett A Becker, Paul Denny, Raymond Pettit, Durell Bouchard,
    Dennis J Bouvier, Brian Harrington, Amir Kamil, Amey Karkare, Chris McDonald,
    Peter-Michael Osera, et al. 2019. Compiler error messages considered unhelpful:
    The landscape of text-based programming error message research. *Proceedings of
    the working group reports on innovation and technology in computer science education*
    (2019), 177–210.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bernacki et al. (2021) Matthew L. Bernacki, Meghan J. Greene, and Nikki G.
    Lobczowski. 2021. A systematic review of research on personalized learning: Personalized
    by whom, to what, how, and for what purpose (s)? *Educational Psychology Review*
    33, 4 (2021), 1675–1715. Publisher: Springer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blikstein (2011) Paulo Blikstein. 2011. Using learning analytics to assess students’
    behavior in open-ended programming tasks. In *Proceedings of the 1st international
    conference on learning analytics and knowledge*. 110–116.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Blikstein et al. (2014) Paulo Blikstein, Marcelo Worsley, Chris Piech, Mehran
    Sahami, Steven Cooper, and Daphne Koller. 2014. Programming pluralism: Using learning
    analytics to detect patterns in the learning of computer programming. *Journal
    of the Learning Sciences* 23, 4 (2014), 561–599. Publisher: Taylor & Francis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Brady et al. (2020) Corey Brady, Melissa Gresalfi, Selena Steinberg, and Madison
    Knowe. 2020. Debugging for Art’s Sake: Beginning Programmers’ Debugging Activity
    in an Expressive Coding Context. (June 2020). [https://repository.isls.org//handle/1/6319](https://repository.isls.org//handle/1/6319)
    Publisher: International Society of the Learning Sciences (ISLS).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bull and Kharrufa (2023) Christopher Bull and Ahmed Kharrufa. 2023. Generative
    AI Assistants in Software Development Education: A vision for integrating Generative
    AI into educational practice, not instinctively defending against it. *IEEE Software*
    (2023), 1–9. [https://doi.org/10.1109/MS.2023.3300574](https://doi.org/10.1109/MS.2023.3300574)
    Conference Name: IEEE Software.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Caballé and Conesa (2019) Santi Caballé and Jordi Conesa. 2019. Conversational
    agents in support for collaborative learning in MOOCs: An analytical review. In
    *Advances in Intelligent Networking and Collaborative Systems: The 10th International
    Conference on Intelligent Networking and Collaborative Systems (INCoS-2018)*.
    Springer, 384–394.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2022) Fuxiang Chen, Fatemeh H. Fard, David Lo, and Timofey Bryksin.
    2022. On the transferability of pre-trained language models for low-resource programming
    languages. In *Proceedings of the 30th IEEE/ACM International Conference on Program
    Comprehension*. 401–412.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen and Wilensky (2021) John Chen and Uri J. Wilensky. 2021. Turtle Universe.
    [https://turtlesim.com/products/turtle-universe/](https://turtlesim.com/products/turtle-universe/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2023b) John Chen, Lexie Zhao, Horn Michael, and Wilensky Uri.
    2023b. The Pocketworld Playground: Engaging Online, Out-of-School Learners with
    Agent-based Programming. In *Proceedings of the ACM Interaction Design and Children
    (IDC)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2021) Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique
    Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
    and Greg Brockman. 2021. Evaluating large language models trained on code. *arXiv
    preprint arXiv:2107.03374* (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2023a) Zhutian Chen, Chenyang Zhang, Qianwen Wang, Jakob Troidl,
    Simon Warchol, Johanna Beyer, Nils Gehlenborg, and Hanspeter Pfister. 2023a. Beyond
    Generating Code: Evaluating GPT on a Data Visualization Course. [https://doi.org/10.48550/arXiv.2306.02914](https://doi.org/10.48550/arXiv.2306.02914)
    arXiv:2306.02914 [cs].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chi et al. (1981) Michelene TH Chi, Paul J Feltovich, and Robert Glaser. 1981.
    Categorization and representation of physics problems by experts and novices.
    *Cognitive science* 5, 2 (1981), 121–152.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Clark et al. (2009) Douglas Clark, Brian Nelson, Pratim Sengupta, and Cynthia
    D’Angelo. 2009. Rethinking science learning through digital games and simulations:
    Genres, examples, and evidence. In *Learning science: Computer games, simulations,
    and education workshop sponsored by the National Academy of Sciences, Washington,
    DC*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clark et al. (2019) Leigh Clark, Nadia Pantidi, Orla Cooney, Philip Doyle, Diego
    Garaialde, Justin Edwards, Brendan Spillane, Emer Gilmartin, Christine Murad,
    and Cosmin Munteanu. 2019. What makes a good conversation? Challenges in designing
    truly conversational agents. In *Proceedings of the 2019 CHI conference on human
    factors in computing systems*. 1–12.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cobbe et al. (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen,
    Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
    Nakano, Christopher Hesse, and John Schulman. 2021. Training Verifiers to Solve
    Math Word Problems. [https://doi.org/10.48550/arXiv.2110.14168](https://doi.org/10.48550/arXiv.2110.14168)
    arXiv:2110.14168 [cs].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cooper (2023) Grant Cooper. 2023. Examining Science Education in ChatGPT: An
    Exploratory Study of Generative Artificial Intelligence. *Journal of Science Education
    and Technology* 32, 3 (June 2023), 444–452. [https://doi.org/10.1007/s10956-023-10039-y](https://doi.org/10.1007/s10956-023-10039-y)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Corbin and Strauss (1990) Juliet M. Corbin and Anselm Strauss. 1990. Grounded
    theory research: Procedures, canons, and evaluative criteria. *Qualitative sociology*
    13, 1 (1990), 3–21. Publisher: Springer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dakhel et al. (2023) Arghavan Moradi Dakhel, Vahid Majdinasab, Amin Nikanjam,
    Foutse Khomh, Michel C. Desmarais, and Zhen Ming Jack Jiang. 2023. Github copilot
    ai pair programmer: Asset or liability? *Journal of Systems and Software* 203
    (2023), 111734. Publisher: Elsevier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dorn et al. (2013) Brian Dorn, Adam Stankiewicz, and Chris Roggi. 2013. Lost
    while searching: Difficulties in information seeking among end-user programmers.
    *Proceedings of the American Society for Information Science and Technology* 50,
    1 (2013), 1–10. Publisher: Wiley Online Library.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Eloundou et al. (2023) Tyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel
    Rock. 2023. Gpts are gpts: An early look at the labor market impact potential
    of large language models. *arXiv preprint arXiv:2303.10130* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fiannaca et al. (2023) Alexander J. Fiannaca, Chinmay Kulkarni, Carrie J. Cai,
    and Michael Terry. 2023. Programming without a Programming Language: Challenges
    and Opportunities for Designing Developer Tools for Prompt Programming. In *Extended
    Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems*. 1–7.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finnie-Ansley et al. (2022) James Finnie-Ansley, Paul Denny, Brett A. Becker,
    Andrew Luxton-Reilly, and James Prather. 2022. The robots are coming: Exploring
    the implications of openai codex on introductory programming. In *Proceedings
    of the 24th Australasian Computing Education Conference*. 10–19.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fleischmann and Wallace (2009) Kenneth R. Fleischmann and William A. Wallace.
    2009. Ensuring transparency in computational modeling. *Commun. ACM* 52, 3 (March
    2009), 131–134. [https://doi.org/10.1145/1467247.1467278](https://doi.org/10.1145/1467247.1467278)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fu et al. (2023) Yue Fu, Mingrui Zhang, Lynn K. Nguyen, Yifan Lin, Rebecca
    Michelson, Tala June Tayebi, and Alexis Hiniker. 2023. Self-Talk with Superhero
    Zip: Supporting Children’s Socioemotional Learning with Conversational Agents.
    In *Proceedings of the 22nd Annual ACM Interaction Design and Children Conference*.
    173–186.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gero et al. (2020) Katy Ilonka Gero, Zahra Ashktorab, Casey Dugan, Qian Pan,
    James Johnson, Werner Geyer, Maria Ruiz, Sarah Miller, David R. Millen, Murray
    Campbell, Sadhana Kumaravel, and Wei Zhang. 2020. Mental Models of AI Agents in
    a Cooperative Game Setting. In *Proceedings of the 2020 CHI Conference on Human
    Factors in Computing Systems* *(CHI ’20)*. Association for Computing Machinery,
    New York, NY, USA, 1–12. [https://doi.org/10.1145/3313831.3376316](https://doi.org/10.1145/3313831.3376316)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gong et al. (2022) Zi Gong, Yinpeng Guo, Pingyi Zhou, Cuiyun Gao, Yasheng Wang,
    and Zenglin Xu. 2022. MultiCoder: Multi-Programming-Lingual Pre-Training for Low-Resource
    Code Completion. [https://doi.org/10.48550/arXiv.2212.09666](https://doi.org/10.48550/arXiv.2212.09666)
    arXiv:2212.09666 [cs].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Harel and Papert (1990) Idit Harel and Seymour Papert. 1990. Software design
    as a learning environment. *Interactive learning environments* 1, 1 (1990), 1–32.
    Publisher: Taylor & Francis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hendrycks et al. (2020) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou,
    Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020. Measuring Massive Multitask
    Language Understanding. [https://openreview.net/forum?id=d7KBjmI3GmQ](https://openreview.net/forum?id=d7KBjmI3GmQ)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hou et al. (2023) Xinyi Hou, Yanjie Zhao, Yue Liu, Zhou Yang, Kailong Wang,
    Li Li, Xiapu Luo, David Lo, John Grundy, and Haoyu Wang. 2023. Large Language
    Models for Software Engineering: A Systematic Literature Review. [http://arxiv.org/abs/2308.10620](http://arxiv.org/abs/2308.10620)
    arXiv:2308.10620 [cs].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hutchins et al. (2020) Nicole M. Hutchins, Gautam Biswas, Ningyu Zhang, Caitlin
    Snyder, Ákos Lédeczi, and Miklós Maróti. 2020. Domain-specific modeling languages
    in computer-based learning environments: A systematic approach to support science
    learning through computational modeling. *International Journal of Artificial
    Intelligence in Education* 30 (2020), 537–580. Publisher: Springer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jeong et al. (2019) Yuin Jeong, Juho Lee, and Younah Kang. 2019. Exploring Effects
    of Conversational Fillers on User Perception of Conversational Agents. In *Extended
    Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems* *(CHI
    EA ’19)*. Association for Computing Machinery, New York, NY, USA, 1–6. [https://doi.org/10.1145/3290607.3312913](https://doi.org/10.1145/3290607.3312913)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. (2022) Ellen Jiang, Edwin Toh, Alejandra Molina, Kristen Olson,
    Claire Kayacik, Aaron Donsbach, Carrie J. Cai, and Michael Terry. 2022. Discovering
    the syntax and strategies of natural language programming with generative language
    models. In *Proceedings of the 2022 CHI Conference on Human Factors in Computing
    Systems*. 1–19.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Joshi et al. (2023) Harshit Joshi, José Cambronero Sanchez, Sumit Gulwani,
    Vu Le, Gust Verbruggen, and Ivan Radiček. 2023. Repair Is Nearly Generation: Multilingual
    Program Repair with LLMs. *Proceedings of the AAAI Conference on Artificial Intelligence*
    37, 4 (June 2023), 5131–5140. [https://doi.org/10.1609/aaai.v37i4.25642](https://doi.org/10.1609/aaai.v37i4.25642)
    Number: 4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kafai et al. (2020) Yasmin Kafai, Gautam Biswas, Nicole Hutchins, Caitlin Snyder,
    Karen Brennan, Paulina Haduong, Kayla DesPortes, Morgan Fong, Virginia J. Flood,
    and Oia Walker-van Aalst. 2020. Turning bugs into learning opportunities: understanding
    debugging processes, perspectives, and pedagogies. (2020). Publisher: International
    Society of the Learning Sciences (ISLS).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kafai and Burke (2015) Yasmin B. Kafai and Quinn Burke. 2015. Constructionist
    Gaming: Understanding the Benefits of Making Games for Learning. *Educational
    Psychologist* 50, 4 (Oct. 2015), 313–334. [https://doi.org/10.1080/00461520.2015.1124022](https://doi.org/10.1080/00461520.2015.1124022)
    Publisher: Routledge _eprint: https://doi.org/10.1080/00461520.2015.1124022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kahn and Winters (2021) Ken Kahn and Niall Winters. 2021. Constructionism and
    AI: A history and possible futures. *British Journal of Educational Technology*
    52, 3 (2021), 1130–1142. Publisher: Wiley Online Library.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kazemitabaar et al. (2023) Majeed Kazemitabaar, Justin Chow, Carl Ka To Ma,
    Barbara J. Ericson, David Weintrop, and Tovi Grossman. 2023. Studying the effect
    of AI Code Generators on Supporting Novice Learners in Introductory Programming.
    *arXiv preprint arXiv:2302.07427* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Khan et al. (2011) Iftikhar Ahmed Khan, Willem-Paul Brinkman, and Robert M Hierons.
    2011. Do moods affect programmers’ debug performance? *Cognition, Technology &
    Work* 13 (2011), 245–258.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Khan and Uddin (2022) Junaed Younus Khan and Gias Uddin. 2022. Automatic code
    documentation generation using gpt-3\. In *Proceedings of the 37th IEEE/ACM International
    Conference on Automated Software Engineering*. 1–6.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kumar et al. (2023) Varun Kumar, Leonard Gleyzer, Adar Kahana, Khemraj Shukla,
    and George Em Karniadakis. 2023. MyCrunchGPT: A chatGPT assisted framework for
    scientific machine learning. [https://doi.org/10.48550/arXiv.2306.15551](https://doi.org/10.48550/arXiv.2306.15551)
    arXiv:2306.15551 [physics].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lau and Guo (2023) Sam Lau and Philip J. Guo. 2023. From” Ban It Till We Understand
    It” to” Resistance is Futile”: How University Programming Instructors Plan to
    Adapt as More Students Use AI Code Generation and Explanation Tools such as ChatGPT
    and GitHub Copilot. (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2005) Yunyao Li, Huahai Yang, and Hosagrahar V. Jagadish. 2005.
    Nalix: an interactive natural language interface for querying xml. In *Proceedings
    of the 2005 ACM SIGMOD international conference on Management of data*. 900–902.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. (2020) Phoebe Lin, Jessica Van Brummelen, Galit Lukin, Randi Williams,
    and Cynthia Breazeal. 2020. Zhorai: Designing a Conversational Agent for Children
    to Explore Machine Learning Concepts. *Proceedings of the AAAI Conference on Artificial
    Intelligence* 34, 09 (April 2020), 13381–13388. [https://doi.org/10.1609/aaai.v34i09.7061](https://doi.org/10.1609/aaai.v34i09.7061)
    Number: 09.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ling et al. (2021) Erin Chao Ling, Iis Tussyadiah, Aarni Tuomi, Jason Stienmetz,
    and Athina Ioannou. 2021. Factors influencing users’ adoption and use of conversational
    agents: A systematic review. *Psychology & marketing* 38, 7 (2021), 1031–1051.
    Publisher: Wiley Online Library.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2023) Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang.
    2023. Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of
    Large Language Models for Code Generation. [https://doi.org/10.48550/arXiv.2305.01210](https://doi.org/10.48550/arXiv.2305.01210)
    arXiv:2305.01210 [cs].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lopez et al. (2008) Mike Lopez, Jacqueline Whalley, Phil Robbins, and Raymond
    Lister. 2008. Relationships between reading, tracing and writing skills in introductory
    programming. In *Proceedings of the fourth international workshop on computing
    education research*. 101–112.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MacNeil et al. (2022) Stephen MacNeil, Andrew Tran, Dan Mogil, Seth Bernstein,
    Erin Ross, and Ziheng Huang. 2022. Generating diverse code explanations using
    the gpt-3 large language model. In *Proceedings of the 2022 ACM Conference on
    International Computing Education Research-Volume 2*. 37–39.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Magueresse et al. (2020) Alexandre Magueresse, Vincent Carles, and Evan Heetderks.
    2020. Low-resource Languages: A Review of Past Work and Future Challenges. [http://arxiv.org/abs/2006.07264](http://arxiv.org/abs/2006.07264)
    arXiv:2006.07264 [cs].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Marwan et al. (2020) Samiha Marwan, Anay Dombe, and Thomas W Price. 2020. Unproductive
    help-seeking in programming: What it is and how to address it. In *Proceedings
    of the 2020 ACM Conference on Innovation and Technology in Computer Science Education*.
    54–60.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: McNutt et al. (2023) Andrew M. McNutt, Chenglong Wang, Robert A. Deline, and
    Steven M. Drucker. 2023. On the design of ai-powered code assistants for notebooks.
    In *Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems*.
    1–16.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Michaelis and Weintrop (2022) Joseph E. Michaelis and David Weintrop. 2022.
    Interest Development Theory in Computing Education: A Framework and Toolkit for
    Researchers and Designers. *ACM Transactions on Computing Education (TOCE)* (2022).
    Publisher: ACM New York, NY.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nam et al. (2023) Daye Nam, Andrew Macvean, Vincent Hellendoorn, Bogdan Vasilescu,
    and Brad Myers. 2023. In-IDE Generation-based Information Support with a Large
    Language Model. [https://doi.org/10.48550/arXiv.2307.08177](https://doi.org/10.48550/arXiv.2307.08177)
    arXiv:2307.08177 [cs].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI (2023) OpenAI. 2023. GPT-4 Technical Report. [https://doi.org/10.48550/arXiv.2303.08774](https://doi.org/10.48550/arXiv.2303.08774)
    arXiv:2303.08774 [cs].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pal et al. (2023) Soumen Pal, Manojit Bhattacharya, Sang-Soo Lee, and Chiranjib
    Chakraborty. 2023. A Domain-Specific Next-Generation Large Language Model (LLM)
    or ChatGPT is Required for Biomedical Engineering and Research. *Annals of Biomedical
    Engineering* (2023), 1–4. Publisher: Springer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Papert (1980) Seymour Papert. 1980. Mindstorms: Children, computers, and powerful
    ideas. (1980). Publisher: Basic Books.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Papert and Harel (1991) Seymour Papert and Idit Harel. 1991. Situating constructionism.
    *constructionism* 36, 2 (1991), 1–11.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peng et al. (2023) Sida Peng, Eirini Kalliamvakou, Peter Cihon, and Mert Demirer.
    2023. The Impact of AI on Developer Productivity: Evidence from GitHub Copilot.
    [https://doi.org/10.48550/arXiv.2302.06590](https://doi.org/10.48550/arXiv.2302.06590)
    arXiv:2302.06590 [cs].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perry et al. (2022) Neil Perry, Megha Srivastava, Deepak Kumar, and Dan Boneh.
    2022. Do Users Write More Insecure Code with AI Assistants? [https://doi.org/10.48550/arXiv.2211.03622](https://doi.org/10.48550/arXiv.2211.03622)
    arXiv:2211.03622 [cs].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Price et al. (2000) David Price, Ellen Rilofff, Joseph Zachary, and Brandon
    Harvey. 2000. NaturalJava: A natural language interface for programming in Java.
    In *Proceedings of the 5th international conference on Intelligent user interfaces*.
    207–211.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pylyshyn (1978) Zenon W. Pylyshyn. 1978. Computational models and empirical
    constraints. *Behavioral and Brain Sciences* 1, 1 (March 1978), 91–99. [https://doi.org/10.1017/S0140525X00059793](https://doi.org/10.1017/S0140525X00059793)
    Publisher: Cambridge University Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resnick and Silverman (2005) Mitchel Resnick and Brian Silverman. 2005. Some
    reflections on designing construction kits for kids. In *Proceedings of the 2005
    conference on Interaction design and children*. 117–122.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robe and Kuttal (2022) Peter Robe and Sandeep Kaur Kuttal. 2022. Designing PairBuddy—A
    Conversational Agent for Pair Programming. *ACM Transactions on Computer-Human
    Interaction* 29, 4 (May 2022), 34:1–34:44. [https://doi.org/10.1145/3498326](https://doi.org/10.1145/3498326)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ross et al. (2023) Steven I. Ross, Fernando Martinez, Stephanie Houde, Michael
    Muller, and Justin D. Weisz. 2023. The programmer’s assistant: Conversational
    interaction with a large language model for software development. In *Proceedings
    of the 28th International Conference on Intelligent User Interfaces*. 491–514.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sannon et al. (2020) Shruti Sannon, Brett Stoll, Dominic DiFranzo, Malte F.
    Jung, and Natalya N. Bazarova. 2020. “I just shared your responses”: Extending
    Communication Privacy Management Theory to Interactions with Conversational Agents.
    *Proceedings of the ACM on Human-Computer Interaction* 4, GROUP (Jan. 2020), 08:1–08:18.
    [https://doi.org/10.1145/3375188](https://doi.org/10.1145/3375188)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Savelka et al. (2023) Jaromir Savelka, Arav Agarwal, Marshall An, Chris Bogart,
    and Majd Sakr. 2023. Thrilled by Your Progress! Large Language Models (GPT-4)
    No Longer Struggle to Pass Assessments in Higher Education Programming Courses.
    In *Proceedings of the 2023 ACM Conference on International Computing Education
    Research V.1*. 78–92. [https://doi.org/10.1145/3568813.3600142](https://doi.org/10.1145/3568813.3600142)
    arXiv:2306.10073 [cs].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sengupta et al. (2015) Pratim Sengupta, Amanda Dickes, Amy Voss Farris, Ashlyn
    Karan, David Martin, and Mason Wright. 2015. Programming in K-12 science classrooms.
    *Commun. ACM* 58, 11 (Oct. 2015), 33–35. [https://doi.org/10.1145/2822517](https://doi.org/10.1145/2822517)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sengupta et al. (2013) Pratim Sengupta, John S. Kinnebrew, Satabdi Basu, Gautam
    Biswas, and Douglas Clark. 2013. Integrating computational thinking with K-12
    science education using agent-based computation: A theoretical framework. *Education
    and Information Technologies* 18, 2 (June 2013), 351–380. [https://doi.org/10.1007/s10639-012-9240-x](https://doi.org/10.1007/s10639-012-9240-x)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Setlur et al. (2016) Vidya Setlur, Sarah E. Battersby, Melanie Tory, Rich Gossweiler,
    and Angel X. Chang. 2016. Eviza: A natural language interface for visual analysis.
    In *Proceedings of the 29th annual symposium on user interface software and technology*.
    365–377.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Skjuve et al. (2023) Marita Skjuve, Asbjørn Følstad, and Petter Bae Brandtzaeg.
    2023. The User Experience of ChatGPT: Findings from a Questionnaire Study of Early
    Users. In *Proceedings of the 5th International Conference on Conversational User
    Interfaces*. 1–10.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Solomon et al. (2020) Cynthia Solomon, Brian Harvey, Ken Kahn, Henry Lieberman,
    Mark L. Miller, Margaret Minsky, Artemis Papert, and Brian Silverman. 2020. History
    of logo. *Proceedings of the ACM on Programming Languages* 4, HOPL (2020), 1–66.
    Publisher: ACM New York, NY, USA.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sorva et al. (2013) Juha Sorva, Ville Karavirta, and Lauri Malmi. 2013. A review
    of generic program visualization systems for introductory programming education.
    *ACM Transactions on Computing Education (TOCE)* 13, 4 (2013), 1–64.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun (2008) Ron Sun. 2008. Introduction to computational cognitive modeling.
    *Cambridge handbook of computational psychology* (2008), 3–19.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tan et al. (2023) Chee Wei Tan, Shangxin Guo, Man Fai Wong, and Ching Nam Hang.
    2023. Copilot for Xcode: Exploring AI-Assisted Programming by Prompting Cloud-based
    Large Language Models. [http://arxiv.org/abs/2307.14349](http://arxiv.org/abs/2307.14349)
    arXiv:2307.14349 [cs].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tarassow (2023) Artur Tarassow. 2023. The potential of LLMs for coding with
    low-resource and domain-specific programming languages. [http://arxiv.org/abs/2307.13018](http://arxiv.org/abs/2307.13018)
    arXiv:2307.13018 [cs].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thiele et al. (2011) J. C. Thiele, W. Kurth, and V. Grimm. 2011. Agent-and
    individual-based modeling with NetLogo: Introduction and new NetLogo extensions.
    *Deutscher Verband Forstlicher Forschungsanstalten, Sektion Forstliche Biometrie
    und Informatik-22\. Tagung* (2011).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tian et al. (2023) Haoye Tian, Weiqi Lu, Tsz On Li, Xunzhu Tang, Shing-Chi Cheung,
    Jacques Klein, and Tegawendé F. Bissyandé. 2023. Is ChatGPT the Ultimate Programming
    Assistant–How far is it? *arXiv preprint arXiv:2304.11938* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tisue and Wilensky (2004) Seth Tisue and Uri Wilensky. 2004. Netlogo: A simple
    environment for modeling complexity. In *International conference on complex systems*,
    Vol. 21\. Citeseer, 16–21.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Turkle and Papert (1990) Sherry Turkle and Seymour Papert. 1990. Epistemological
    pluralism: Styles and voices within the computer culture. *Signs: Journal of women
    in culture and society* 16, 1 (1990), 128–157. Publisher: University of Chicago
    Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vaithilingam et al. (2022) Priyan Vaithilingam, Tianyi Zhang, and Elena L.
    Glassman. 2022. Expectation vs. experience: Evaluating the usability of code generation
    tools powered by large language models. In *Chi conference on human factors in
    computing systems extended abstracts*. 1–7.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wambsganss et al. (2021) Thiemo Wambsganss, Tobias Kueng, Matthias Soellner,
    and Jan Marco Leimeister. 2021. ArgueTutor: An adaptive dialog-based learning
    system for argumentation skills. In *Proceedings of the 2021 CHI conference on
    human factors in computing systems*. 1–13.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2023) Bailin Wang, Zi Wang, Xuezhi Wang, Yuan Cao, Rif A. Saurous,
    and Yoon Kim. 2023. Grammar Prompting for Domain-Specific Language Generation
    with Large Language Models. [http://arxiv.org/abs/2305.19234](http://arxiv.org/abs/2305.19234)
    arXiv:2305.19234 [cs].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2021) Qiaosi Wang, Koustuv Saha, Eric Gregori, David Joyner, and
    Ashok Goel. 2021. Towards mutual theory of mind in human-ai interaction: How language
    reflects what students perceive about a virtual teaching assistant. In *Proceedings
    of the 2021 CHI conference on human factors in computing systems*. 1–14.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weintrop et al. (2016) David Weintrop, Elham Beheshti, Michael Horn, Kai Orton,
    Kemi Jona, Laura Trouille, and Uri Wilensky. 2016. Defining Computational Thinking
    for Mathematics and Science Classrooms. *Journal of Science Education and Technology*
    25, 1 (Feb. 2016), 127–147. [https://doi.org/10.1007/s10956-015-9581-5](https://doi.org/10.1007/s10956-015-9581-5)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wellner and Levin (2023) Galit Wellner and Ilya Levin. 2023. Ihde meets Papert:
    combining postphenomenology and constructionism for a future agenda of philosophy
    of education in the era of digital technologies. *Learning, Media and Technology*
    (2023), 1–14. Publisher: Taylor & Francis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wermelinger (2023) Michel Wermelinger. 2023. Using GitHub Copilot to solve simple
    programming problems. In *Proceedings of the 54th ACM Technical Symposium on Computer
    Science Education V. 1*. 172–178.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whalley et al. (2021a) Jacqueline Whalley, Amber Settle, and Andrew Luxton-Reilly.
    2021a. Novice reflections on debugging. In *Proceedings of the 52nd ACM technical
    symposium on computer science education*. 73–79.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whalley et al. (2021b) Jacqueline Whalley, Amber Settle, and Andrew Luxton-Reilly.
    2021b. Novice Reflections on Debugging. In *Proceedings of the 52nd ACM Technical
    Symposium on Computer Science Education* *(SIGCSE ’21)*. Association for Computing
    Machinery, New York, NY, USA, 73–79. [https://doi.org/10.1145/3408877.3432374](https://doi.org/10.1145/3408877.3432374)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wilensky and Rand (2015) Uri Wilensky and William Rand. 2015. *An introduction
    to agent-based modeling: modeling natural, social, and engineered complex systems
    with NetLogo*. Mit Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wilensky (1997) Uri J. Wilensky. 1997. NetLogo Wolf Sheep Predation model. [http://ccl.northwestern.edu/netlogo/models/WolfSheepPredation](http://ccl.northwestern.edu/netlogo/models/WolfSheepPredation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Winkler et al. (2020) Rainer Winkler, Sebastian Hobert, Antti Salovaara, Matthias
    Söllner, and Jan Marco Leimeister. 2020. Sara, the lecturer: Improving learning
    in online education with a scaffolding-based conversational agent. In *Proceedings
    of the 2020 CHI conference on human factors in computing systems*. 1–14.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Winkler and Söllner (2018) Rainer Winkler and Matthias Söllner. 2018. Unleashing
    the potential of chatbots in education: A state-of-the-art analysis. In *Academy
    of Management Proceedings*, Vol. 2018\. Academy of Management Briarcliff Manor,
    NY 10510, 15903. Issue: 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2023) Xingbo Wu, Nathanaël Cheriere, Cheng Zhang, and Dushyanth
    Narayanan. 2023. RustGen: An Augmentation Approach for Generating Compilable Rust
    Code with Large Language Models. (June 2023). [https://openreview.net/forum?id=y9A0vJ5vuM](https://openreview.net/forum?id=y9A0vJ5vuM)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang and Aurisicchio (2021) Xi Yang and Marco Aurisicchio. 2021. Designing
    conversational agents: A self-determination theory approach. In *Proceedings of
    the 2021 CHI Conference on Human Factors in Computing Systems*. 1–16.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik R. Narasimhan, and Yuan Cao. 2022. ReAct: Synergizing Reasoning and Acting
    in Language Models. In *The Eleventh International Conference on Learning Representations*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yilmaz and Yilmaz (2023) Ramazan Yilmaz and Fatma Gizem Karaoglan Yilmaz. 2023.
    Augmented intelligence in programming learning: Examining student views on the
    use of ChatGPT for programming learning. *Computers in Human Behavior: Artificial
    Humans* 1, 2 (2023), 100005. Publisher: Elsevier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zamfirescu-Pereira et al. (2023) J. D. Zamfirescu-Pereira, Richmond Y. Wong,
    Bjoern Hartmann, and Qian Yang. 2023. Why Johnny can’t prompt: how non-AI experts
    try (and fail) to design LLM prompts. In *Proceedings of the 2023 CHI Conference
    on Human Factors in Computing Systems*. 1–21.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zastudil et al. (2023) Cynthia Zastudil, Magdalena Rogalska, Christine Kapp,
    Jennifer Vaughn, and Stephen MacNeil. 2023. Generative AI in Computing Education:
    Perspectives of Students and Instructors. *arXiv preprint arXiv:2308.04309* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
