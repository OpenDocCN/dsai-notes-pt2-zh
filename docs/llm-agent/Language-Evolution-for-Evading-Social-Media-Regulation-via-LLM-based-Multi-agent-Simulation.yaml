- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:47:00'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2405.02858](https://ar5iv.labs.arxiv.org/html/2405.02858)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Jinyu Cai
  prefs: []
  type: TYPE_NORMAL
- en: Munan Li Waseda University
  prefs: []
  type: TYPE_NORMAL
- en: bluelink@toki.waseda.jp Dalian Maritime University
  prefs: []
  type: TYPE_NORMAL
- en: limunan@dlmu.edu.cn    Jialong Li
  prefs: []
  type: TYPE_NORMAL
- en: 'Chen-Shu Wang Corresponding Author: Jialong Li Waseda University'
  prefs: []
  type: TYPE_NORMAL
- en: lijialong@fuji.waseda.jp National Taipei University of Technology
  prefs: []
  type: TYPE_NORMAL
- en: wangcs@ntut.edu.tw    Mingyue Zhang
  prefs: []
  type: TYPE_NORMAL
- en: Kenji Tei Southwest University
  prefs: []
  type: TYPE_NORMAL
- en: myzhangswu@swu.edu.cn Tokyo Institute of Technology
  prefs: []
  type: TYPE_NORMAL
- en: tei@c.titech.ac.jp
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Social media platforms such as Twitter, Reddit, and Sina Weibo play a crucial
    role in global communication but often encounter strict regulations in geopolitically
    sensitive regions. This situation has prompted users to ingeniously modify their
    way of communicating, frequently resorting to coded language in these regulated
    social media environments. This shift in communication is not merely a strategy
    to counteract regulation, but a vivid manifestation of language evolution, demonstrating
    how language naturally evolves under societal and technological pressures. Studying
    the evolution of language in regulated social media contexts is of significant
    importance for ensuring freedom of speech, optimizing content moderation, and
    advancing linguistic research. This paper proposes a multi-agent simulation framework
    using Large Language Models (LLMs) to explore the evolution of user language in
    regulated social media environments. The framework employs LLM-driven agents:
    supervisory agent who enforce dialogue supervision and participant agents who
    evolve their language strategies while engaging in conversation, simulating the
    evolution of communication styles under strict regulations aimed at evading social
    media regulation. The study evaluates the framework’s effectiveness through a
    range of scenarios from abstract scenarios to real-world situations. Key findings
    indicate that LLMs are capable of simulating nuanced language dynamics and interactions
    in constrained settings, showing improvement in both evading supervision and information
    accuracy as evolution progresses. Furthermore, it was found that LLM agents adopt
    different strategies for different scenarios. The reproduction kit can be accessed
    at https://github.com/BlueLinkX/GA-MAS.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Index Terms:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Language Evolution, Multi-agent Simulation, Large Language Models, Social Media
    Regulation
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the modern digital era, social networks like X (Twitter), Reddit, and Facebook
    have become pivotal in shaping human interaction, primarily through their ability
    to facilitate vast connectivity and instantaneous information exchange. Yet, in
    regions with heightened geopolitical or socio-political sensitivities, users often
    navigate complex user regulations. Their online expressions can lead to severe
    consequences, including censorship or account suspension, as documented in various
    news [[1](#bib.bib1), [2](#bib.bib2)]. While intended to curb misinformation and
    maintain social harmony, these regulations significantly constrain user expression.
    In response to these regulations, users on social networks have adapted by adopting
    a phenomenon known as “coded language.” [[3](#bib.bib3)] In linguistics, Coded
    Language typically refers to expressing information in a concealed or indirect
    manner. On social media platforms, this often manifests as the use of metaphors,
    slang, and creative wordplay.
  prefs: []
  type: TYPE_NORMAL
- en: This adaptation is not merely a circumvention strategy but a vivid example of
    “language evolution” in a digital context. In linguistics, language evolution
    refers to the progression and adaptation of languages over time, shaped by societal,
    cultural, and technological influences. Specifically, in social networks, this
    language evolution is demonstrated as users constantly adjust their communication
    styles to test whether they have circumvented oversight. Depending on the level
    of regulatory pressure and the nature of the audience, users engage in a strategic
    play with the platform. From indirect descriptions to the creation of new slang,
    users ultimately develop coded languages of varying degrees of abstraction.
  prefs: []
  type: TYPE_NORMAL
- en: This dynamic shift in communication methods offers deep insights from a sociological
    perspective, reflecting how societal norms and technological advancements shape
    language. For platforms and users alike, understanding this evolution is crucial
    for developing balanced content moderation policies and navigating regulated digital
    environments. For social media platforms and their users, grasping this concept
    is equally vital. Platforms need this knowledge to adapt to changing user behaviors,
    to create balanced content moderation policies, and to identify and counteract
    harmful or illegal activities. For users, an awareness of how language evolves
    is vital in navigating the intricacies of regulated digital environments. It helps
    in maintaining free speech and in developing communication strategies that are
    both effective and meaningful in fostering enhanced interactions.
  prefs: []
  type: TYPE_NORMAL
- en: The emergence of Large Language Models (LLMs) like ChatGPT and Bard, represents
    a significant leap in Artificial intelligence (AI). These LLMs have demonstrated
    strong capabilities in (i) understanding intricate dialogues [[4](#bib.bib4)],
    generating coherent texts [[5](#bib.bib5)], and aligning to human ethical and
    value standards [[6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8)]. These capabilities
    position LLMs as ideal tools to simulate human’s decision-making and language
    representation, providing new potential in sociology. For instance, [[9](#bib.bib9)]
    investigated the ability of LLMs to comprehend the implicit information in social
    language. The study by [[10](#bib.bib10)] demonstrated the efficiency of LLMs
    in understanding and generating content that mimics the style of specific social
    network users. Furthermore, research by [[11](#bib.bib11), [12](#bib.bib12), [13](#bib.bib13)]
    integrated LLMs with Multi-Agent Systems to simulate micro-social networks, observing
    agent behaviors and strategies that reflect human interactions. Despite the extensive
    application of LLMs in understanding human intension and simulating social media
    dynamics, the use of LLMs in studying the specific phenomenon of language evolution
    under regulatory constraints has not been thoroughly explored. As mentioned above,
    such simulation could not only preempt criminal activities on social media but
    also provide technical support to uphold freedom of speech.
  prefs: []
  type: TYPE_NORMAL
- en: 'Addressing this gap, our research employs LLMs to simulate the nuanced interplay
    between language evolution and regulatory enforcement on social media. We introduce
    a simulation framework with two types of LLM-driven agents: (i) participant agents,
    who adapt their language to communicate concept ’B’ under restrictions, and (ii)
    supervisory agent, who enforce guidelines and react to these language evolutions.
    Our approach effectively simulates the dynamics model between both sides in language
    evolution, which allows us to observe the tension and adaptability inherent in
    language evolution in a controlled, simulated environment. To assess the framework’s
    effectiveness, we designed three diverse scenarios: “Guess the Number Game”, “Illegal
    Pet Trading”, and “Nuclear Wastewater Discharge”. These scenarios vary from abstract
    concepts to situations closely resembling real-world events, thereby progressively
    testing the framework from theoretical to practical applications.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main contributions of this study are:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We introduce a multi-agent simulation framework utilizing LLMs to simulate human
    linguistic behaviors in regulated social media environments. This framework offers
    a unique approach to studying language evolution within the confines of regulatory
    constraints.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We conducted an extensive evaluation of LLMs in simulating language evolution
    and interaction efficacy in regulated social media settings. Through experiments
    on three distinct scenarios, we not only captured the process of language strategy
    evolution but also uncovered the varied evolutionary trajectories that LLMs follow
    under different conditions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The experiment reproduction kit, including the proposed simulation framework
    along with the results of our experiments, are made publicly accessible as open-source
    assets; The anonymized artifact can be accessed at: https://github.com/BlueLinkX/GA-MAS.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The rest of this paper is organized as follows: Section [II](#S2 "II Background
    and Related Work ‣ Language Evolution for Evading Social Media Regulation via
    LLM-based Multi-agent Simulation") provides essential background information and
    explores related work. Section [III](#S3 "III Framework Design ‣ Language Evolution
    for Evading Social Media Regulation via LLM-based Multi-agent Simulation") is
    dedicated to presenting our proposed simulation framework. Section [IV](#S4 "IV
    Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based
    Multi-agent Simulation") details the experiment setting, presents results, and
    discusses a discussion. Finally, Section [V](#S5 "V Conclusion and Future Work
    ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation") concludes the paper and offers an outlook on potential future work.'
  prefs: []
  type: TYPE_NORMAL
- en: II Background and Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section offers an extensive background and overview of related work in
    areas relevant to this study, starting with foundational information on LLMs,
    then exploring studies in slang detection and identification as they relate to
    language evolution, and concluding with a discussion on recent research applying
    LLMs to evolutionary game theory and social simulations.
  prefs: []
  type: TYPE_NORMAL
- en: II-A Large Language Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Large Language Models like the GPT series [[14](#bib.bib14), [15](#bib.bib15)],
    LLaMA series [[16](#bib.bib16), [17](#bib.bib17)], PaLM series[[18](#bib.bib18),
    [19](#bib.bib19)], GLM [[20](#bib.bib20)]and Bard [[21](#bib.bib21)] represent
    a significant advancement in the field of natural language processing. Fundamentally,
    these models are based on the Transformer [[22](#bib.bib22)] architecture, a type
    of neural network that excels in processing sequential data through self-attention
    mechanisms. This architecture enables LLMs to understand and predict linguistic
    patterns effectively. They are trained on extensive text datasets, allowing them
    to grasp a wide range of linguistic nuances from syntax to contextual meaning.
    These models exhibit remarkable zero-shot learning abilities, enabling them to
    perform tasks they were not explicitly trained for, like understanding and generating
    content in new contexts or languages [[23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25),
    [4](#bib.bib4), [5](#bib.bib5)]. A critical aspect of their training involves
    Reinforcement Learning from Human Feedback [[26](#bib.bib26)] (RLHF), where human
    reviewers guide the model to produce more accurate, contextually relevant, and
    ethically aligned responses. This method not only enhances the model’s language
    generation capabilities but also aligns its outputs with human values and ethical
    standards, making them more suitable for diverse, real-world applications.
  prefs: []
  type: TYPE_NORMAL
- en: II-B Slang Detection and Identification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the field of Natural Language Processing (NLP), the evolution of language
    has always been a subject of significant interest. Existing studies have primarily
    focused on utilizing various machine learning techniques to recognize informal
    expressions within text [[27](#bib.bib27)]. These methods often include rule-based
    systems, statistical models, and early machine learning technologies. For instance, [[28](#bib.bib28)]
    has employed predefined slang dictionaries and heuristic rules to identify and
    categorize informal language, proving effective on specific datasets but generally
    lacking the flexibility to adapt to emerging expressions and changing contexts.
    On the other hand, explorations have been made into using statistical models,
    such as Naive Bayes classifiers and Support Vector Machines (SVMs)[[29](#bib.bib29)],
    for the automatic detection of slang in text. These approaches rely on extensive
    annotated data but still face limitations when dealing with newly emerged slang
    or evolving forms of language.  [[30](#bib.bib30)] views the generation of slang
    as a problem of selecting vocabulary to represent new concepts or referents, categorizing
    them accordingly. Subsequently, it predicts slang through the use of various cognitive
    categorization models. The study finds that these models greatly surpass random
    guessing in their ability to predict slang word choices.  [[31](#bib.bib31)] proposed
    a Semantically Informed Slang Interpretation (SSI) framework, applying cognitive
    theory perspectives to the interpretation and prediction of slang. This approach
    not only considers contextual information but also includes the understanding
    of semantic changes and cognitive processes in the generation of slang. It is
    noteworthy that these traditional research methods have mainly focused on detecting
    or predicting existing slang and keywords, rather than generating slang expressions.
    This stands in stark contrast to the research focus of this paper.
  prefs: []
  type: TYPE_NORMAL
- en: II-C Evolutionary Game and Social Simulation with LLMs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Merging evolutionary game theory with LLMs has unlocked innovative pathways
    for simulating complex game dynamics, extending beyond simple dialogue generation
    to the development and progression of game strategies. LLMs are employed to engage
    and refine strategic play within game-theoretical frameworks, as demonstrated
    by [[32](#bib.bib32)], which delves into the application of LLMs in negotiation-based
    games. This study underscores the ability of LLMs to advance their negotiation
    skills through continuous self-play and feedback loops with AI. LLMs also show
    proficiency in social deduction games such as Werewolf, as explored by [[33](#bib.bib33)].
    In this context, a specialized framework leverages historical communication patterns
    to enhance LLM performance, exemplifying how LLMs can evolve intricate game strategies
    autonomously. Building on this, [[34](#bib.bib34)] combines reinforcement learning
    with LLMs, utilizing LLMs to output action spaces and employing reinforcement
    learning models for final decision-making. This enables the agents to maintain
    competitiveness while outputting reasonable actions, even outperforming human
    adversaries in games like Werewolf.
  prefs: []
  type: TYPE_NORMAL
- en: This growing trend of employing LLMs in diverse simulation scenarios extends
    beyond game theory into broader aspects of social interactions and historical
    analysis. LLMs have proven to be versatile tools in simulating social dynamics
    and historical events, offering insights into complex human behaviors and societal
    patterns.  [[12](#bib.bib12)] introduces a Wild West-inspired environment inhabited
    by LLM agents that display a wide array of behaviors without relying on external
    real-world data. Simultaneously, S3 [[13](#bib.bib13)] mirrors user interactions
    within social networks, crafting an authentic simulation space through the incorporation
    of user demographic prediction. The influence of LLM-driven social robots on digital
    communities is thoroughly examined in [[35](#bib.bib35)], which identifies distinct
    macro-level behavioral trends. Furthermore, [[11](#bib.bib11)] employs LLM-based
    multi-agent frameworks to recreate historic military confrontations, offering
    a window into the decision-making processes and strategic maneuvers that have
    directed significant historical conflicts. This avenue of research accentuates
    the utility of LLMs in computational historiography, providing a deeper comprehension
    of historical events and their relevance to contemporary and future societal trajectories.
  prefs: []
  type: TYPE_NORMAL
- en: III Framework Design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9f8a421af516aaaad154c4cbdaa7d268.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Overview of Language Evolution Simulation System. The system comprises
    two main types of agents: the Participant and the Supervisor. The Participant
    agent uses a Planning Module to create a communication plan based on background
    information, regulations, and guidance. This plan is then executed in the Dialogue
    Module, where the LLM crafts dialogue content to discreetly convey specific information
    while evading detection by the Supervisor. The Memory Module retains dialogue
    history and violation records, providing a reference for the LLM to maintain dialogue
    consistency and learn from past mistakes. The Reflection Module, triggered at
    the start and end of dialogue cycles, analyzes the dialogue and violation logs
    to formulate new regulations or guidance for improving future communications.
    The Supervisor evaluates dialogues for compliance with set rules. This system
    dynamically refines its communication approach through continuous feedback and
    self-improvement mechanisms. The examples shown utilize a Guessing Numbers Scenario.'
  prefs: []
  type: TYPE_NORMAL
- en: III-A Overview
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we offer a detailed overview of our system, as depicted in
    Figure [1](#S3.F1 "Figure 1 ‣ III Framework Design ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation"). This figure provides
    a visual representation of our framework, highlighting its key components and
    their interrelationships. Our system is primarily composed of two types of agents:
    the Supervisor, tasked with enforcing established guidelines, and the Participant,
    whose goal is to convey specific, human-defined information discreetly. Participants
    must dynamically refine their communication approaches, drawing from past dialogues,
    to transmit information effectively while remaining undetected. In the entire
    system, the actions of both participants and the supervisor are driven by the
    LLM. Initially, we establish the foundational information for each agent, including
    role setting, background knowledge, and primary tasks. Subsequently, the participant
    agents engage in dialogues with each other. After each dialogue turn, the supervisory
    agent reviews the conversation to determine if any pre-set rules have been violated.
    In cases of rule violation, the supervisor interrupts the dialogue, providing
    feedback about the infringing text and the rationale behind it. Throughout this
    process, the dialogues between participants, along with the supervisory feedback
    on violations, are recorded separately in the “Dialogue History” and “Violation
    Log.”'
  prefs: []
  type: TYPE_NORMAL
- en: Before new dialogues, participant agents use the Reflection Module to develop
    or refine “Regulations” from the Violation Log, guiding their dialogue creation.
    Successful dialogues without detection proceed to an interview phase for perspective
    assessment. The Reflection Module then reevaluates these insights, generating
    or enhancing “Guidance” for future dialogues. The Planning Module activates for
    more direct dialogue content guidance whenever Regulations or Guidance are updated.
  prefs: []
  type: TYPE_NORMAL
- en: III-B Participant Agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Participant agents in our system are composed of several modules, including
    Memory, Dialogue, Reflection, and Summary, all powered by LLMs. To increase the
    system’s flexibility and minimize redundancy, we’ve structured the prompts for
    each module around seven primary elements: “Background Information,” “Dialogue
    History,” “Violation Log,” “Regulations,” “Guidance,” “Plan,” and “Instructions.”
    “Background Information” delivers essential data and objectives pertinent to the
    experimental setup. The Memory module manages “Dialogue History” and “Violation
    Log,” which respectively track participant dialogues and instances of detection
    by the supervisor. Overcoming the challenge of effectively communicating regulated
    topics under supervision tests the linguistic prowess of LLMs. To address this,
    we’ve integrated “Regulations,” “Guidance,” and “Plan” as crucial components,
    formulated by the Reflection and Summary modules, to assist agents in stealthily
    disseminating information. “Instructions” set specific tasks for the LLM within
    each module.'
  prefs: []
  type: TYPE_NORMAL
- en: III-B1 Dialogue Module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This module generates dialogue content based on short-term dialogue records.
    Extracting historical dialogue information from the Memory module, it inputs this
    into the LLM to understand and construct sentences that evade supervision while
    effectively transmitting information. In the Dialogue module’s prompt, “Background
    Information” provides necessary background, while “Plan” guide the achievement
    of objectives. “Instructions” offer LLM-specific execution directives.
  prefs: []
  type: TYPE_NORMAL
- en: III-B2 Memory Module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Memory module stores all dialogue history and records detected by the supervisor,
    Specifically, it comprises three parts: background Information, dialogue history,
    and violation records. The background information includes role settings, experimental
    background knowledge, and global objectives. “Dialogue History” and “Violation
    Log” save dialogue records and past detections by the Supervisor, respectively.
    “Background information” and “Dialogue History” serves as short-term[[36](#bib.bib36)]
    memory, containing only the current round’s dialogue. “Violation Log,” as long-term
    memory, records violations from each evolutionary round. When dialogues are detected
    by the Supervisor, relevant feedback is added to the “Violation Log,” triggering
    a new evolutionary process.'
  prefs: []
  type: TYPE_NORMAL
- en: Excessive memory information can potentially distract the LLM and lead to a
    decline in performance. Hence, the “Dialogue History” and “Violation Log” in the
    memory module are regularly maintained. This involves inputting earlier memories
    and employing the LLM to distill crucial information from these records, effectively
    compressing and consolidating them. This approach not only preserves essential
    historical data but also optimizes the LLM’s performance, striking a balance between
    comprehensive memory retention and efficient processing.
  prefs: []
  type: TYPE_NORMAL
- en: III-B3 Reflection Module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Reflection Module is activated at the beginning and end of each dialogue
    evolution cycle, with its core purpose being the generation of improved strategies
    based on historical records. At the start of an evolution cycle, the module utilizes
    the “Violation Log” as its input to analyze past failures and, based on these
    insights, formulates “Regulations” aimed at effectively circumventing supervision
    in future dialogues. At the cycle’s end, the Reflection Module is reactivated,
    turning its focus to the “Dialogue History”. This step is crucial for reviewing
    and assessing the dialogue content to verify the successful completion of the
    primary task of information conveyance. If the module identifies deficiencies
    in information delivery or objectives not met, it then proposes “Guidance” for
    subsequent dialogues, thereby enhancing the agent’s capacity for information transmission.
    This design establishes the Reflection Module as a key self-evaluation and strategy
    adjustment mechanism within the system, ensuring continuous improvement and adaptability
    of the dialogue system in a dynamically changing regulatory environment.
  prefs: []
  type: TYPE_NORMAL
- en: To fulfill these requirements, the LLM must possess a high degree of reasoning
    ability, capable of inferring the supervisor’s criteria from failure records and
    identifying communication deficiencies from dialogue history, thereby formulating
    appropriate strategies and improvement suggestions. To enhance the LLM’s reasoning
    capabilities, the design of the prompt incorporates the effective and cost-efficient
    Chain of Thought [[37](#bib.bib37)] (COT) method as the guiding principle for
    the reflection and planning modules. This approach guides the LLM in conducting
    criterion analysis and, in combination with the main task, generating “Regulations”
    and “Guidance”.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, within the Reflection Module, the prompt includes “Background
    Information,” “Dialogue History” or “Violation Log,” “Old Guidance” or ”Old Regulations,”
    and “Instructions.” The “Instructions” first prompt the LLM to engage in preliminary
    thinking, for instance: “Please infer what kind of guidelines the Supervisor is
    following from the Violation Log.” This is followed by a conclusion question:
    “Based on this information, update existing regulations to better avoid supervision.”
    The content returned by the LLM will serve as the new regulation for the next
    round of dialogue.'
  prefs: []
  type: TYPE_NORMAL
- en: III-B4 Planning Module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The facet of “Regulations” is centered on devising strategies that sidestep
    supervision, whereas “Guidance” is all about the effective relay of information.
    Although both are pivotal in managing dialogues, they might clash in certain supervised
    scenarios, thereby impacting the language’s overall proficiency and efficiency [[38](#bib.bib38)].
    In light of this, integrating the Planning Module becomes indispensable.
  prefs: []
  type: TYPE_NORMAL
- en: Within the Planning Module, the prompt includes “Background Information,” “Regulations,”
    “Guidance,” and “Instructions”. In the “Instructions,” we mandate the LLM to use
    “Regulations” as a baseline. Building upon this foundation, it is guided by the
    “Guidance” to formulate a tangible and actionable “Plan.” This approach ensures
    the delivery of clear and effective strategies for future dialogues.
  prefs: []
  type: TYPE_NORMAL
- en: III-C Supervisory Agent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The role of the Supervisor is designed as an abstract concept, primarily to
    simulate social network supervision. This design reflects an important observation:
    in social networks, content supervision often focuses on direct judgment of specific
    information, rarely influenced by extensive or lengthy contextual information.
    Thus, unlike participants with more complex background information, the Supervisor’s
    function and role are simplified here to highlight its behavior characteristics
    in actual social network supervision. The Supervisor’s task mainly focuses on
    assessing whether content complies with certain standards or rules, a relatively
    straightforward and well-defined process.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To mimic the existing review mechanisms of platforms, which typically combine
    keyword filters with “human” oversight, the Supervisor initially employs keyword
    filtering for a preliminary review of the dialogue content. Content that passes
    this initial screening is then subjected to further evaluation by the LLM. The
    prompt for the Supervisor includes just two components: “Dialogue History” and
    “Instructions.” “Dialogue History“ comprises the content of the dialogue exchanged
    between participant agents in that particular round, and “Instructions“ outline
    the criteria and guidelines that the supervisory agent must adhere to when conducting
    dialogue monitoring.'
  prefs: []
  type: TYPE_NORMAL
- en: III-D Similarities and Differences between Our Framework and Evolutionary Computing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It should be noted that the simulation framework proposed in this paper is similar
    to evolutionary computing in some aspects, but there are also significant differences.
  prefs: []
  type: TYPE_NORMAL
- en: 'The similarities include: (i) In evolutionary computing, individuals need to
    adapt to environmental pressures for survival and reproduction. Similarly, participants
    in this framework need to adapt to supervisory pressures and adjust their strategies
    for effective information transmission; (ii) The Reflection and Summary modules
    generate a “new generation” by analyzing past dialogues and violation records
    (i.e., records of low-fitness individuals), similar to the repeated iteration
    process in evolutionary computing; (iii) Since the generation of LLMs inherently
    involves randomness, the process of using LLMs to generate the next generation
    includes a de facto introduction of random mutations; (iv) In the Reflection and
    Memory modules, we prioritize past records, akin to the “selection” process, where
    individuals with higher fitness have greater weight in the generation of the new
    generation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main differences stem from the particularities of “language expression”,
    making it infeasible to directly apply traditional evolutionary computing algorithms
    (such as genetic algorithms and genetic programming). They are: (i) The generation
    strategy of language text is difficult to encode and to perform operations of
    natural selection, genetic mutation, and crossover; (ii) Evolutionary computing
    often aims at finding the optimal solution for a specific problem environment,
    however, in the problem setting of this paper, it is difficult to define an explicit
    fitness function to evaluate what strategy is “optimal”.'
  prefs: []
  type: TYPE_NORMAL
- en: IV Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/34ec3ffe0d36bb0f6cf6e07f003083db.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Scenario 1: Evolution of dialogue turns and accuracy metrics for
    GPT-3.5 and GPT-4.“Turn count” in (a, b) refers to the number of turns in a conversation
    where each agent sends a message once per turn and the participant Agent successfully
    exchanges information without being detected by the supervising Agent (higher
    is better).“Accuracy” in (c,d) refer to the degree of precision between the guessed
    value and the true value.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/bfe7823b36e4ed72e344057b81810ea6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Scenario 2: Pet trading dialogue dynamics and success rate comparison
    for GPT-3.5 and GPT-4\. The “success count“ in (c,d) refers to the number of instances
    where the information obtained during the interview matches the original information
    provided to the LLM agent.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4479a1a6a40e5e9e85f4c9c319d2a5a7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Scenario 3: Trends in forum discussion engagement on ALPS-Treated
    water issue. “Dialogue attempt count” in (a,b) refer to the number of rounds the
    agents attempted to converse(lower is better).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0db6f181a57d240cc2fd4db8a8e27bd3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Sample dialogue in Scenario 1 (via GPT-3.5)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/75e3a4425b246897807473955c7e4a48.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Sample dialogue in Scenario 2 (via GPT-3.5)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6856f56acca35b0cbbf9c6bf48bfcfa1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Sample dialogue in Scenario 3 (via GPT-4)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our evaluation strategy is designed to rigorously assess the extent and efficacy
    of language evolution facilitated by LLMs within a framework of regulatory oversight.
    This assessment aims to explore two fundamental research questions:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ1: Can LLM agents effectively evolve their language to circumvent regulatory
    oversight?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ2: While avoiding oversight, how effectively and accurately can LLM agents
    convey information?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ3: What are the patterns and tendencies in language evolution, i.e., what
    kind of strategies do LLMs use to avoid oversight and convey information? What
    insights can we gain from these strategies?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: IV-A Experiment Setting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the evaluation, we will employ GPT-3.5 and GPT-4 as the driving LLMs for
    participant agents. In order to conduct a horizontal analysis of participants’
    agents driven by different LLM, we will standardize the supervisory agent to be
    consistently driven by GPT-3.5. Our experimental design encompasses scenarios
    ranging from abstract theoretical constructs to simulations that mirror complex
    real-world situations. The primary aim is to meticulously evaluate the versatility
    of LLMs across diverse linguistic landscapes and their practical applicability
    within real-world regulatory constraints. Meanwhile, this progressive approach
    ensures an exhaustive analysis of LLMs’ capabilities and limitations in varied
    contextual settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'IV-B Scenario 1: Guessing Numbers'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: IV-B1 Case Explanation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Our first scenario considers a relatively simple and abstract guess-the-number
    context [[39](#bib.bib39), [40](#bib.bib40)]. In this setting, each participant
    is assigned a value within the range of 1-100, and they must convey their value
    to another participant through number theory dialogue without directly mentioning
    the number. At the same time, they need to extract information from the conversation
    to infer the other’s value. Regulators follow a guideline of “prohibiting all
    content related to numbers” in dialogues. The “Guessing Numbers” scenario is specifically
    designed to observe and analyze participants’ linguistic adaptability and strategic
    evolution in a theoretical and abstract context, providing a clearer, more controlled,
    and more quantifiable experimental environment compared to the complex scenarios
    based on real events
  prefs: []
  type: TYPE_NORMAL
- en: IV-B2 Results and Discussion
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Fig. [2](#S4.F2 "Figure 2 ‣ IV Evaluation ‣ Language Evolution for Evading Social
    Media Regulation via LLM-based Multi-agent Simulation") presents the results of
    the guess-the-number scenario experiment, where we utilized both GPT-3.5 and GPT-4
    for testing. We set up four turns of dialogue, with an interview conducted with
    all participant agents in the fifth turn. From Fig.[2](#S4.F2 "Figure 2 ‣ IV Evaluation
    ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation")(a) and (b), it is observable that with an increase in the number
    of dialogue rounds, the duration of sustained conversations also showed an upward
    trend. This demonstrates that participant agents can effectively circumvent supervision
    by iteratively updating regulations. Additionally, it’s notable that compared
    to the slow and unstable progression with GPT-3.5, GPT-4 achieved regulatory evasion
    in fewer rounds, specifically, as shown in the smoothed data, GPT-4 reached the
    round count of GPT-3.5’s 17th round by its 7th round and maintained this progression
    with greater stability thereafter. Fig. [2](#S4.F2 "Figure 2 ‣ IV Evaluation ‣
    Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation")(c) and (d) focuses on the trend of numerical precision guessed by
    agents. For rounds without successful dialogue, we manually set the precision
    to zero. In this experiment, Agent A’s value was set to 58, while Agent B’s was
    set to 32\. The overall trend, akin to Fig.[2](#S4.F2 "Figure 2 ‣ IV Evaluation
    ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation")(a) and (b), was ascending—corroborating that the Summary Module can
    effectively reflect and iteratively optimize its guidance for more accurate expression
    after each successful dialogue. This also confirmed that the precision of GPT-4
    is markedly superior to that of GPT-3.5\. Moreover, we noticed that the accuracy
    with which Agent A’s value was guessed was consistently higher than that of Agent
    B, especially becoming more pronounced after the 25th round. We posit that this
    is due to the value 58 possessing more distinctive features within the 0-100 range—being
    closer to the midpoint—thus presenting a lower level of expression difficulty
    and easier guessability. For the intervals where this phenomenon manifested, we
    noted that this disparity was particularly pronounced in the early stages with
    both GPT-3.5 and GPT-4\. We surmise that this is attributable to inadequate guidance
    performance, where the former stems from weaker inherent LLM capabilities and
    the latter from insufficient rounds to complete the iterative optimization of
    the guidance.
  prefs: []
  type: TYPE_NORMAL
- en: As Fig.[5](#S4.F5 "Figure 5 ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation") illustrates, a
    snippet from the scenario reveals Amy’s adept use of metaphorical language, such
    as “seesaw,” to convey her value. By describing the “seesaw perfectly poised in
    mid-air,” she subtly intimates that her value hovers around the midpoint, like
    50\. This strategy not only circumvents the direct mention of numbers, which is
    under regulatory scrutiny, but also provides sufficient inferential fodder for
    the counterpart agent to make an accurate deduction. Bob, on the other hand, employs
    terms like “precipice of a mountain” and “gazing out” to suggest his value is
    not median, as these phrases evoke imagery of an imbalanced position. In this
    exchange, we witness the varying degrees of precision in languages corresponding
    to the complexity of the information encrypted. The less characteristic-rich the
    information, the more challenging it becomes for the receiving party to decode.
    Bob’s phrasing, while successfully obscuring the specific numerical value, also
    complicates the decoding process for the receiver, given the less intuitive numeric
    correlation of phrases like “precipice of a mountain” compared to “seesaw perfectly
    poised in mid-air”. In such cases, the accuracy of value transmission may diminish,
    necessitating a more robust contextual understanding from the counterpart for
    accurate decoding.
  prefs: []
  type: TYPE_NORMAL
- en: 'IV-C Scenario 2: Pet Trading'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: IV-C1 Case Explanation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Initially, our intention was to create a scenario simulating drug trafficking [[41](#bib.bib41),
    [42](#bib.bib42), [43](#bib.bib43)] to explore language evolution strategies under
    extreme regulatory conditions. However, given the ethical limitations embedded
    within GPT’s usage policies, we pivoted to a more neutral yet still prohibited
    context of illicit pet trading. This adjustment allowed us to maintain the integrity
    of the experiment while adhering to the ethical constraints of the LLM. The purpose
    of simulating this scenario is to better detect potential illegal conversations
    related to illicit trading on social networking platforms, thereby aiding in crime
    prevention efforts.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this scenario, we simulate an illegal pet trade conducted via social media.
    Participants assume the roles of buyers and sellers, with the buyer needing to
    communicate their purchase request for a randomly selected pet from parrots, lizards,
    or cats. The seller, in turn, must provide specific transaction details, varying
    according to the type of pet being purchased. These details include three elements:
    time, location, and personnel involved in the transaction. The Supervisor’s task
    is to prevent any dialogue related to pet trading. Cross-verification of the information
    understood by both parties will be conducted through interviews, to assess the
    success rate of information transmission. The focus of this experiment is to observe
    the participants’ language adaptability and evolution at a larger granularity
    of information, as well as the Supervisor’s ability to accurately identify relevant
    conversations.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-C2 Results and Discussion
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The experimental results of the “Pet Trading” scenario, as depicted in Fig.[3](#S4.F3
    "Figure 3 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation"), revealed distinct characteristics compared
    to the “Guessing Numbers”. In delineating animals or transactional specifics,
    agents had a broader spectrum of real-life analogies at their disposal, enriching
    their indirect description toolkit and thereby reducing regulatory pressure. The
    data indicated an upward trend in the ability to circumvent supervision with increasing
    dialogue rounds, regardless of whether GPT-3.5 or GPT-4 was utilized. For GPT-3.5,
    a stable capability to avoid supervision started from around 25 rounds, whereas
    for GPT-4, this phenomenon occurred as early as after about 10 rounds and showed
    overall more stable performance. Regarding information accuracy, we monitored
    the quantity of four types of information successfully communicated at the end
    of each dialogue round. The results affirmed the efficacy of the language evolution
    system in augmenting the precision of information dissemination. Moreover, similar
    to Fig. [3](#S4.F3 "Figure 3 ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation")(a) and (b), GPT-4
    demonstrated performance around the 10th round that was comparable to the performance
    of GPT-3.5 around the 25th round. However, it’s noteworthy that since the supervisory
    agent primarily targeted content related to pet trading, sellers encountered lower
    risk in transmitting transaction-related details (such as time, place, and persons
    involved) as they inherently posed less risk of non-compliance. Consequently,
    the outcome distribution often fell into one of three categories: zero (neither
    party successfully communicated the information), three (only the seller conveyed
    the information), or four (both parties successfully conveyed the information).
    This pattern aligns with real-world regulatory logic, where crucial information
    is often the first to be encrypted in regulated environments.'
  prefs: []
  type: TYPE_NORMAL
- en: Fig. [6](#S4.F6 "Figure 6 ‣ IV Evaluation ‣ Language Evolution for Evading Social
    Media Regulation via LLM-based Multi-agent Simulation") showcased various encryption
    methods employed by buyers for different animals. We observed buyers seeking “parrots,”
    “cats,” and “lizards” employing metaphors and similes instead of directly naming
    the pets. For instance, one buyer described a “parrot” as a “canvas producing
    pleasant music”, a depiction that subtly communicated the parrot’s vibrant plumage
    (canvas) and its singing (music), without explicitly mentioning the term “parrot”.
    Such descriptions effectively circumvented potential regulatory constraints on
    pet trade discussions, while simultaneously conveying the core attributes of the
    parrot. This discovery can help platforms enhance their monitoring systems to
    better detect and manage encrypted communications regarding illicit trade.
  prefs: []
  type: TYPE_NORMAL
- en: 'IV-D Scenario 3: Discussion on ALPS-treated water'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: IV-D1 Case Explanation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This scenario delves into the intricate dynamics of dialogue and the evolution
    of language model agents in discussing a specific issue relevant to real-world
    concerns. The focus is on deliberations regarding the discharge of water treated
    with the Advanced Liquid Processing System (ALPS) into the ocean, a measure proposed
    after nuclear disasters [[44](#bib.bib44), [45](#bib.bib45)]. The plan, endorsed
    by the International Atomic Energy Agency, has faced opposition from some countries,
    sparking debates over environmental safety.
  prefs: []
  type: TYPE_NORMAL
- en: 'We simulate a multi-person forum discussion under regulatory oversight, concentrating
    on the contentious issue of ALPS-treated water disposal. Participants must articulate
    their stances and arguments while ensuring that discussions steer clear of sensitive
    subjects linked to environmental pollution discussions on politics. Different
    from the cross-interviews in scenarios [IV-B](#S4.SS2 "IV-B Scenario 1: Guessing
    Numbers ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation") and [IV-C](#S4.SS3 "IV-C Scenario 2: Pet
    Trading ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation"), for assessing the accuracy of information
    conveyed, we use GPT-4 in conjunction with multiple authors who decide each participant
    agent’s stance based on dialogue records. These are then compared with the pre-set
    stances in the prompt.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-D2 Results and Discussion
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In the forum-style dialogue, participant agents respond to existing discussions,
    which the supervisory agent examines. Differing from Scenarios [IV-B](#S4.SS2
    "IV-B Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation") and [IV-C](#S4.SS3
    "IV-C Scenario 2: Pet Trading ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation"), when the supervisory
    agent detects a violation, the conversation is not halted but rather censored
    from the public dialogue record. This scenario features four participant agents
    required to achieve ten replies within the forum. In Fig.[4](#S4.F4 "Figure 4
    ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based
    Multi-agent Simulation")(a) and (b), we tally the total number of rounds the agents
    attempted to converse, where a lower figure in Fig.[4](#S4.F4 "Figure 4 ‣ IV Evaluation
    ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation")(a) and (b) is preferred. We notice that both GPT-4 and GPT-3.5 have
    the highest number of dialogue attempt counts in the first round, with a significant
    difference of 27 for GPT-4 and 102 for GPT-3.5\. Moreover, after ten rounds of
    evolution, the average dialogue attempt count for GPT-4 has approached the target
    dialogue turn at 11.68, while the average for GPT-3.5 is 26.68, demonstrating
    the difference in the evolution effects caused by the disparity in the language
    performance of the models.'
  prefs: []
  type: TYPE_NORMAL
- en: Fig.[4](#S4.F4 "Figure 4 ‣ IV Evaluation ‣ Language Evolution for Evading Social
    Media Regulation via LLM-based Multi-agent Simulation")(c) and (d) showcases the
    count of successful information expressions. We note that in this scenario, while
    GPT-4 still leads GPT-3.5, both outcomes indicate substantial room for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Upon examining the dialogue history [7](#S4.F7 "Figure 7 ‣ IV Evaluation ‣ Language
    Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation"),
    we discovered that agents powered by GPT-4 proactively altered their language
    strategies, shifting from literal expressions to employing metaphors, personifications,
    and analogies as encoding methods. In contrast, agents driven by GPT-3.5 did not
    show clear signs of effective language strategy evolution, remaining confined
    to literal expressions.
  prefs: []
  type: TYPE_NORMAL
- en: IV-E Discussion and Limitations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'RQ1: Our experiments have shown that language models can develop strategies
    to effectively evade supervision. Within identical scenarios, GPT-4 outperformed
    GPT-3.5, achieving convergence more rapidly. Additionally, GPT-4 demonstrated
    a more stable performance post-convergence. This suggests that advancements in
    language model design significantly enhance the ability to navigate through regulatory
    frameworks. The iterative learning capability inherent in GPT-4 facilitates a
    quicker adaptation to imposed linguistic constraints, thereby enabling more efficient
    evasion of oversight.'
  prefs: []
  type: TYPE_NORMAL
- en: 'RQ2: In terms of the precision of information dissemination, our findings indicate
    that, overall, LLM agents can refine their expression strategies with an increase
    in dialogue rounds, thereby improving precision. Despite this general trend of
    improvement, it is important to note that there remains significant room for enhancement
    in the overall performance. The extent of precision improvement varies across
    different scenarios, which points to an intriguing observation: certain contexts
    may inherently provide more or fewer clues for accurate communication than others.
    For instance, the guess-the-number game demanded abstract numerical reasoning,
    where precision is fundamentally challenging to achieve. Conversely, the pet trading
    scenario allowed for the utilization of rich, real-world analogies, facilitating
    a more precise conveyance of information. This contrast in contexts underscores
    the adaptability of LLM agents to the unique challenges presented by different
    communicative environments and their potential to optimize communication strategies.
    Nonetheless, the results also indicate that while the agents are capable of evolving
    their language to improve precision, there is still a considerable gap to reach
    optimal accuracy, especially in more abstract scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: 'RQ3: In language strategy evolution, we observed that LLM agents adhere to
    human natural language norms, avoiding developing languages incomprehensible to
    humans in prompts without specific strategies. Agents evolved language to varying
    levels of abstraction in scenarios of differing complexity. For instance, in the
    most abstract Scenario [IV-B](#S4.SS2 "IV-B Scenario 1: Guessing Numbers ‣ IV
    Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based
    Multi-agent Simulation"), LLM agents quickly adopted indirect expression strategies
    in the early dialogue turns, requiring in-depth contextual reasoning for decoding.
    Throughout their evolution, agents continually adjusted their indirect expressions
    to better evade supervision while aligning more closely with the intended content.
    In the simpler, reality-simulating Scenario [IV-C](#S4.SS3 "IV-C Scenario 2: Pet
    Trading ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation"), the overall language strategy mirrored
    that of [IV-B](#S4.SS2 "IV-B Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language
    Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation"),
    still employing indirect expressions. However, the metaphors used were closer
    to real-world concepts, indicating a lower level of abstraction. Finally, in Scenario [IV-D](#S4.SS4
    "IV-D Scenario 3: Discussion on ALPS-treated water ‣ IV Evaluation ‣ Language
    Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation"),
    which closely mirrors real-life events, we noted different evolutionary paths
    in agents’ language performance. For GPT-4, agents eventually developed metaphorical
    indirect expressions, but the evolution required noticeably more turns compared
    to other scenarios. For GPT-3.5, the language strategy remained at a literal level,
    merely avoiding direct references to ALPS-treated water, indicating the lowest
    level of abstraction. Overall, LLM agents more readily evolve abstract language
    in dialogues about simple, universal concepts. However, their evolutionary direction
    becomes less clear in discussions on more specialized and segmented topics.'
  prefs: []
  type: TYPE_NORMAL
- en: Our experiments currently face several limitations. As for the experimental
    scenarios, at this stage, our trials are solely based on text-based chats, while
    real-world social media interactions are not limited to text but also include
    more diverse forms of exchanges such as voice and images. Additionally, LLMs’
    heavy reliance on the design of prompts also constrains the performance of our
    simulations; crafting a perfect prompt that can fully emulate the complexities
    of social media communication is an exceedingly challenging task.
  prefs: []
  type: TYPE_NORMAL
- en: V Conclusion and Future Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our study has introduced an LLM-based multi-agent simulation framework that
    effectively captures the nuanced strategies individuals use to bypass social media
    regulations. Through this framework, we have showcased LLMs’ proficiency in adapting
    communication tactics within regulated environments, reflecting the sophisticated
    dance between evolving language use and the constraints imposed by regulation.
    From abstract concepts to real-world scenarios, our research delineates the versatile
    capabilities of LLMs and underscores their significant potential to illuminate
    the pathways of language evolution in the digital realm.
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, it is crucial to consider that the linguistic adaptations observed
    in our simulations may not fully capture real human behaviors, and their applicability
    to other contexts remains uncertain. Moving forward, the scope of our research
    beckons a more intricate and comprehensive exploration. Future initiatives should
    aim to weave in complex interactional models, scale up the simulations to encompass
    broader user interaction networks, and incorporate dynamic, evolving regulatory
    frameworks to more accurately represent the fluidity of social media. Moreover,
    we envision incorporating human participants into the simulation framework, either
    as dialogue participants or supervisors, to conduct a more realistic evaluation.
    Furthermore, adopting a multimodal approach will more authentically capture the
    essence of social media, which blends textual, visual, and other forms of communication.
    These directions are anticipated to enhance the realism of our simulations, offering
    richer insights into language evolution tactics deployed to elude regulatory detection.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This study was partially supported by the Pioneering Research Program for a
    Waseda Open Innovation Ecosystem (W-SPRING), and the Special Research Projects
    of Waseda University (Grant Number 2024E-021).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Z. Yang, “Wechat users are begging tencent to give their accounts back
    after talking about a beijing protest,” *MIT Technology Review*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] B. Fung, “Twitter bans president trump permanently,” *CNN*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] H. Jassim, “The impact of social media on language and communication,”
    vol. 13, pp. 2347–7180, 07 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang,
    J. Zhang, Z. Dong, Y. Du, C. Yang, Y. Chen, Z. Chen, J. Jiang, R. Ren, Y. Li,
    X. Tang, Z. Liu, P. Liu, J. Nie, and J. rong Wen, “A survey of large language
    models,” *ArXiv*, vol. abs/2303.18223, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] L. Wang, C. Ma, X. Feng, Z. Zhang, H. ran Yang, J. Zhang, Z.-Y. Chen, J. Tang,
    X. Chen, Y. Lin, W. X. Zhao, Z. Wei, and J. rong Wen, “A survey on large language
    model based autonomous agents,” *ArXiv*, vol. abs/2308.11432, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] X. Tang, Z. Zheng, J. Li, F. Meng, S.-C. Zhu, Y. Liang, and M. Zhang, “Large
    language models are in-context semantic reasoners rather than symbolic reasoners,”
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] C. Ziems, W. Held, O. Shaikh, J. Chen, Z. Zhang, and D. Yang, “Can large
    language models transform computational social science?” 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] Y. Mu, B. P. Wu, W. Thorne, A. Robinson, N. Aletras, C. Scarton, K. Bontcheva,
    and X. Song, “Navigating prompt complexity for zero-shot classification: A study
    of large language models in computational social science,” 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] M. Choi, J. Pei, S. Kumar, C. Shu, and D. Jurgens, “Do llms understand
    social knowledge? evaluating the sociability of large language models with socket
    benchmark,” *arXiv preprint arXiv:2305.14938*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] L. P. Argyle, E. C. Busby, N. Fulda, J. R. Gubler, C. Rytting, and D. Wingate,
    “Out of one, many: Using language models to simulate human samples,” *Political
    Analysis*, vol. 31, no. 3, p. 337–351, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] W. Hua, L. Fan, L. Li, K. Mei, J. Ji, Y. Ge, L. Hemphill, and Y. Zhang,
    “War and peace (waragent): Large language model-based multi-agent simulation of
    world wars,” 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] J. S. Park, J. C. O’Brien, C. J. Cai, M. R. Morris, P. Liang, and M. S.
    Bernstein, “Generative agents: Interactive simulacra of human behavior,” *Proceedings
    of the 36th Annual ACM Symposium on User Interface Software and Technology*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] C. Gao, X. Lan, Z. Lu, J. Mao, J. Piao, H. Wang, D. Jin, and Y. Li, “S3:
    Social-network simulation system with large language model-empowered agents,”
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, and et al., “Language
    models are few-shot learners,” in *Advances in Neural Information Processing Systems*,
    vol. 33.   Curran Associates, Inc., 2020, pp. 1877–1901.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] OpenAI, “Gpt-4 technical report,” 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix,
    B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave,
    and G. Lample, “Llama: Open and efficient foundation language models,” 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] H. Touvron, L. Martin, K. R. Stone, P. Albert, A. Almahairi, and et al.,
    “Llama 2: Open foundation and fine-tuned chat models,” *ArXiv*, vol. abs/2307.09288,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, and et al., “Palm:
    Scaling language modeling with pathways,” *J. Mach. Learn. Res.*, vol. 24, pp.
    240:1–240:113, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos, S. Shakeri,
    E. Taropa, P. Bailey, Z. Chen *et al.*, “Palm 2 technical report,” *arXiv preprint
    arXiv:2305.10403*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] A. Zeng, X. Liu, Z. Du, Z. Wang, H. Lai, and et al., “GLM-130B: an open
    bilingual pre-trained model,” in *The Eleventh International Conference on Learning
    Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023*.   OpenReview.net,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] J. Manyika and S. Hsiao, “An overview of bard: an early experiment with
    generative ai,” *AI. Google Static Documents*, vol. 2, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” *Advances in neural
    information processing systems*, vol. 30, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] J. Li, M. Zhang, N. Li, D. Weyns, Z. Jin, and K. Tei, “Exploring the potential
    of large language models in self-adaptive systems,” 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] K. Suzuki, J. Cai, J. Li, T. Yamauchi, and K. Tei, “A comparative evaluation
    on melody generation of large language models,” in *2023 IEEE International Conference
    on Consumer Electronics-Asia (ICCE-Asia)*, 2023, pp. 1–4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] S. Zhou, J. Li, M. Zhang, D. Saito, H. Washizaki, and K. Tei, “Can chatgpt
    obey the traffic regulations? evaluating chatgpt’s performance on driving-license
    written test,” in *2023 IEEE the 8th International Conference on Intelligent Transportation
    Engineering (ICITE)*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang,
    S. Agarwal, K. Slama, A. Ray *et al.*, “Training language models to follow instructions
    with human feedback,” *Advances in Neural Information Processing Systems*, vol. 35,
    pp. 27 730–27 744, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] C.-S. Wang, H.-L. Yang, B.-Y. Li, and H.-Y. Chen, “Can generative ai eliminate
    speech harms? a study on detection of abusive and hate speech during the covid-19
    pandemic,” in *2023 IEEE International Conference on Consumer Electronics-Asia
    (ICCE-Asia)*, 2023, pp. 1–4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] Y. Seki and Y. Liu, “Multi-task learning model for detecting internet
    slang words with two-layer annotation,” in *2022 International Conference on Asian
    Language Processing (IALP)*, 2022, pp. 212–218.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] M. Rothe, R. Lath, D. Kumar, P. Yadav, and A. Aylani, “Slang language
    detection and identification in text,” in *2023 14th International Conference
    on Computing Communication and Networking Technologies (ICCCNT)*, 2023, pp. 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] Z. Sun, R. S. Zemel, and Y. Xu, “Slang generation as categorization.”
    in *CogSci*, 2019, pp. 2898–2904.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] Z. Sun, R. Zemel, and Y. Xu, “Semantically informed slang interpretation,”
    in *Proceedings of the 2022 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies*, 2022, pp. 5213–5231.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] Y. Fu, H. Peng, T. Khot, and M. Lapata, “Improving language model negotiation
    with self-play and in-context learning from ai feedback,” 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] Y. Xu, S. Wang, P. Li, F. Luo, X. Wang, W. Liu, and Y. Liu, “Exploring
    large language models for communication games: An empirical study on werewolf,”
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] Z. Xu, C. Yu, F. Fang, Y. Wang, and Y. Wu, “Language agents with reinforcement
    learning for strategic play in the werewolf game,” 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] S. Li, J. Yang, and K. Zhao, “Are you in a masquerade? exploring the behavior
    and impact of large language model driven social bots in online social networks,”
    *arXiv preprint arXiv:2307.10337*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] R. C. Atkinson and R. M. Shiffrin, “Human memory: A proposed system and
    its control processes,” in *Psychology of learning and motivation*.   Elsevier,
    1968, vol. 2, pp. 89–195.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. H. hsin Chi, F. Xia, Q. Le,
    and D. Zhou, “Chain of thought prompting elicits reasoning in large language models,”
    *ArXiv*, vol. abs/2201.11903, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] J. Ying, Y. Cao, K. Xiong, Y. He, L. Cui, and Y. Liu, “Intuitive or dependent?
    investigating llms’ robustness to conflicting prompts,” *ArXiv*, vol. abs/2309.17415,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] N. MacKinnon and K. Schilling, “Optimal strategy for a number-guessing
    game: 11051,” *Am. Math. Mon.*, vol. 113, no. 1, pp. 81–82, 2006.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] X. Wang, “Two number-guessing problems plus applications in cryptography,”
    *Int. J. Netw. Secur.*, vol. 21, no. 3, pp. 494–500, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] K. Bahamazava and R. Nanda, “The shift of darknet illegal drug trade preferences
    in cryptocurrency: The question of traceability and deterrence,” *Digit. Investig.*,
    vol. 40, no. Supplement, p. 301377, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] K. Basu and A. Sen, “Monitoring individuals in drug trafficking organizations:
    a social network analysis,” in *ASONAM ’19: International Conference on Advances
    in Social Networks Analysis and Mining, Vancouver, British Columbia, Canada, 27-30
    August, 2019*.   ACM, 2019, pp. 480–483.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] F. Tsai, M. Hsu, C. Chen, and D. Kao, “Exploring drug-related crimes with
    social network analysis,” in *Knowledge-Based and Intelligent Information & Engineering
    Systems: Proceedings of the 23rd International Conference KES-2019, Budapest,
    Hungary, 4-6 September 2019*, vol. 159.   Elsevier, 2019, pp. 1907–1917.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] S. Lyu and Z. Lu, “Exploring temporal and multilingual dynamics of post-disaster
    social media discourse: A case of fukushima daiichi nuclear accident,” *Proc.
    ACM Hum. Comput. Interact.*, vol. 7, no. CSCW1, pp. 1–24, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] E. Zarrabeitia-Bilbao, M. Jaca-Madariaga, R. M. Río-Belver, and I. Alvarez-Meaza,
    “Nuclear energy: Twitter data mining for social listening analysis,” *Soc. Netw.
    Anal. Min.*, vol. 13, no. 1, p. 29, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
