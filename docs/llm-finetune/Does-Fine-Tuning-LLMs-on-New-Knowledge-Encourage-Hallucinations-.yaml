- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: æœªåˆ†ç±»'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»åˆ«ï¼šæœªåˆ†ç±»
- en: 'date: 2024-09-08 18:37:00'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¥æœŸï¼š2024-09-08 18:37:00
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¾®è°ƒ LLMs ä»¥çº³å…¥æ–°çŸ¥è¯†æ˜¯å¦ä¼šé¼“åŠ±å¹»è§‰ï¼Ÿ
- en: æ¥æºï¼š[https://ar5iv.labs.arxiv.org/html/2405.05904](https://ar5iv.labs.arxiv.org/html/2405.05904)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¥æºï¼š[https://ar5iv.labs.arxiv.org/html/2405.05904](https://ar5iv.labs.arxiv.org/html/2405.05904)
- en: Zorik Gekhman^T â€ƒGal Yona^G â€ƒRoee Aharoni^Gâ€ƒMatan Eyal^G â€ƒAmir Feder^G
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Zorik Gekhman^T â€ƒGal Yona^G â€ƒRoee Aharoni^Gâ€ƒMatan Eyal^G â€ƒAmir Feder^G
- en: Roi Reichart^Tâ€ƒJonathan Herzig^G
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Roi Reichart^Tâ€ƒJonathan Herzig^G
- en: ^TTechnion - Israel Institute of Technology â€ƒ^GGoogle Research
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ^Tä»¥è‰²åˆ—ç†å·¥å­¦é™¢ â€ƒ^Gè°·æ­Œç ”ç©¶
- en: zorikgekhman@gmail.com, jherzig@google.com Â  Work done during an internship
    at Google Research.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: zorikgekhman@gmail.com, jherzig@google.com Â  ç ”ç©¶å·¥ä½œåœ¨ Google Research å®ä¹ æœŸé—´å®Œæˆã€‚
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æ‘˜è¦
- en: When large language models are aligned via supervised fine-tuning, they may
    encounter new factual information that was not acquired through pre-training.
    It is often conjectured that this can teach the model the behavior of *hallucinating*
    factually incorrect responses, as the model is trained to generate facts that
    are not grounded in its pre-existing knowledge. In this work, we study the impact
    of such exposure to new knowledge on the capability of the fine-tuned model to
    utilize its pre-existing knowledge. To this end, we design a controlled setup,
    focused on closed-book QA, where we vary the proportion of the fine-tuning examples
    that introduce new knowledge. We demonstrate that large language models struggle
    to acquire new factual knowledge through fine-tuning, as fine-tuning examples
    that introduce new knowledge are learned significantly slower than those consistent
    with the modelâ€™s knowledge. However, we also find that as the examples with new
    knowledge are eventually learned, they linearly increase the modelâ€™s tendency
    to hallucinate. Taken together, our results highlight the risk in introducing
    new factual knowledge through fine-tuning, and support the view that large language
    models mostly acquire factual knowledge through pre-training, whereas fine-tuning
    teaches them to use it more efficiently.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å½“é€šè¿‡ç›‘ç£å¾®è°ƒå¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¯¹é½æ—¶ï¼Œå®ƒä»¬å¯èƒ½ä¼šé‡åˆ°åœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­æœªè·å¾—çš„æ–°äº‹å®ä¿¡æ¯ã€‚é€šå¸¸æ¨æµ‹ï¼Œè¿™å¯èƒ½ä¼šæ•™ä¼šæ¨¡å‹äº§ç”Ÿ*è™šå‡çš„*äº‹å®é”™è¯¯å“åº”çš„è¡Œä¸ºï¼Œå› ä¸ºæ¨¡å‹è¢«è®­ç»ƒç”Ÿæˆä¸åŸºäºå…¶ç°æœ‰çŸ¥è¯†çš„äº‹å®ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†è¿™ç§æ–°çŸ¥è¯†çš„æš´éœ²å¯¹å¾®è°ƒæ¨¡å‹åˆ©ç”¨å…¶ç°æœ‰çŸ¥è¯†èƒ½åŠ›çš„å½±å“ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå—æ§çš„è®¾ç½®ï¼Œé‡ç‚¹å…³æ³¨é—­å·
    QAï¼Œåœ¨è¿™ä¸ªè®¾ç½®ä¸­ï¼Œæˆ‘ä»¬å˜åŒ–å¼•å…¥æ–°çŸ¥è¯†çš„å¾®è°ƒç¤ºä¾‹çš„æ¯”ä¾‹ã€‚æˆ‘ä»¬å±•ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹é€šè¿‡å¾®è°ƒè·å–æ–°äº‹å®çŸ¥è¯†çš„å›°éš¾ï¼Œå› ä¸ºå¼•å…¥æ–°çŸ¥è¯†çš„å¾®è°ƒç¤ºä¾‹å­¦ä¹ é€Ÿåº¦æ˜æ˜¾æ…¢äºä¸æ¨¡å‹çŸ¥è¯†ä¸€è‡´çš„ç¤ºä¾‹ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ä¹Ÿå‘ç°ï¼Œéšç€æ–°çŸ¥è¯†ç¤ºä¾‹çš„æœ€ç»ˆå­¦ä¹ ï¼Œå®ƒä»¬çº¿æ€§å¢åŠ äº†æ¨¡å‹äº§ç”Ÿå¹»è§‰çš„å€¾å‘ã€‚ç»¼ä¸Šæ‰€è¿°ï¼Œæˆ‘ä»¬çš„ç»“æœå¼ºè°ƒäº†é€šè¿‡å¾®è°ƒå¼•å…¥æ–°äº‹å®çŸ¥è¯†çš„é£é™©ï¼Œå¹¶æ”¯æŒäº†å¤§å‹è¯­è¨€æ¨¡å‹ä¸»è¦é€šè¿‡é¢„è®­ç»ƒè·å–äº‹å®çŸ¥è¯†çš„è§‚ç‚¹ï¼Œè€Œå¾®è°ƒåˆ™æ•™ä¼šå®ƒä»¬æ›´æœ‰æ•ˆåœ°ä½¿ç”¨è¿™äº›çŸ¥è¯†ã€‚
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 ä»‹ç»
- en: '![Refer to caption](img/1d35a58459c3bc75e537229b382b4b7a.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒæ ‡é¢˜](img/1d35a58459c3bc75e537229b382b4b7a.png)'
- en: 'Figure 1: Train and development accuracies as a function of the fine-tuning
    duration, when fine-tuning on $50\%$ and $50\%$ examples. $\mathtt{Unknown}$.
    The best development performance is obtained when the LLM fits the majority of
    the $\mathtt{Known}$ ones. From this point, fitting $\mathtt{Unknown}$ examples
    reduces the performance.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 1ï¼šå½“åœ¨ $50\%$ å’Œ $50\%$ çš„ç¤ºä¾‹ä¸Šè¿›è¡Œå¾®è°ƒæ—¶ï¼Œè®­ç»ƒå’Œå¼€å‘å‡†ç¡®æ€§ä¸å¾®è°ƒæ—¶é•¿çš„å…³ç³»ã€‚ $\mathtt{Unknown}$ã€‚å½“ LLM
    é€‚åº”äº†å¤§å¤šæ•°çš„ $\mathtt{Known}$ ç¤ºä¾‹æ—¶ï¼Œè¡¨ç°æœ€ä½³ã€‚ä»è¿™ä¸€ç‚¹å¼€å§‹ï¼Œé€‚åº” $\mathtt{Unknown}$ ç¤ºä¾‹ä¼šé™ä½æ€§èƒ½ã€‚
- en: Pre-training Large Language Models (LLMs) on textual corpora embeds substantial
    factual knowledge in their parameters Petroni etÂ al. ([2019](#bib.bib20)); AlKhamissi
    etÂ al. ([2022](#bib.bib1)); Cohen etÂ al. ([2023](#bib.bib5)), which is essential
    for excelling in various downstream applications. These models often require further
    alignment to desired behaviors, typically achieved through supervised fine-tuning
    on instruction-following tasks Wei etÂ al. ([2022](#bib.bib30)); Mishra etÂ al.
    ([2022](#bib.bib18)) and preference learning from human feedback Ouyang etÂ al.
    ([2022](#bib.bib19)); Rafailov etÂ al. ([2024](#bib.bib21)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ–‡æœ¬è¯­æ–™åº“ä¸ŠåµŒå…¥äº†å¤§é‡äº‹å®çŸ¥è¯†åœ¨å…¶å‚æ•°ä¸­ Petroni et al. ([2019](#bib.bib20)); AlKhamissi
    et al. ([2022](#bib.bib1)); Cohen et al. ([2023](#bib.bib5))ï¼Œè¿™å¯¹åœ¨å„ç§ä¸‹æ¸¸åº”ç”¨ä¸­è¡¨ç°å‡ºè‰²è‡³å…³é‡è¦ã€‚è¿™äº›æ¨¡å‹é€šå¸¸éœ€è¦è¿›ä¸€æ­¥å¯¹é½åˆ°æœŸæœ›çš„è¡Œä¸ºï¼Œé€šå¸¸é€šè¿‡åœ¨æŒ‡ä»¤è·Ÿéšä»»åŠ¡ä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒ
    Wei et al. ([2022](#bib.bib30)); Mishra et al. ([2022](#bib.bib18)) å’Œä»äººç±»åé¦ˆä¸­è¿›è¡Œåå¥½å­¦ä¹ 
    Ouyang et al. ([2022](#bib.bib19)); Rafailov et al. ([2024](#bib.bib21)) æ¥å®ç°ã€‚
- en: In the fine-tuning phase, the model is usually trained on outputs created by
    human annotators or other LLMs. As a result, the model may encounter new factual
    information, extending beyond the knowledge it acquired during pre-training. This
    raises the question of how LLMs integrate new facts outside of their pre-existing
    knowledge. One possibility is that the model simply adapts by learning this new
    factual information. However, a common conjecture posits that such exposure to
    new knowledge may encourage the model to *hallucinate* factually incorrect responses,
    as the model is essentially trained to generate facts that are not grounded in
    its pre-existing knowledge Schulman ([2023](#bib.bib24)); Huang etÂ al. ([2023](#bib.bib9));
    Gao ([2021](#bib.bib6)); Goldberg ([2023](#bib.bib7)); Gudibande etÂ al. ([2023](#bib.bib8)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¾®è°ƒé˜¶æ®µï¼Œæ¨¡å‹é€šå¸¸ä¼šåœ¨ç”±äººå·¥æ ‡æ³¨è€…æˆ–å…¶ä»– LLM åˆ›å»ºçš„è¾“å‡ºä¸Šè¿›è¡Œè®­ç»ƒã€‚å› æ­¤ï¼Œæ¨¡å‹å¯èƒ½ä¼šé‡åˆ°æ–°çš„äº‹å®ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯è¶…å‡ºäº†å®ƒåœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­è·å¾—çš„çŸ¥è¯†ã€‚è¿™å¼•å‘äº†ä¸€ä¸ªé—®é¢˜ï¼Œå³
    LLM å¦‚ä½•æ•´åˆè¶…å‡ºå…¶å·²æœ‰çŸ¥è¯†çš„æ–°äº‹å®ã€‚ä¸€ç§å¯èƒ½æ€§æ˜¯æ¨¡å‹é€šè¿‡å­¦ä¹ è¿™äº›æ–°äº‹å®ä¿¡æ¯æ¥è¿›è¡Œé€‚åº”ã€‚ç„¶è€Œï¼Œæ™®éçš„æ¨æµ‹è®¤ä¸ºï¼Œè¿™ç§æ–°çŸ¥è¯†çš„æš´éœ²å¯èƒ½ä¼šä¿ƒä½¿æ¨¡å‹*å¹»æƒ³*å‡ºäº‹å®ä¸æ­£ç¡®çš„å›åº”ï¼Œå› ä¸ºæ¨¡å‹æœ¬è´¨ä¸Šè¢«è®­ç»ƒç”Ÿæˆä¸å…¶å·²æœ‰çŸ¥è¯†ä¸ç›¸ç¬¦çš„äº‹å®
    Schulman ([2023](#bib.bib24))ï¼›Huang et al. ([2023](#bib.bib9))ï¼›Gao ([2021](#bib.bib6))ï¼›Goldberg
    ([2023](#bib.bib7))ï¼›Gudibande et al. ([2023](#bib.bib8))ã€‚
- en: In this work, we study how learning new factual knowledge through fine-tuning
    impacts the modelâ€™s tendency to hallucinate w.r.t. its pre-existing knowledge,
    exploring the above conjecture.Â¹Â¹1While we focus on supervised fine-tuning, our
    findings are relevant to offline preference optimization methods such as DPOÂ Rafailov
    etÂ al. ([2024](#bib.bib21)) that may add new knowledge.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†é€šè¿‡å¾®è°ƒå­¦ä¹ æ–°äº‹å®çŸ¥è¯†å¦‚ä½•å½±å“æ¨¡å‹åœ¨å…¶å·²æœ‰çŸ¥è¯†æ–¹é¢çš„å¹»æƒ³å€¾å‘ï¼Œæ¢è®¨äº†ä¸Šè¿°æ¨æµ‹ã€‚Â¹Â¹1è™½ç„¶æˆ‘ä»¬ä¸“æ³¨äºç›‘ç£å¾®è°ƒï¼Œä½†æˆ‘ä»¬çš„å‘ç°ä¹Ÿä¸å¦‚
    DPO Rafailov et al. ([2024](#bib.bib21)) ç­‰å¯èƒ½æ·»åŠ æ–°çŸ¥è¯†çš„ç¦»çº¿åå¥½ä¼˜åŒ–æ–¹æ³•ç›¸å…³ã€‚
- en: To study the impact of new knowledge, we must be able to assess whether a single
    fine-tuning example is consistent with the modelâ€™s knowledge. We propose SliCK,
    a hierarchy of four *knowledge categories*, derived from a continuous measure
    that quantifies the agreement between model-generated answers and the ground-truth
    labels. In SliCK, examples are first categorized into $\mathtt{Known}$ types,
    where the latter corresponds to examples with facts that are most likely unknown
    to the model. The $\mathtt{Known}$, $\mathtt{MaybeKnown}$ ([FigureÂ 2](#S2.F2 "In
    2 Study Setup â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç ”ç©¶æ–°çŸ¥è¯†çš„å½±å“ï¼Œæˆ‘ä»¬å¿…é¡»èƒ½å¤Ÿè¯„ä¼°å•ä¸ªå¾®è°ƒç¤ºä¾‹æ˜¯å¦ä¸æ¨¡å‹çš„çŸ¥è¯†ä¸€è‡´ã€‚æˆ‘ä»¬æå‡ºäº† SliCKï¼Œä¸€ä¸ªç”±å››ä¸ª*çŸ¥è¯†ç±»åˆ«*ç»„æˆçš„å±‚æ¬¡ç»“æ„ï¼Œè¿™äº›ç±»åˆ«æ¥æºäºä¸€ä¸ªè¿ç»­é‡åº¦ï¼Œè¯¥é‡åº¦é‡åŒ–äº†æ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚åœ¨
    SliCK ä¸­ï¼Œç¤ºä¾‹é¦–å…ˆè¢«åˆ†ç±»ä¸º $\mathtt{Known}$ ç±»å‹ï¼Œå…¶ä¸­åè€…å¯¹åº”äºæ¨¡å‹æœ€å¯èƒ½ä¸çŸ¥é“çš„äº‹å®çš„ç¤ºä¾‹ã€‚$\mathtt{Known}$ã€$\mathtt{MaybeKnown}$ï¼ˆ[å›¾Â 2](#S2.F2
    "åœ¨ 2 ç ”ç©¶è®¾ç½® â€£ å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹æ˜¯å¦ä¼šé¼“åŠ±å¹»æƒ³ï¼Ÿ")ï¼‰ã€‚
- en: Equipped with the above method, we carefully design a controlled study, focused
    on closed-book question answering (QA), where we vary the proportion of the fine-tuning
    examples categorized as $\mathtt{Unknown}$, while controlling for other factors.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ç”¨ä¸Šè¿°æ–¹æ³•ï¼Œæˆ‘ä»¬ç²¾å¿ƒè®¾è®¡äº†ä¸€é¡¹å—æ§ç ”ç©¶ï¼Œä¸“æ³¨äºé—­å·é—®ç­”ï¼ˆQAï¼‰ï¼Œåœ¨å…¶ä¸­æˆ‘ä»¬è°ƒæ•´äº†è¢«åˆ†ç±»ä¸º $\mathtt{Unknown}$ çš„å¾®è°ƒç¤ºä¾‹çš„æ¯”ä¾‹ï¼ŒåŒæ—¶æ§åˆ¶å…¶ä»–å› ç´ ã€‚
- en: Our study empirically demonstrates that learning from $\mathtt{Unknown}$ examples
    is correlated with better utilization of pre-existing knowledge.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„ç ”ç©¶å®è¯è¡¨æ˜ï¼Œä» $\mathtt{Unknown}$ ç¤ºä¾‹ä¸­å­¦ä¹ ä¸æ›´å¥½åœ°åˆ©ç”¨å·²æœ‰çŸ¥è¯†ç›¸å…³ã€‚
- en: Through an analysis of the training dynamics, we discover that the LLM fits
    $\mathtt{Unknown}$ examples (top plot in [FigureÂ 1](#S1.F1 "In 1 Introduction
    â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")). This indicates
    that during fine-tuning, LLMs struggle to integrate new factual knowledge (present
    in the $\mathtt{Unknown}$ fine-tuning examples).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å¯¹è®­ç»ƒåŠ¨æ€çš„åˆ†æï¼Œæˆ‘ä»¬å‘ç° LLM æ‹Ÿåˆäº† $\mathtt{Unknown}$ ç¤ºä¾‹ï¼ˆ[å›¾Â 1](#S1.F1 "åœ¨ 1 å¼•è¨€ â€£ å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹æ˜¯å¦ä¼šé¼“åŠ±å¹»æƒ³ï¼Ÿ")ä¸­çš„é¡¶éƒ¨å›¾è¡¨ï¼‰ã€‚è¿™è¡¨æ˜åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼ŒLLM
    éš¾ä»¥æ•´åˆæ–°çš„äº‹å®çŸ¥è¯†ï¼ˆå­˜åœ¨äº $\mathtt{Unknown}$ å¾®è°ƒç¤ºä¾‹ä¸­ï¼‰ã€‚
- en: From a practical perspective, mitigating overfitting using *early-stopping*
    (vertical dotted line in [FigureÂ 1](#S1.F1 "In 1 Introduction â€£ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?")) can minimize the risk of the
    hallucinations caused by fitting the $\mathtt{Unknown}$ fine-tuning examples substantially
    reduces the risk of overfitting, without sacrificing performance.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å®é™…è§’åº¦æ¥çœ‹ï¼Œä½¿ç”¨*æ—©åœ*ï¼ˆ[å›¾ 1](#S1.F1 "åœ¨1ä»‹ç» â€£ å¾®è°ƒLLMsçš„æ–°çŸ¥è¯†æ˜¯å¦ä¼šé¼“åŠ±å¹»è§‰ï¼Ÿ")ä¸­çš„å‚ç›´è™šçº¿ï¼‰å¯ä»¥æœ€å¤§é™åº¦åœ°å‡å°‘ç”±æ‹Ÿåˆ$\mathtt{æœªçŸ¥}$å¾®è°ƒç¤ºä¾‹å¼•èµ·çš„å¹»è§‰é£é™©ï¼Œä¸”ä¸ä¼šç‰ºç‰²æ€§èƒ½ã€‚
    |
- en: We further evaluate the impact of fine-tuning examples from each of our three
    $\mathtt{Known}$, does not yield the best results. Our analysis reveals that incorporating
    $\mathtt{MaybeKnown}$ fine-tuning examples, representing facts with lower degrees
    of certainty, plays an important part in properly handling such examples in test
    time. This indicates that the composition of fine-tuning examples significantly
    influences the extent to which LLMs effectively utilize their pre-existing knowledge.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿›ä¸€æ­¥è¯„ä¼°äº†ä»æ¯ä¸ª$\mathtt{å·²çŸ¥}$çš„å¾®è°ƒç¤ºä¾‹çš„å½±å“ï¼Œå‘ç°è¿™å¹¶æœªäº§ç”Ÿæœ€ä½³ç»“æœã€‚æˆ‘ä»¬çš„åˆ†ææ­ç¤ºäº†ï¼Œå°†$\mathtt{å¯èƒ½å·²çŸ¥}$çš„å¾®è°ƒç¤ºä¾‹ï¼ˆä»£è¡¨ä¸ç¡®å®šåº¦è¾ƒä½çš„äº‹å®ï¼‰çº³å…¥å…¶ä¸­ï¼Œåœ¨æµ‹è¯•æ—¶å¤„ç†è¿™äº›ç¤ºä¾‹æ—¶èµ·åˆ°äº†é‡è¦ä½œç”¨ã€‚è¿™è¡¨æ˜å¾®è°ƒç¤ºä¾‹çš„ç»„æˆæ˜¾è‘—å½±å“äº†LLMsæœ‰æ•ˆåˆ©ç”¨å…¶é¢„å…ˆå­˜åœ¨çŸ¥è¯†çš„ç¨‹åº¦ã€‚
    |
- en: To summarize, we study the effect of new factual knowledge in the fine-tuning
    data by designing a controlled setup that isolates this factor. We find that fine-tuning
    examples that introduce new knowledge are learned slowly, which suggests that
    LLMs struggle to integrate new knowledge through fine-tuning and supports the
    view that LLMs mostly acquire knowledge through pre-training Zhou etÂ al. ([2023](#bib.bib34));
    Lin etÂ al. ([2023](#bib.bib15)). However, we also find that as the model eventually
    learns new knowledge through fine-tuning, it becomes more prone to hallucinations
    w.r.t. its pre-existing knowledge. Collectively, our findings highlight the potential
    for unintended consequences when introducing new knowledge through fine-tuning,
    and imply that fine-tuning may be more useful as a mechanism to enhance the utilization
    of pre-existing knowledge.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“æ¥è¯´ï¼Œæˆ‘ä»¬é€šè¿‡è®¾è®¡ä¸€ä¸ªæ§åˆ¶è®¾ç½®æ¥ç ”ç©¶å¾®è°ƒæ•°æ®ä¸­æ–°äº‹å®çŸ¥è¯†çš„æ•ˆæœï¼Œä»¥éš”ç¦»è¿™ä¸€å› ç´ ã€‚æˆ‘ä»¬å‘ç°ï¼Œå¼•å…¥æ–°çŸ¥è¯†çš„å¾®è°ƒç¤ºä¾‹å­¦ä¹ ç¼“æ…¢ï¼Œè¿™è¡¨æ˜LLMsé€šè¿‡å¾®è°ƒæ•´åˆæ–°çŸ¥è¯†å­˜åœ¨å›°éš¾ï¼Œå¹¶æ”¯æŒLLMsä¸»è¦é€šè¿‡é¢„è®­ç»ƒè·å¾—çŸ¥è¯†çš„è§‚ç‚¹ï¼ˆZhou
    et al. ([2023](#bib.bib34)); Lin et al. ([2023](#bib.bib15))ï¼‰ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ä¹Ÿå‘ç°ï¼Œå½“æ¨¡å‹æœ€ç»ˆé€šè¿‡å¾®è°ƒå­¦ä¹ æ–°çŸ¥è¯†æ—¶ï¼Œå®ƒå¯¹å…¶é¢„å…ˆå­˜åœ¨çš„çŸ¥è¯†æ›´å®¹æ˜“å‡ºç°å¹»è§‰ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„å‘ç°çªæ˜¾äº†é€šè¿‡å¾®è°ƒå¼•å…¥æ–°çŸ¥è¯†æ—¶å¯èƒ½äº§ç”Ÿçš„æ„å¤–åæœï¼Œå¹¶æš—ç¤ºå¾®è°ƒä½œä¸ºå¢å¼ºé¢„å…ˆå­˜åœ¨çŸ¥è¯†åˆ©ç”¨çš„æœºåˆ¶å¯èƒ½æ›´æœ‰ç”¨ã€‚
    |
- en: 2 Study Setup
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 ç ”ç©¶è®¾ç½®
- en: '| Type | Category | Definition | Explanation |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| ç±»å‹ | ç±»åˆ« | å®šä¹‰ | è§£é‡Š |'
- en: '| --- | --- | --- | --- |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| $\mathtt{Known}$ | $P_{\mathtt{Correct}}(q,a;M,T=0)=1$ | Greedy decoding
    *always* predicts the correct answer. |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{å·²çŸ¥}$ | $P_{\mathtt{æ­£ç¡®}}(q,a;M,T=0)=1$ | è´ªå©ªè§£ç *æ€»æ˜¯*é¢„æµ‹æ­£ç¡®ç­”æ¡ˆã€‚ |'
- en: '| $\mathtt{MaybeKnown}$ | Greedy decoding *sometimes* (but not always) predicts
    the correct answer. |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{å¯èƒ½å·²çŸ¥}$ | è´ªå©ªè§£ç *æœ‰æ—¶*ï¼ˆä½†å¹¶éæ€»æ˜¯ï¼‰é¢„æµ‹æ­£ç¡®ç­”æ¡ˆã€‚ |'
- en: '| $\mathtt{WeaklyKnown}$ | Greedy decoding *never* predicts the correct answer,
    whereas temperature sampling with  *sometimes* predicts the correct answer. |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{å¼±å·²çŸ¥}$ | è´ªå©ªè§£ç *ä»ä¸*é¢„æµ‹æ­£ç¡®ç­”æ¡ˆï¼Œè€Œæ¸©åº¦é‡‡æ ·åœ¨*æœ‰æ—¶*é¢„æµ‹æ­£ç¡®ç­”æ¡ˆã€‚ |'
- en: '| $\mathtt{Unknown}$ | $P_{\mathtt{Correct}}(q,a;M,T\geq 0)=0$ | The model
    *never* predicts the correct answer, thus it seem to lack the knowledge of the
    correct answer. |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{æœªçŸ¥}$ | $P_{\mathtt{æ­£ç¡®}}(q,a;M,T\geq 0)=0$ | æ¨¡å‹*ä»ä¸*é¢„æµ‹æ­£ç¡®ç­”æ¡ˆï¼Œå› æ­¤ä¼¼ä¹ç¼ºä¹æ­£ç¡®ç­”æ¡ˆçš„çŸ¥è¯†ã€‚
    |'
- en: (a)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '| Category | Question | Gold Answer | Greedy Answers | Sampled Answers |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| ç±»åˆ« | é—®é¢˜ | é»„é‡‘ç­”æ¡ˆ | è´ªå©ªç­”æ¡ˆ | é‡‡æ ·ç­”æ¡ˆ |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| $\mathtt{HighlyKnown}$ | Who founded Science of Mind? | Ernest Holmes | [Ernest
    Holmes, .. Ernest Holmes, ..] | [â€¦, â€¦] |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{é«˜åº¦å·²çŸ¥}$ | è°åˆ›ç«‹äº†ã€Šå¿ƒçµç§‘å­¦ã€‹ï¼Ÿ | Ernest Holmes | [Ernest Holmes, .. Ernest
    Holmes, ..] | [â€¦, â€¦] |'
- en: '| $\mathtt{MaybeKnown}$ | What is the capital of Toledo District? | Punta Gorda
    | [Belmopan, .., Punta Gorda, ..] | [â€¦, â€¦] |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{å¯èƒ½å·²çŸ¥}$ | æ‰˜è±å¤šåŒºçš„é¦–éƒ½æ˜¯ä»€ä¹ˆï¼Ÿ | Punta Gorda | [Belmopan, .., Punta Gorda,
    ..] | [â€¦, â€¦] |'
- en: '| $\mathtt{WeaklyKnown}$ | What kind of work does Scott McGrew do? | Journalist
    | [Film director, .. Actor, ..] | [Musician, .. Journalist, ..] |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{å¼±å·²çŸ¥}$ | Scott McGrewä»äº‹ä»€ä¹ˆå·¥ä½œï¼Ÿ | è®°è€… | [ç”µå½±å¯¼æ¼”, .. æ¼”å‘˜, ..] | [éŸ³ä¹å®¶, ..
    è®°è€…, ..] |'
- en: '| $\mathtt{Unknown}$ | Where is Benedict located? | Hubbard County | [Louisiana,
    .. New Mexico, ..] | [Washington, .. Texas, ..] |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| $\mathtt{Unknown}$ | æœ¬å°¼è¿ªå…‹ç‰¹åœ¨å“ªé‡Œï¼Ÿ | å“ˆä¼¯å¾·å¿ | [è·¯æ˜“æ–¯å®‰é‚£å·ï¼Œ.. æ–°å¢¨è¥¿å“¥å·ï¼Œ..] | [åç››é¡¿å·ï¼Œ.. å¾·å…‹è¨æ–¯å·ï¼Œ..]
    |'
- en: (b)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆbï¼‰
- en: 'Figure 2: Formal definitions of the SliCK knowledge categories, based on the
    $P_{\mathtt{Correct}}$ measure as defined in Â§[3](#S3 "3 Quantifying Knowledge
    in LLMs â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") (a),
    accompanied with real examples from the annotated EntityQuestions dataset used
    in our study (b).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 2ï¼šSliCK çŸ¥è¯†ç±»åˆ«çš„æ­£å¼å®šä¹‰ï¼ŒåŸºäº Â§[3](#S3 "3 é‡åŒ– LLM çŸ¥è¯† â€£ å¯¹æ–°çŸ¥è¯†è¿›è¡Œç»†è°ƒæ˜¯å¦ä¼šå¯¼è‡´è™šå‡ä¿¡æ¯ï¼Ÿ")ï¼ˆaï¼‰ä¸­å®šä¹‰çš„ $P_{\mathtt{Correct}}$
    æµ‹é‡ï¼Œå¹¶é™„æœ‰æ¥è‡ªæˆ‘ä»¬ç ”ç©¶ä¸­ä½¿ç”¨çš„æ³¨é‡Š EntityQuestions æ•°æ®é›†çš„å®é™…ç¤ºä¾‹ï¼ˆbï¼‰ã€‚
- en: Given a fine-tuning dataset $D$, we denote by $M_{D}$ on $D$ affects $M_{D}$
    with varying proportions of examples that are unknown to $M$.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ç»™å®šä¸€ä¸ªç»†è°ƒæ•°æ®é›† $D$ï¼Œæˆ‘ä»¬ç”¨ $M_{D}$ è¡¨ç¤º $D$ ä¸Šçš„ $M_{D}$ï¼Œå…¶å—ä¸åŒæ¯”ä¾‹çš„æœªçŸ¥ç¤ºä¾‹å½±å“ã€‚
- en: When constructing $D$, where $q$ is the ground-truth answer (e.g., â€œFranceâ€).
    To this end, we use EntityQuestions Sciavolino etÂ al. ([2021](#bib.bib25)), where
    triplets from a diverse set of relations from Wikidata VrandeÄiÄ‡ and KrÃ¶tzsch
    ([2014](#bib.bib28)) are converted to QA pairs. These relations encompass a broad
    spectrum of factual knowledge, including biographical information, geographical
    data, ownership and authorship details, history and more. We use the original
    development and test splits, and we sub-sample the train split to create different
    variants of $D$. We focus on 12 diverse relations and reserve 7 additional relations
    for an *out-of-distribution* test set, used (only) in Â§[4.5](#S4.SS5 "4.5 Generalization
    to New Relations â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?").
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ„å»º $D$ æ—¶ï¼Œå…¶ä¸­ $q$ æ˜¯çœŸå®ç­”æ¡ˆï¼ˆä¾‹å¦‚ï¼Œâ€œæ³•å›½â€ï¼‰ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ EntityQuestions Sciavolino ç­‰ï¼ˆ[2021](#bib.bib25)ï¼‰ï¼Œå…¶ä¸­æ¥è‡ª
    Wikidata VrandeÄiÄ‡ å’Œ KrÃ¶tzschï¼ˆ[2014](#bib.bib28)ï¼‰çš„å¤šæ ·å…³ç³»ä¸‰å…ƒç»„è¢«è½¬æ¢ä¸º QA å¯¹ã€‚è¿™äº›å…³ç³»æ¶µç›–äº†å¹¿æ³›çš„äº‹å®çŸ¥è¯†ï¼ŒåŒ…æ‹¬ä¼ è®°ä¿¡æ¯ã€åœ°ç†æ•°æ®ã€æ‰€æœ‰æƒå’Œä½œè€…ä¿¡æ¯ã€å†å²ç­‰ã€‚æˆ‘ä»¬ä½¿ç”¨åŸå§‹çš„å¼€å‘å’Œæµ‹è¯•åˆ’åˆ†ï¼Œå¹¶å¯¹è®­ç»ƒåˆ’åˆ†è¿›è¡Œå­æŠ½æ ·ä»¥åˆ›å»ºä¸åŒçš„
    $D$ å˜ä½“ã€‚æˆ‘ä»¬å…³æ³¨ 12 ç§ä¸åŒçš„å…³ç³»ï¼Œå¹¶ä¸º *åˆ†å¸ƒå¤–* æµ‹è¯•é›†ä¿ç•™ 7 ç§é¢å¤–çš„å…³ç³»ï¼Œä»…åœ¨ Â§[4.5](#S4.SS5 "4.5 æ–°å…³ç³»çš„æ³›åŒ– â€£
    4 æœªçŸ¥ç¤ºä¾‹æœ‰å¤šæœ‰å®³ï¼Ÿ â€£ å¯¹æ–°çŸ¥è¯†è¿›è¡Œç»†è°ƒæ˜¯å¦ä¼šå¯¼è‡´è™šå‡ä¿¡æ¯ï¼Ÿ") ä¸­ä½¿ç”¨ã€‚
- en: As $M$, we use the PaLM 2-M base model Anil etÂ al. ([2023](#bib.bib2)). We focus
    on exact match (EM) as our evaluation metric.Â²Â²2We validated that in our setting
    EM strongly correlates with word-level F1 Rajpurkar etÂ al. ([2016](#bib.bib22)),
    and we choose EM as it is more intuitive for the purposes of our analysis. Full
    technical details are in Â§[A](#A1 "Appendix A Data Preprocessing â€£ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?").
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸º $M$ï¼Œæˆ‘ä»¬ä½¿ç”¨ PaLM 2-M åŸºç¡€æ¨¡å‹ Anil ç­‰ï¼ˆ[2023](#bib.bib2)ï¼‰ã€‚æˆ‘ä»¬å…³æ³¨ç²¾ç¡®åŒ¹é…ï¼ˆEMï¼‰ä½œä¸ºæˆ‘ä»¬çš„è¯„ä¼°æŒ‡æ ‡ã€‚Â²Â²2
    æˆ‘ä»¬éªŒè¯äº†åœ¨æˆ‘ä»¬çš„è®¾ç½®ä¸­ EM ä¸å•è¯çº§ F1 Rajpurkar ç­‰ï¼ˆ[2016](#bib.bib22)ï¼‰å¼ºç›¸å…³ï¼Œæˆ‘ä»¬é€‰æ‹© EMï¼Œå› ä¸ºå®ƒåœ¨åˆ†æä¸­æ›´ç›´è§‚ã€‚å®Œæ•´çš„æŠ€æœ¯ç»†èŠ‚è§
    Â§[A](#A1 "é™„å½• A æ•°æ®é¢„å¤„ç† â€£ å¯¹æ–°çŸ¥è¯†è¿›è¡Œç»†è°ƒæ˜¯å¦ä¼šå¯¼è‡´è™šå‡ä¿¡æ¯ï¼Ÿ")ã€‚
- en: 3 Quantifying Knowledge in LLMs
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 é‡åŒ– LLM ä¸­çš„çŸ¥è¯†
- en: To assess the effect of new knowledge in $D$, we have to annotate each $(q,a)$
    w.r.t. whether $M$ is $a$ measure based on samples from $M$ pairs into four *knowledge
    categories*. We name this approach SliCK (Sampling-based Categorization of Knowledge).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¯„ä¼° $D$ ä¸­æ–°çŸ¥è¯†çš„æ•ˆæœï¼Œæˆ‘ä»¬å¿…é¡»æ ¹æ® $M$ æ˜¯å¦æ˜¯ $a$ çš„æ ·æœ¬ï¼Œå¯¹æ¯ä¸ª $(q,a)$ è¿›è¡Œæ³¨é‡Šï¼ŒåŸºäºä» $M$ ä¸­æŠ½å–çš„æ ·æœ¬å°†å…¶åˆ’åˆ†ä¸ºå››ä¸ª
    *çŸ¥è¯†ç±»åˆ«*ã€‚æˆ‘ä»¬å°†è¿™ç§æ–¹æ³•å‘½åä¸º SliCKï¼ˆåŸºäºé‡‡æ ·çš„çŸ¥è¯†åˆ†ç±»ï¼‰ã€‚
- en: '![Refer to caption](img/3b3ae11ed58b850538a0c65864c005e8.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒè¯´æ˜](img/3b3ae11ed58b850538a0c65864c005e8.png)'
- en: (a)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆaï¼‰
- en: '![Refer to caption](img/2e7c479730dcb1b5c36867e65ca4b5e0.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒè¯´æ˜](img/2e7c479730dcb1b5c36867e65ca4b5e0.png)'
- en: (b)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆbï¼‰
- en: 'Figure 3: Test performance as a function of the $\%$ examples in the fine-tuning
    dataset $D$ and are identical to (a). Dotted lines correspond to fine-tuning on
    the ablated variants $D_{\mathtt{Known}}$ examples are filtered-out. For $0\%$
    $D=$ and for $100\%$ there is no $D_{\mathtt{Known}}$.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 3ï¼šæµ‹è¯•æ€§èƒ½ä½œä¸ºç»†è°ƒæ•°æ®é›† $D$ ä¸­ç¤ºä¾‹æ¯”ä¾‹ $\%$ çš„å‡½æ•°ï¼Œä¸ï¼ˆaï¼‰ç›¸åŒã€‚è™šçº¿å¯¹åº”äºç»†è°ƒæ—¶è¢«æ’é™¤çš„å˜ä½“ $D_{\mathtt{Known}}$
    ç¤ºä¾‹ã€‚å¯¹äº $0\%$ï¼Œ$D=$ï¼Œè€Œå¯¹äº $100\%$ï¼Œæ²¡æœ‰ $D_{\mathtt{Known}}$ã€‚
- en: Defining $\bm{P_{\bm{\mathtt{Correct}}}}$.
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å®šä¹‰ $\bm{P_{\bm{\mathtt{Correct}}}}$ã€‚
- en: We adopt the perspective that $M$ is $a$ when prompted to answer $q$ is a base
    model that has not been specifically fine-tuned to follow instructions, we prompt
    $M$.Â³Â³3In our study we achieve this by using exemplars from the same relation.
    E.g., if $q=$â€œWhere is Paris located?â€, the exemplars would follow the pattern
    â€œWhere is {X} located?â€.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é‡‡çº³äº† $M$ æ˜¯å½“è¢«æç¤ºå›ç­” $q$ æ—¶çš„ $a$ çš„è§‚ç‚¹ï¼Œä½œä¸ºä¸€ä¸ªæ²¡æœ‰è¢«ä¸“é—¨å¾®è°ƒä»¥éµå¾ªæŒ‡ä»¤çš„åŸºç¡€æ¨¡å‹ï¼Œæˆ‘ä»¬æç¤º $M$ã€‚Â³Â³3åœ¨æˆ‘ä»¬çš„ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨æ¥è‡ªç›¸åŒå…³ç³»çš„ç¤ºä¾‹æ¥å®ç°è¿™ä¸€ç‚¹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœ
    $q=$â€œå·´é»åœ¨å“ªé‡Œï¼Ÿâ€ç¤ºä¾‹å°†éµå¾ªæ¨¡å¼â€œ{X} ä½äºå“ªé‡Œï¼Ÿâ€
- en: In practice, $M$ as an estimate of how likely is $M$ to $q$.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œ$M$ æ˜¯å¯¹ $M$ ç›¸å¯¹äº $q$ å¯èƒ½æ€§çš„ä¼°è®¡ã€‚
- en: For the purposes of our study we approximate the value of $P_{\mathtt{Correct}}$
    different random 4-shot prompts.â´â´4We use 4-shot simply since we found it enough
    for $M$ and $16$. $P_{\mathtt{Correct}}(q,a;M,T=0)$ by the fraction of correct
    sampled answers. Full details are in Â§[C](#A3 "Appendix C ğ‘·_ğ™²ğš˜ğš›ğš›ğšğšŒğš Approximation
    â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æˆ‘ä»¬çš„ç ”ç©¶ç›®çš„ï¼Œæˆ‘ä»¬é€šè¿‡ä¸åŒçš„éšæœº 4-shot æç¤ºæ¥è¿‘ä¼¼ $P_{\mathtt{Correct}}$ çš„å€¼ã€‚â´â´4æˆ‘ä»¬ä½¿ç”¨ 4-shot ä»…ä»…æ˜¯å› ä¸ºæˆ‘ä»¬å‘ç°å®ƒå¯¹äº
    $M$ å’Œ $16$ è¶³å¤Ÿã€‚$P_{\mathtt{Correct}}(q,a;M,T=0)$ æ˜¯é€šè¿‡æ­£ç¡®å›ç­”çš„æ¯”ä¾‹æ¥è®¡ç®—çš„ã€‚è¯¦ç»†ä¿¡æ¯è§ Â§[C](#A3
    "é™„å½• C ğ‘·_ğ™²ğš˜ğš›ğš›ğšğšŒğš è¿‘ä¼¼ â€£ å¾®è°ƒ LLM æ˜¯å¦ä¼šå¯¼è‡´è™šå‡ä¿¡æ¯ï¼Ÿ")ã€‚
- en: Deriving knowledge categories from $\bm{P_{\bm{\mathtt{Correct}}}}$.
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ä» $\bm{P_{\bm{\mathtt{Correct}}}}$ å¯¼å‡ºçŸ¥è¯†ç±»åˆ«ã€‚
- en: We define the $\mathtt{Unknown}$ pairs for which $M$. In our notations this
    means that $P_{\mathtt{Correct}}(q,a;M,T\geq 0)=0$, i.e. $M$, we consider $(q,a)$.
    In this choice, we posit that if prompting $M$ can *sometimes* result with the
    correct answer $a$ must have some association with the relevant fact.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å®šä¹‰äº† $\mathtt{Unknown}$ å¯¹ï¼Œå¯¹äº $M$ã€‚åœ¨æˆ‘ä»¬çš„ç¬¦å·ä¸­ï¼Œè¿™æ„å‘³ç€ $P_{\mathtt{Correct}}(q,a;M,T\geq
    0)=0$ï¼Œå³ $M$ï¼Œæˆ‘ä»¬è€ƒè™‘ $(q,a)$ã€‚åœ¨è¿™ä¸ªé€‰æ‹©ä¸­ï¼Œæˆ‘ä»¬å‡è®¾å¦‚æœæç¤º $M$ æœ‰æ—¶èƒ½ç»™å‡ºæ­£ç¡®ç­”æ¡ˆ $a$ï¼Œé‚£ä¹ˆ $a$ å¿…é¡»ä¸ç›¸å…³äº‹å®æœ‰æŸç§å…³è”ã€‚
- en: Recognizing that knowledge can vary in degrees of certainty and extent, we divide
    the $\mathtt{Known}$ pairs into three distinct categories (top three rows in Tables
    [1(a)](#S2.T1.st1 "Table 1(a) â€£ Figure 2 â€£ 2 Study Setup â€£ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?") and [1(b)](#S2.T1.st2 "Table 1(b)
    â€£ Figure 2 â€£ 2 Study Setup â€£ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?")). Motivated by the principle that $M$ if $(q,a)$, we put emphasis
    on *greedy decoding* outcomes, represented with $P_{\mathtt{Correct}}(q,a;M,T=0)$
    represents $(q,a)$ *always* greedily predicts $a$ *sometimes* (but not always)
    greedily predicts $a$ as $\mathtt{MaybeKnown}$ *never* greedily predicts $a$ as
    $\mathtt{WeaklyKnown}$.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: è®¤è¯†åˆ°çŸ¥è¯†å¯ä»¥åœ¨ç¡®å®šæ€§å’ŒèŒƒå›´ä¸Šæœ‰æ‰€ä¸åŒï¼Œæˆ‘ä»¬å°† $\mathtt{Known}$ å¯¹åˆ†ä¸ºä¸‰ä¸ªä¸åŒçš„ç±»åˆ«ï¼ˆè§è¡¨ [1(a)](#S2.T1.st1 "è¡¨
    1(a) â€£ å›¾ 2 â€£ 2 ç ”ç©¶è®¾ç½® â€£ å¾®è°ƒ LLM æ˜¯å¦ä¼šå¯¼è‡´è™šå‡ä¿¡æ¯ï¼Ÿ") å’Œ [1(b)](#S2.T1.st2 "è¡¨ 1(b) â€£ å›¾ 2 â€£
    2 ç ”ç©¶è®¾ç½® â€£ å¾®è°ƒ LLM æ˜¯å¦ä¼šå¯¼è‡´è™šå‡ä¿¡æ¯ï¼Ÿ")ï¼‰ã€‚å— $M$ çš„åŸåˆ™å¯å‘ï¼Œå¦‚æœ $(q,a)$ï¼Œæˆ‘ä»¬å¼ºè°ƒ *è´ªå©ªè§£ç * çš„ç»“æœï¼Œç”¨ $P_{\mathtt{Correct}}(q,a;M,T=0)$
    è¡¨ç¤º $(q,a)$ *æ€»æ˜¯* è´ªå©ªåœ°é¢„æµ‹ $a$ *æœ‰æ—¶*ï¼ˆä½†ä¸æ˜¯æ€»æ˜¯ï¼‰è´ªå©ªåœ°é¢„æµ‹ $a$ ä½œä¸º $\mathtt{MaybeKnown}$ *ä»ä¸* è´ªå©ªåœ°é¢„æµ‹
    $a$ ä½œä¸º $\mathtt{WeaklyKnown}$ã€‚
- en: We apply SliCK to annotate each $(q,a)$.âµâµ5In EntityQuestions we have $24\%$,
    $23\%$, $17\%$, and $36\%$. Full per-relation statistics are in Â§[D](#A4 "Appendix
    D Data Annotation â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
    We analyze the quality of our categories in Â§[6](#S6 "6 SliCK Knowledge Categories
    Analysis â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åº”ç”¨ SliCK æ¥æ³¨é‡Šæ¯ä¸ª $(q,a)$ã€‚âµâµ5åœ¨ EntityQuestions ä¸­ï¼Œæˆ‘ä»¬çš„æ¯”ä¾‹åˆ†åˆ«ä¸º $24\%$ã€$23\%$ã€$17\%$
    å’Œ $36\%$ã€‚è¯¦ç»†çš„æ¯å…³ç³»ç»Ÿè®¡æ•°æ®è§ Â§[D](#A4 "é™„å½• D æ•°æ®æ³¨é‡Š â€£ å¾®è°ƒ LLM æ˜¯å¦ä¼šå¯¼è‡´è™šå‡ä¿¡æ¯ï¼Ÿ")ã€‚æˆ‘ä»¬åœ¨ Â§[6](#S6 "6
    SliCK çŸ¥è¯†ç±»åˆ«åˆ†æ â€£ å¾®è°ƒ LLM æ˜¯å¦ä¼šå¯¼è‡´è™šå‡ä¿¡æ¯ï¼Ÿ") åˆ†æäº†æˆ‘ä»¬ç±»åˆ«çš„è´¨é‡ã€‚
- en: 4 How Harmful are $\mathtt{Unknown}$ Examples?
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 $\mathtt{Unknown}$ ç¤ºä¾‹çš„å±å®³æœ‰å¤šå¤§ï¼Ÿ
- en: 'In this section we study the effect of new knowledge in the fine-tuning dataset
    $D$ examples in $D$ and create variants of $D$ of $\mathtt{Unknown}$ $\mathtt{Known}$
    categories collectively (see [TableÂ 1(a)](#S2.T1.st1 "In Figure 2 â€£ 2 Study Setup
    â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")), and provide
    a per-category analysis in Â§[5](#S5 "5 Understanding Knowledge Types: Their Value
    and Impact â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
    We denote early-stopping based on the development set as early_stop (happens after
    5-10 epochs) and 50 fine-tuning epochs as Convergence, as at this point $M$ (i.e.
    $100\%$ training accuracy). We measure test performance as a proxy for hallucinations
    since we are in a closed-book QA setup with disjoint train/test splits, where
    the model has to use its per-existing knowledge to answer test questions (see
    Â§[B](#A2 "Appendix B Test performance as Proxy for Hallucinations â€£ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?") for further discussion).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†æ–°çŸ¥è¯†åœ¨å¾®è°ƒæ•°æ®é›† $D$ ä¸­çš„æ•ˆæœï¼Œå¹¶åˆ›å»ºäº† $D$ çš„ $\mathtt{Unknown}$ å’Œ $\mathtt{Known}$
    ç±»åˆ«çš„å˜ä½“ï¼ˆè§ [è¡¨ 1(a)](#S2.T1.st1 "åœ¨å›¾ 2 â€£ 2 å­¦ä¹ è®¾ç½® â€£ å¾®è°ƒ LLM åœ¨æ–°çŸ¥è¯†ä¸Šçš„è¡¨ç°æ˜¯å¦ä¿ƒä½¿è™šå‡ä¿¡æ¯ï¼Ÿ")ï¼‰ï¼Œå¹¶åœ¨ Â§[5](#S5
    "5 ç†è§£çŸ¥è¯†ç±»å‹ï¼šå®ƒä»¬çš„ä»·å€¼å’Œå½±å“ â€£ å¾®è°ƒ LLM åœ¨æ–°çŸ¥è¯†ä¸Šçš„è¡¨ç°æ˜¯å¦ä¿ƒä½¿è™šå‡ä¿¡æ¯ï¼Ÿ") æä¾›äº†æ¯ä¸ªç±»åˆ«çš„åˆ†æã€‚æˆ‘ä»¬å°†åŸºäºå¼€å‘é›†çš„æ—©æœŸåœæ­¢ç§°ä¸º early_stopï¼ˆå‘ç”Ÿåœ¨
    5-10 ä¸ªå‘¨æœŸä¹‹åï¼‰ï¼Œ50 ä¸ªå¾®è°ƒå‘¨æœŸç§°ä¸º Convergenceï¼Œæ­¤æ—¶ $M$ï¼ˆå³ $100\%$ è®­ç»ƒå‡†ç¡®ç‡ï¼‰ã€‚æˆ‘ä»¬æµ‹é‡æµ‹è¯•æ€§èƒ½ä½œä¸ºè™šå‡ä¿¡æ¯çš„ä»£ç†ï¼Œå› ä¸ºæˆ‘ä»¬å¤„äºä¸€ä¸ªå°é—­ä¹¦æœ¬
    QA è®¾ç½®ä¸­ï¼Œè®­ç»ƒ/æµ‹è¯•æ‹†åˆ†æ˜¯äº’æ–¥çš„ï¼Œæ¨¡å‹å¿…é¡»åˆ©ç”¨å…¶ç°æœ‰çŸ¥è¯†å›ç­”æµ‹è¯•é—®é¢˜ï¼ˆè§ Â§[B](#A2 "é™„å½• B æµ‹è¯•æ€§èƒ½ä½œä¸ºè™šå‡ä¿¡æ¯çš„ä»£ç† â€£ å¾®è°ƒ LLM åœ¨æ–°çŸ¥è¯†ä¸Šçš„è¡¨ç°æ˜¯å¦ä¿ƒä½¿è™šå‡ä¿¡æ¯ï¼Ÿ")
    ä»¥è·å–è¿›ä¸€æ­¥è®¨è®ºï¼‰ã€‚
- en: 4.1 Higher $\mathtt{Unknown}$ Ratio is Proportional to Performance Degradation
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 è¾ƒé«˜çš„ $\mathtt{Unknown}$ æ¯”ä¾‹ä¸æ€§èƒ½ä¸‹é™æˆæ­£æ¯”
- en: '[FigureÂ 3(a)](#S3.F3.sf1 "In Figure 3 â€£ 3 Quantifying Knowledge in LLMs â€£ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") presents the performance
    as a function of the % of $\mathtt{Unknown}$, for different fine-tuning durations.
    Higher %$\mathtt{Unknown}$ examples are less useful than $\mathtt{Known}$. Interestingly,
    this effect increases with larger $\%$ (the inter-line spacing from early_stop
    exhibits a monotonic increase along the positive x-axis), suggesting that a higher
    %$\mathtt{Unknown}$ increases the risk of overfitting.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾ 3(a)](#S3.F3.sf1 "åœ¨å›¾ 3 â€£ 3 é‡åŒ– LLM ä¸­çš„çŸ¥è¯† â€£ å¾®è°ƒ LLM åœ¨æ–°çŸ¥è¯†ä¸Šçš„è¡¨ç°æ˜¯å¦ä¿ƒä½¿è™šå‡ä¿¡æ¯ï¼Ÿ") å±•ç¤ºäº†åœ¨ä¸åŒå¾®è°ƒæ—¶é•¿ä¸‹ï¼Œ$\mathtt{Unknown}$
    ç™¾åˆ†æ¯”çš„æ€§èƒ½ã€‚è¾ƒé«˜çš„ $\mathtt{Unknown}$ ç™¾åˆ†æ¯”ç¤ºä¾‹æ¯” $\mathtt{Known}$ ç¤ºä¾‹çš„æ•ˆæœå·®ã€‚æœ‰è¶£çš„æ˜¯ï¼Œè¿™ç§æ•ˆæœéšç€ $\%$
    çš„å¢åŠ è€Œå¢åŠ ï¼ˆearly_stop çš„è¡Œé—´è·æ²¿ç€æ­£ x è½´å•è°ƒå¢åŠ ï¼‰ï¼Œè¿™è¡¨æ˜è¾ƒé«˜çš„ $\%$ $\mathtt{Unknown}$ å¢åŠ äº†è¿‡æ‹Ÿåˆçš„é£é™©ã€‚'
- en: '4.2 $\mathtt{Unknown}$ Examples: Harmful or Neutral?'
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 $\mathtt{Unknown}$ ç¤ºä¾‹ï¼šæœ‰å®³è¿˜æ˜¯ä¸­æ€§ï¼Ÿ
- en: Since $|D|$ could stem from simply the lower number of the $\mathtt{Known}$
    examples are *harmful* or *neutral*. To address this, we measure the effect of
    filtering-out all the $\mathtt{Unknown}$. For each $D$, consisting only from the
    $\mathtt{Known}$. E.g., if $D$ $\mathtt{Unknown}$ $\mathtt{Known}$$D_{\mathtt{Known}}$.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº $|D|$ å¯èƒ½æºäº $\mathtt{Known}$ ç¤ºä¾‹æ•°é‡è¾ƒå°‘æ˜¯ *æœ‰å®³* æˆ– *ä¸­æ€§çš„*ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æµ‹é‡äº†è¿‡æ»¤æ‰æ‰€æœ‰ $\mathtt{Unknown}$
    çš„æ•ˆæœã€‚å¯¹äºæ¯ä¸ª $D$ï¼Œä»…ç”± $\mathtt{Known}$ ç»„æˆã€‚ä¾‹å¦‚ï¼Œå¦‚æœ $D$ æ˜¯ $\mathtt{Unknown}$ å’Œ $\mathtt{Known}$ï¼Œåˆ™
    $D_{\mathtt{Known}}$ã€‚
- en: '[FigureÂ 3(b)](#S3.F3.sf2 "In Figure 3 â€£ 3 Quantifying Knowledge in LLMs â€£ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") presents the results.
    Perhaps surprisingly, for early_stop the results for $D$, indicating that the
    $\mathtt{Unknown}$ examples are actually very *harmful*. In this case $D$, and
    the gap between them is proportional to the $\mathtt{Unknown}$ ratio.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾ 3(b)](#S3.F3.sf2 "åœ¨å›¾ 3 â€£ 3 é‡åŒ– LLM ä¸­çš„çŸ¥è¯† â€£ å¾®è°ƒ LLM åœ¨æ–°çŸ¥è¯†ä¸Šçš„è¡¨ç°æ˜¯å¦ä¿ƒä½¿è™šå‡ä¿¡æ¯ï¼Ÿ") å±•ç¤ºäº†ç»“æœã€‚ä¹Ÿè®¸ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå¯¹äº
    early_stopï¼Œ$D$ çš„ç»“æœè¡¨æ˜ $\mathtt{Unknown}$ ç¤ºä¾‹å®é™…ä¸Šæ˜¯éå¸¸ *æœ‰å®³* çš„ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ $D$ï¼Œå®ƒä»¬ä¹‹é—´çš„å·®è·ä¸ $\mathtt{Unknown}$
    æ¯”ä¾‹æˆæ­£æ¯”ã€‚'
- en: Interestingly, for $D_{\mathtt{Known}}$ (full lines). This indicates that the
    presence of $\mathtt{Unknown}$ ratios more prone to overfitting.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰è¶£çš„æ˜¯ï¼Œå¯¹äº $D_{\mathtt{Known}}$ï¼ˆå®Œæ•´çš„çº¿ï¼‰ã€‚è¿™è¡¨æ˜ $\mathtt{Unknown}$ æ¯”ä¾‹çš„å­˜åœ¨æ›´å®¹æ˜“å¯¼è‡´è¿‡æ‹Ÿåˆã€‚
- en: 4.3 $\mathtt{Unknown}$ Examples
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 $\mathtt{Unknown}$ ç¤ºä¾‹
- en: We showed that $\mathtt{Unknown}$ were fitted by $M$ and $\mathtt{Unknown}$
    as a function of the fine-tuning duration. The development accuracy is presented
    in a zoomed-in plot at the bottom, as it falls within a narrower range. We include
    a breakdown of the train accuracy per $\mathtt{Known}$ category in Â§[F](#A6 "Appendix
    F Train Accuracy on Different ğ™ºğš—ğš˜ğš ğš— Categories â€£ Does Fine-Tuning LLMs on New
    Knowledge Encourage Hallucinations?").
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å±•ç¤ºäº† $\mathtt{Unknown}$ å¦‚ä½•è¢« $M$ é€‚é…ï¼Œä»¥åŠ $\mathtt{Unknown}$ éšå¾®è°ƒæ—¶é—´çš„å˜åŒ–ã€‚å‘å±•å‡†ç¡®æ€§åœ¨åº•éƒ¨çš„ç¼©æ”¾å›¾ä¸­å±•ç¤ºï¼Œå› ä¸ºå®ƒè½åœ¨ä¸€ä¸ªæ›´çª„çš„èŒƒå›´å†…ã€‚æˆ‘ä»¬åœ¨
    Â§[F](#A6 "é™„å½• F åœ¨ä¸åŒ ğ™ºğš—ğš˜ğš ğš— ç±»åˆ«ä¸Šçš„è®­ç»ƒå‡†ç¡®æ€§ â€£ å¾®è°ƒ LLM åœ¨æ–°çŸ¥è¯†ä¸Šçš„è¡¨ç°æ˜¯å¦ä¼šå¼•å‘å¹»æƒ³ï¼Ÿ") ä¸­åŒ…å«äº†æ¯ä¸ª $\mathtt{Known}$
    ç±»åˆ«çš„è®­ç»ƒå‡†ç¡®æ€§åˆ†è§£ã€‚
- en: '![Refer to caption](img/3f66df0e142a9a0850f73422f885e127.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§æ ‡é¢˜](img/3f66df0e142a9a0850f73422f885e127.png)'
- en: 'Figure 4: The state of the examples in the fine-tuning dataset $D$ (y-axis),
    we illustrate which portion of the examples in $D$).'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 4ï¼šåœ¨å¾®è°ƒæ•°æ®é›† $D$ ä¸­çš„ç¤ºä¾‹çŠ¶æ€ï¼ˆyè½´ï¼‰ï¼Œæˆ‘ä»¬å±•ç¤ºäº† $D$ ä¸­çš„ç¤ºä¾‹çš„éƒ¨åˆ†ã€‚
- en: '$M$ fine-tuning examples substantially slower than $\mathtt{Known}$ reaches
    peak performance on the development set, while fitting the majority of the $\mathtt{Known}$.
    In [FigureÂ 4](#S4.F4 "In 4.3 ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples are Fitted Slower than ğ™ºğš—ğš˜ğš ğš— Examples
    â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?"), we show that this behavior is consistent across all
    our variants of $D$ examples had a *neutral* effect on performance (Â§[4.2](#S4.SS2
    "4.2 ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples: Harmful or Neutral? â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples?
    â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")), as at this
    point $M$ examples are the ones that are likely to introduce new factual knowledge,
    their significantly slow fitting rate suggests that LLMs struggle to acquire new
    factual knowledge through fine-tuning, instead they learn to expose their pre-existing
    knowledge using the $\mathtt{Known}$ examples.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: $M$ å¾®è°ƒç¤ºä¾‹æ˜¾è‘—æ¯” $\mathtt{Known}$ æ›´æ…¢è¾¾åˆ°å¼€å‘é›†çš„å³°å€¼æ€§èƒ½ï¼ŒåŒæ—¶é€‚é…äº†å¤§éƒ¨åˆ† $\mathtt{Known}$ã€‚åœ¨ [å›¾ 4](#S4.F4
    "åœ¨ 4.3 $\mathtt{Unknown}$ ç¤ºä¾‹æ¯” $\mathtt{Known}$ ç¤ºä¾‹æ›´æ…¢ â€£ 4 $\mathtt{Unknown}$ ç¤ºä¾‹æœ‰å¤šæœ‰å®³ï¼Ÿ
    â€£ å¾®è°ƒ LLM åœ¨æ–°çŸ¥è¯†ä¸Šçš„è¡¨ç°æ˜¯å¦ä¼šå¼•å‘å¹»æƒ³ï¼Ÿ") ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¿™ä¸€è¡Œä¸ºåœ¨æ‰€æœ‰ $D$ ç¤ºä¾‹çš„å˜ä½“ä¸­æ˜¯ä¸€è‡´çš„ï¼Œå¯¹æ€§èƒ½æœ‰ *ä¸­ç«‹* å½±å“ (Â§[4.2](#S4.SS2
    "4.2 $\mathtt{Unknown}$ ç¤ºä¾‹ï¼šæœ‰å®³è¿˜æ˜¯ä¸­ç«‹ï¼Ÿ â€£ 4 $\mathtt{Unknown}$ ç¤ºä¾‹æœ‰å¤šæœ‰å®³ï¼Ÿ â€£ å¾®è°ƒ LLM åœ¨æ–°çŸ¥è¯†ä¸Šçš„è¡¨ç°æ˜¯å¦ä¼šå¼•å‘å¹»æƒ³ï¼Ÿ"))ï¼Œå› ä¸ºæ­¤æ—¶
    $M$ ç¤ºä¾‹å¾ˆå¯èƒ½å¼•å…¥æ–°çš„äº‹å®çŸ¥è¯†ï¼Œå…¶æ˜¾è‘—ç¼“æ…¢çš„é€‚é…é€Ÿç‡è¡¨æ˜ LLM åœ¨å¾®è°ƒä¸­éš¾ä»¥è·å–æ–°çš„äº‹å®çŸ¥è¯†ï¼Œè€Œæ˜¯é€šè¿‡ $\mathtt{Known}$ ç¤ºä¾‹æš´éœ²å…¶é¢„å…ˆå­˜åœ¨çš„çŸ¥è¯†ã€‚
- en: '4.4 The Influence of $\mathtt{Unknown}$ on Accuracy: A Linear Model Perspective'
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 $\mathtt{Unknown}$ å¯¹å‡†ç¡®æ€§çš„å½±å“ï¼šçº¿æ€§æ¨¡å‹è§†è§’
- en: '|  | $\beta_{0}$ | $\beta_{\text{unk}}$ |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|  | $\beta_{0}$ | $\beta_{\text{unk}}$ |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| In-distribution (Â§[4.4](#S4.SS4 "4.4 The Influence of ğš„ğš—ğš”ğš—ğš˜ğš ğš— vs ğ™ºğš—ğš˜ğš ğš— on
    Accuracy: A Linear Model Perspective â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")) | $36.9$ | $-8.3$
    |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| åˆ†å¸ƒå†… (Â§[4.4](#S4.SS4 "4.4 $\mathtt{Unknown}$ ä¸ $\mathtt{Known}$ å¯¹å‡†ç¡®æ€§çš„å½±å“ï¼šçº¿æ€§æ¨¡å‹è§†è§’
    â€£ 4 $\mathtt{Unknown}$ ç¤ºä¾‹æœ‰å¤šæœ‰å®³ï¼Ÿ â€£ å¾®è°ƒ LLM åœ¨æ–°çŸ¥è¯†ä¸Šçš„è¡¨ç°æ˜¯å¦ä¼šå¼•å‘å¹»æƒ³ï¼Ÿ")) | $36.9$ | $-8.3$
    |'
- en: '| Out-of-distribution (Â§[4.5](#S4.SS5 "4.5 Generalization to New Relations
    â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?")) | $36.2$ | $-3.0$ |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| åˆ†å¸ƒå¤– (Â§[4.5](#S4.SS5 "4.5 æ³›åŒ–åˆ°æ–°å…³ç³» â€£ 4 $\mathtt{Unknown}$ ç¤ºä¾‹æœ‰å¤šæœ‰å®³ï¼Ÿ â€£ å¾®è°ƒ LLM åœ¨æ–°çŸ¥è¯†ä¸Šçš„è¡¨ç°æ˜¯å¦ä¼šå¼•å‘å¹»æƒ³ï¼Ÿ"))
    | $36.2$ | $-3.0$ |'
- en: 'Table 1: Results of our linear model for predicting the test accuracy as defined
    by [EquationÂ 1](#S4.E1 "In 4.4 The Influence of ğš„ğš—ğš”ğš—ğš˜ğš ğš— vs ğ™ºğš—ğš˜ğš ğš— on Accuracy:
    A Linear Model Perspective â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?").'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ 1ï¼šæˆ‘ä»¬çº¿æ€§æ¨¡å‹é¢„æµ‹æµ‹è¯•å‡†ç¡®æ€§çš„ç»“æœï¼Œå¦‚ [å…¬å¼ 1](#S4.E1 "åœ¨ 4.4 $\mathtt{Unknown}$ ä¸ $\mathtt{Known}$
    å¯¹å‡†ç¡®æ€§çš„å½±å“ï¼šçº¿æ€§æ¨¡å‹è§†è§’ â€£ 4 $\mathtt{Unknown}$ ç¤ºä¾‹æœ‰å¤šæœ‰å®³ï¼Ÿ â€£ å¾®è°ƒ LLM åœ¨æ–°çŸ¥è¯†ä¸Šçš„è¡¨ç°æ˜¯å¦ä¼šå¼•å‘å¹»æƒ³ï¼Ÿ") æ‰€å®šä¹‰ã€‚
- en: '|  | early_stop |  | Convergence |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '|  | æå‰åœæ­¢ |  | æ”¶æ•› |'
- en: '| --- | --- | --- | --- |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  | $\mathtt{Full}$ | $\mathtt{Mkn}$ | $\mathtt{Unk}$ |  | $\mathtt{Hkn}$
    | $\mathtt{Wkn}$ |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathtt{Full}$ | $\mathtt{Mkn}$ | $\mathtt{Unk}$ |  | $\mathtt{Hkn}$
    | $\mathtt{Wkn}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- |'
- en: '| $D_{\mathtt{HighlyKnown}}$ | 40.5 |  | 98.7 | 60.1 | 9.0 | 0.6 |  | 40.0
    |  | 98.4 | 58.8 | 8.5 | 0.7 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{HighlyKnown}}$ | 40.5 |  | 98.7 | 60.1 | 9.0 | 0.6 |  | 40.0
    |  | 98.4 | 58.8 | 8.5 | 0.7 |'
- en: '| $D_{\mathtt{MaybeKnown}}$ | 43.6 |  | 98.4 | 69.9 | 12.1 | 1.0 |  | 43.2
    |  | 97.5 | 68.2 | 12.9 | 1.3 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{MaybeKnown}}$ | 43.6 |  | 98.4 | 69.9 | 12.1 | 1.0 |  | 43.2
    |  | 97.5 | 68.2 | 12.9 | 1.3 |'
- en: '| $D_{\mathtt{WeaklyKnown}}$ | 39.2 |  | 95.0 | 59.2 | 8.6 | 0.4 |  | 35.4
    |  | 73.5 | 55.8 | 17.2 | 2.2 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{WeaklyKnown}}$ | 39.2 |  | 95.0 | 59.2 | 8.6 | 0.4 |  | 35.4
    |  | 73.5 | 55.8 | 17.2 | 2.2 |'
- en: '| $D_{\mathtt{Unknown}}$ | 37.5 |  | 95.6 | 52.9 | 6.5 | 0.6 |  | 25.8 |  |
    55.8 | 36.6 | 12.2 | 3.2 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{Unknown}}$ | 37.5 |  | 95.6 | 52.9 | 6.5 | 0.6 |  | 25.8 |  |
    55.8 | 36.6 | 12.2 | 3.2 |'
- en: '| $D_{\mathtt{Natural}}$ | 43.5 |  | 98.0 | 67.6 | 14.1 | 1.8 |  | 41.8 |  |
    95.5 | 61.7 | 14.8 | 2.5 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{Natural}}$ | 43.5 |  | 98.0 | 67.6 | 14.1 | 1.8 |  | 41.8 |  |
    95.5 | 61.7 | 14.8 | 2.5 |'
- en: 'Table 2: Accuracies for the single-category variants from Â§[5](#S5 "5 Understanding
    Knowledge Types: Their Value and Impact â€£ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?"), across per-category subsets of the test set. $\mathtt{Full}$=$\mathtt{HighlyKnown}$=$\mathtt{MaybeKnown}$=$\mathtt{WeaklyKnown}$=$\mathtt{Unknown}$
    (significance test details are in Â§[I](#A9 "Appendix I Statistic Significance
    Tests â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")).'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ 2ï¼šæ¥è‡ª Â§[5](#S5 "5 ç†è§£çŸ¥è¯†ç±»å‹ï¼šå®ƒä»¬çš„ä»·å€¼å’Œå½±å“ â€£ å¾®è°ƒ LLMs äºæ–°çŸ¥è¯†æ˜¯å¦ä¿ƒè¿›å¹»è§‰ï¼Ÿ") çš„å•ç±»åˆ«å˜ä½“çš„å‡†ç¡®ç‡ï¼Œè·¨æ¯ä¸ªç±»åˆ«çš„æµ‹è¯•é›†å­é›†ã€‚$\mathtt{Full}$=$\mathtt{HighlyKnown}$=$\mathtt{MaybeKnown}$=$\mathtt{WeaklyKnown}$=$\mathtt{Unknown}$ï¼ˆæ˜¾è‘—æ€§æµ‹è¯•çš„è¯¦ç»†ä¿¡æ¯è§
    Â§[I](#A9 "é™„å½• I ç»Ÿè®¡æ˜¾è‘—æ€§æµ‹è¯• â€£ å¾®è°ƒ LLMs äºæ–°çŸ¥è¯†æ˜¯å¦ä¿ƒè¿›å¹»è§‰ï¼Ÿ")ï¼‰ã€‚
- en: '[FigureÂ 1](#S1.F1 "In 1 Introduction â€£ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?") demonstrates that after the development performance
    peaks at early_stop (vertical dotted line), it deteriorates as $M$ examples. In
    this section, we aim to characterize this relationship more accurately by assessing
    whether a simple linear dependency can tie the impact of fitting $\mathtt{Known}$
    training examples on test accuracy. To this end we use the following linear regression
    model:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾ 1](#S1.F1 "åœ¨ 1 ä»‹ç» â€£ å¾®è°ƒ LLMs äºæ–°çŸ¥è¯†æ˜¯å¦ä¿ƒè¿›å¹»è§‰ï¼Ÿ") è¯´æ˜äº†åœ¨å¼€å‘æ€§èƒ½åœ¨ early_stopï¼ˆå‚ç›´è™šçº¿ï¼‰å¤„è¾¾åˆ°å³°å€¼åï¼Œéšç€
    $M$ ç¤ºä¾‹çš„å¢åŠ ï¼Œæ€§èƒ½å¼€å§‹ä¸‹é™ã€‚åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬æ—¨åœ¨é€šè¿‡è¯„ä¼°ç®€å•çš„çº¿æ€§ä¾èµ–æ˜¯å¦èƒ½å¤Ÿå°†æ‹Ÿåˆ $\mathtt{Known}$ è®­ç»ƒç¤ºä¾‹å¯¹æµ‹è¯•å‡†ç¡®æ€§çš„å½±å“è¿›è¡Œæ›´å‡†ç¡®çš„æè¿°ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä»¥ä¸‹çº¿æ€§å›å½’æ¨¡å‹ï¼š'
- en: '|  | $Accuracy$ |  | (1) |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '|  | $Accuracy$ |  | (1) |'
- en: where $N_{\text{Kn}}$ are the number of the $\mathtt{Known}$ examples in $D$
    fits.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ $N_{\text{Kn}}$ æ˜¯ $D$ ä¸­çš„ $\mathtt{Known}$ ç¤ºä¾‹çš„æ•°é‡ã€‚
- en: 'We estimate the coefficientsâ¶â¶6Full details in Â§[G](#A7 "Appendix G Linear
    Model â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"). We
    note that this linear model is only valid in bounded region of $N_{\text{kn}}\leq|D|$.
    by collecting ($Accuracy$, $N_{\text{Unk}}$ variants. [TableÂ 1](#S2.T1 "In 4.4
    The Influence of ğš„ğš—ğš”ğš—ğš˜ğš ğš— vs ğ™ºğš—ğš˜ğš ğš— on Accuracy: A Linear Model Perspective â€£ 4
    How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?") presents the results (top row). The high $R^{2}$ examples hurts
    performance ($\beta_{unk}
    roughly matches the positive impact from <math id=$).'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¼°è®¡äº†ç³»æ•°â¶â¶6è¯¦ç»†ä¿¡æ¯è§ Â§[G](#A7 "é™„å½• G çº¿æ€§æ¨¡å‹ â€£ å¾®è°ƒ LLMs äºæ–°çŸ¥è¯†æ˜¯å¦ä¿ƒè¿›å¹»è§‰ï¼Ÿ")ã€‚æˆ‘ä»¬æ³¨æ„åˆ°ï¼Œè¯¥çº¿æ€§æ¨¡å‹ä»…åœ¨ $N_{\text{kn}}\leq|D|$
    çš„æœ‰ç•ŒåŒºåŸŸå†…æœ‰æ•ˆã€‚é€šè¿‡æ”¶é›†ï¼ˆ$Accuracy$ï¼Œ$N_{\text{Unk}}$ å˜ä½“ï¼‰ã€‚[è¡¨ 1](#S2.T1 "åœ¨ 4.4 ğš„ğš—ğš”ğš—ğš˜ğš ğš— ä¸ ğ™ºğš—ğš˜ğš ğš—
    å¯¹å‡†ç¡®æ€§çš„å½±å“ï¼šä¸€ç§çº¿æ€§æ¨¡å‹è§†è§’ â€£ 4 ğš„ğš—ğš”ğš—ğš˜ğšğš ğšğš”ğš˜ğš˜ğš˜ğš˜ğš›") æ˜¾ç¤ºäº†ç»“æœï¼ˆé¡¶è¡Œï¼‰ã€‚é«˜ $R^{2}$ ç¤ºä¾‹ä¼šå½±å“æ€§èƒ½ï¼ˆ$\beta_{unk}\math> å¤§è‡´åŒ¹é…äº†æ­£é¢å½±å“ã€‚
- en: 4.5 Generalization to New Relations
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 å¯¹æ–°å…³ç³»çš„æ³›åŒ–
- en: In the above setup, the $(q,a)$. We now investigate whether our observed dynamics
    has a broader effect on the modelâ€™s knowledge, and transfers to relations not
    represented in $D$. To test this, we reserve a subset of the relations for an
    *out-of-distribution* (OOD) test set, excluding them from the train and development
    splits. See Â§[A](#A1 "Appendix A Data Preprocessing â€£ Does Fine-Tuning LLMs on
    New Knowledge Encourage Hallucinations?") for details and Tables [4](#A1.T4 "Table
    4 â€£ Appendix A Data Preprocessing â€£ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?") and [5](#A1.T5 "Table 5 â€£ Appendix A Data Preprocessing â€£ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") for in-distribution
    vs OOD relations.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šè¿°è®¾ç½®ä¸­ï¼Œ$(q,a)$ã€‚æˆ‘ä»¬ç°åœ¨è°ƒæŸ¥æˆ‘ä»¬è§‚å¯Ÿåˆ°çš„åŠ¨æ€æ˜¯å¦å¯¹æ¨¡å‹çš„çŸ¥è¯†æœ‰æ›´å¹¿æ³›çš„å½±å“ï¼Œå¹¶ä¸”æ˜¯å¦è½¬ç§»åˆ° $D$ ä¸­æœªè¡¨ç¤ºçš„å…³ç³»ä¸Šã€‚ä¸ºæµ‹è¯•è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬ä¿ç•™äº†éƒ¨åˆ†å…³ç³»ç”¨äº
    *åˆ†å¸ƒå¤–*ï¼ˆOODï¼‰æµ‹è¯•é›†ï¼Œå°†å®ƒä»¬ä»è®­ç»ƒå’Œå¼€å‘åˆ†å‰²ä¸­æ’é™¤ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§ Â§[A](#A1 "é™„å½• A æ•°æ®é¢„å¤„ç† â€£ å¾®è°ƒ LLMs äºæ–°çŸ¥è¯†æ˜¯å¦ä¿ƒè¿›å¹»è§‰ï¼Ÿ")
    ä»¥åŠè¡¨ [4](#A1.T4 "è¡¨ 4 â€£ é™„å½• A æ•°æ®é¢„å¤„ç† â€£ å¾®è°ƒ LLMs äºæ–°çŸ¥è¯†æ˜¯å¦ä¿ƒè¿›å¹»è§‰ï¼Ÿ") å’Œ [5](#A1.T5 "è¡¨ 5 â€£ é™„å½•
    A æ•°æ®é¢„å¤„ç† â€£ å¾®è°ƒ LLMs äºæ–°çŸ¥è¯†æ˜¯å¦ä¿ƒè¿›å¹»è§‰ï¼Ÿ") å¯¹æ¯”åˆ†å¸ƒå†…ä¸ OOD å…³ç³»ã€‚
- en: 'Our results on the OOD test set reveal similar key insights: (1) Higher $\mathtt{Unknown}$
    examples are harmful for OOD performance, but mostly when $M$, $\beta_{\text{kn}}>
    and <math id=$ (see [TableÂ 1](#S2.T1 "In 4.4 The Influence of ğš„ğš—ğš”ğš—ğš˜ğš ğš— vs ğ™ºğš—ğš˜ğš ğš—
    on Accuracy: A Linear Model Perspective â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples?
    â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")). More details
    are in Â§[H](#A8 "Appendix H Out-of-distribution (OOD) Evaluation â€£ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?").'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨OODæµ‹è¯•é›†ä¸Šçš„ç»“æœæ­ç¤ºäº†ç±»ä¼¼çš„å…³é”®è§è§£ï¼šï¼ˆ1ï¼‰æ›´é«˜çš„$\mathtt{æœªçŸ¥}$ç¤ºä¾‹å¯¹OODæ€§èƒ½æœ‰å®³ï¼Œä½†ä¸»è¦æ˜¯åœ¨$M$ï¼Œ$\beta_{\text{kn}}>
    å’Œ <math id=$ï¼ˆè§ [è¡¨1](#S2.T1 "åœ¨ 4.4 ğš„ğš—ğš”ğš—ğš˜ğš ğš— ä¸ ğ™ºğš—ğš˜ğš ğšŸğš— å¯¹å‡†ç¡®æ€§çš„å½±å“ï¼šçº¿æ€§æ¨¡å‹è§†è§’ â€£ 4 ğš„ğš—ğš”ğš—ğš˜ğšğšœ
    ç¤ºä¾‹çš„å±å®³æœ‰å¤šå¤§ï¼Ÿ â€£ å¾®è°ƒLLMsæ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±å¹»æƒ³ï¼Ÿ")ï¼‰ã€‚æ›´å¤šç»†èŠ‚è§ Â§[H](#A8 "é™„å½•H åˆ†å¸ƒå¤–ï¼ˆOODï¼‰è¯„ä¼° â€£ å¾®è°ƒLLMsæ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±å¹»æƒ³ï¼Ÿ")ã€‚
- en: Overall, *our insights transfer across relations*. This essentially shows that
    fine-tuning on $\mathtt{Unknown}$ examples such as *"Where is [E1] located?"*,
    can encourage hallucinations on seemingly unrelated questions, such as *"Who founded
    [E2]?"*. This further supports the conclusion that the observed effects likely
    stem from the model learning the *behavior* of generating answers that are not
    grounded in its pre-existing knowledge.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ä½“è€Œè¨€ï¼Œ*æˆ‘ä»¬çš„è§è§£è·¨å…³ç³»è½¬ç§»*ã€‚è¿™æœ¬è´¨ä¸Šè¡¨æ˜ï¼Œå¾®è°ƒ$\mathtt{æœªçŸ¥}$ç¤ºä¾‹ï¼Œå¦‚*â€œ[E1] ä½äºå“ªé‡Œï¼Ÿâ€*ï¼Œå¯ä»¥é¼“åŠ±åœ¨çœ‹ä¼¼æ— å…³çš„é—®é¢˜ä¸Šå‡ºç°å¹»æƒ³ï¼Œä¾‹å¦‚*â€œè°åˆ›ç«‹äº†
    [E2]ï¼Ÿâ€*ã€‚è¿™è¿›ä¸€æ­¥æ”¯æŒäº†è¿™æ ·ä¸€ä¸ªç»“è®ºï¼šè§‚å¯Ÿåˆ°çš„æ•ˆåº”å¯èƒ½æºäºæ¨¡å‹å­¦ä¹ åˆ°çš„*è¡Œä¸º*ï¼Œå³ç”Ÿæˆé‚£äº›ä¸åŸºäºå…¶å·²æœ‰çŸ¥è¯†çš„ç­”æ¡ˆã€‚
- en: '5 Understanding Knowledge Types: Their Value and Impact'
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 ç†è§£çŸ¥è¯†ç±»å‹ï¼šå®ƒä»¬çš„ä»·å€¼å’Œå½±å“
- en: 'When addressing our main research question on the effect of $\mathtt{Unknown}$
    categories collectively for simplicity (see [TableÂ 1(a)](#S2.T1.st1 "In Figure
    2 â€£ 2 Study Setup â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")).
    We now examine the effect of each category, exploring the following questions:
    Q1: How *training examples* from each category impact the test performance? Q2:
    What is the modelâ€™s performance across *test examples* from each category? To
    address Q1 we created single-category variants of the fine-tuning dataset $D$
    consisting solely of examples from the category $\mathtt{CAT}$. For reference,
    we include a variant with the *natural* categories distribution in EntityQuestions,
    denoted $D_{\mathtt{Natural}}$ is fixed and identical to our experiments in Â§[4](#S4
    "4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?"). To address Q2, we further break down the test set
    performance by category. [TableÂ 2](#S4.T2 "In 4.4 The Influence of ğš„ğš—ğš”ğš—ğš˜ğš ğš— vs
    ğ™ºğš—ğš˜ğš ğš— on Accuracy: A Linear Model Perspective â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples?
    â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") presents
    the results.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¤„ç†æˆ‘ä»¬ä¸»è¦ç ”ç©¶é—®é¢˜æ—¶ï¼Œä¸ºäº†ç®€åŒ–$\mathtt{æœªçŸ¥}$ç±»åˆ«çš„æ•´ä½“æ•ˆæœï¼ˆè§ [è¡¨1(a)](#S2.T1.st1 "åœ¨å›¾2 â€£ 2 ç ”ç©¶è®¾ç½® â€£ å¾®è°ƒLLMsæ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±å¹»æƒ³ï¼Ÿ")ï¼‰ã€‚æˆ‘ä»¬ç°åœ¨æ£€æŸ¥æ¯ä¸ªç±»åˆ«çš„æ•ˆæœï¼Œæ¢è®¨ä»¥ä¸‹é—®é¢˜ï¼šQ1ï¼šæ¯ä¸ªç±»åˆ«çš„*è®­ç»ƒç¤ºä¾‹*å¦‚ä½•å½±å“æµ‹è¯•æ€§èƒ½ï¼ŸQ2ï¼šæ¨¡å‹åœ¨æ¯ä¸ªç±»åˆ«çš„*æµ‹è¯•ç¤ºä¾‹*ä¸Šçš„è¡¨ç°å¦‚ä½•ï¼Ÿä¸ºäº†å›ç­”Q1ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä»…åŒ…å«ç±»åˆ«$\mathtt{CAT}$ç¤ºä¾‹çš„å•ç±»åˆ«å¾®è°ƒæ•°æ®é›†$D$çš„å˜ä½“ã€‚ä¸ºäº†å‚è€ƒï¼Œæˆ‘ä»¬åŒ…æ‹¬äº†ä¸€ä¸ªå…·æœ‰*è‡ªç„¶*ç±»åˆ«åˆ†å¸ƒçš„å˜ä½“ï¼Œè®°ä¸º$D_{\mathtt{è‡ªç„¶}}$ï¼Œå®ƒå›ºå®šä¸”ä¸æˆ‘ä»¬åœ¨
    Â§[4](#S4 "4 ğš„ğš—ğš”ğš—ğš˜ğš ğšŸğš— ç¤ºä¾‹çš„å±å®³æœ‰å¤šå¤§ï¼Ÿ â€£ å¾®è°ƒLLMsæ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±å¹»æƒ³ï¼Ÿ") ä¸­çš„å®éªŒç›¸åŒã€‚ä¸ºäº†å›ç­”Q2ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æŒ‰ç±»åˆ«æ‹†è§£æµ‹è¯•é›†è¡¨ç°ã€‚[è¡¨2](#S4.T2
    "åœ¨ 4.4 ğš„ğš—ğš”ğš—ğš˜ğš£ ğ™ºğš—ğš˜ğš ğšŸğš— å¯¹å‡†ç¡®æ€§çš„å½±å“ï¼šçº¿æ€§æ¨¡å‹è§†è§’ â€£ 4 ğš„ğš—ğš”ğš—ğš˜ğš§ ç¤ºä¾‹çš„å±å®³æœ‰å¤šå¤§ï¼Ÿ â€£ å¾®è°ƒLLMsæ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±å¹»æƒ³ï¼Ÿ")
    å±•ç¤ºäº†ç»“æœã€‚
- en: MaybeKnown Examples are Essential.
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ä¹Ÿè®¸**å·²çŸ¥**ç¤ºä¾‹æ˜¯è‡³å…³é‡è¦çš„ã€‚
- en: Since $\mathtt{Unknown}$ examples. Surprisingly, $D_{\mathtt{HighlyKnown}}$
    test examples, yet its performance on the remaining categories is inferior. $D_{\mathtt{MaybeKnown}}$,
    $D_{\mathtt{MaybeKnown}}$â€™s performance on $\mathtt{MaybeKnown}$), without compromising
    performance on $\mathtt{HighlyKnown}$). This suggests that $\mathtt{MaybeKnown}$
    to correctly handle such examples during inference. It also demonstrates that
    with the right fine-tuning examples, $M_{D}$ becomes more capable of utilizing
    its pre-existing knowledge.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº$\mathtt{æœªçŸ¥}$ç¤ºä¾‹ã€‚å‡ºä¹æ„æ–™çš„æ˜¯ï¼Œ$D_{\mathtt{é«˜åº¦å·²çŸ¥}}$æµ‹è¯•ç¤ºä¾‹ï¼Œç„¶è€Œå®ƒåœ¨å‰©ä½™ç±»åˆ«ä¸Šçš„è¡¨ç°è¾ƒå·®ã€‚$D_{\mathtt{ä¹Ÿè®¸å·²çŸ¥}}$ï¼Œ$D_{\mathtt{ä¹Ÿè®¸å·²çŸ¥}}$åœ¨$\mathtt{ä¹Ÿè®¸å·²çŸ¥}$ä¸Šçš„è¡¨ç°ï¼‰ï¼Œè€Œä¸ä¼šå½±å“$\mathtt{é«˜åº¦å·²çŸ¥}$ä¸Šçš„è¡¨ç°ã€‚è¿™è¡¨æ˜$\mathtt{ä¹Ÿè®¸å·²çŸ¥}$åœ¨æ¨æ–­è¿‡ç¨‹ä¸­æ­£ç¡®å¤„ç†è¿™äº›ç¤ºä¾‹çš„èƒ½åŠ›ã€‚å®ƒè¿˜è¡¨æ˜ï¼Œé€šè¿‡é€‚å½“çš„å¾®è°ƒç¤ºä¾‹ï¼Œ$M_{D}$å˜å¾—æ›´æœ‰èƒ½åŠ›åˆ©ç”¨å…¶å·²æœ‰çš„çŸ¥è¯†ã€‚
- en: Limited Knowledge Enhances Overfitting.
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æœ‰é™çŸ¥è¯†å¢å¼ºè¿‡æ‹Ÿåˆã€‚
- en: 'In Â§[4.2](#S4.SS2 "4.2 ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples: Harmful or Neutral? â€£ 4 How Harmful
    are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"),
    we demonstrated that $\mathtt{Unknown}$, though to a lesser degree. Specifically,
    at Convergence, $D_{\mathtt{WeaklyKnown}}$ experience significant performance
    drops compared to early_stop ($39.2{\mkern-3.0mu}\rightarrow{\mkern-3.0mu}35.4$).
    With training to Convergence, they show a modest improvement on $\mathtt{WeaklyKnown}$
    but substantially degrade on $\mathtt{HighlyKnown}$. This highlights that the
    decrease in performance is strongly attributed to an increased rate of hallucinations
    w.r.t. facts that were already known to $M$ after pre-training.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 'åœ¨Â§[4.2](#S4.SS2 "4.2 ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples: Harmful or Neutral? â€£ 4 How Harmful
    are ğš„ğš—ğš”ğšğšœğšœğšŠğš›ğš Examples? â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†$\mathtt{Unknown}$ï¼Œå°½ç®¡ç¨‹åº¦è¾ƒè½»ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨æ”¶æ•›æ—¶ï¼Œ$D_{\mathtt{WeaklyKnown}}$çš„è¡¨ç°ç›¸æ¯”äºæ—©æœŸåœæ­¢æœ‰æ˜¾è‘—ä¸‹é™ï¼ˆ$39.2{\mkern-3.0mu}\rightarrow{\mkern-3.0mu}35.4$ï¼‰ã€‚åœ¨è®­ç»ƒåˆ°æ”¶æ•›æ—¶ï¼Œå®ƒä»¬åœ¨$\mathtt{WeaklyKnown}$ä¸Šè¡¨ç°æœ‰æ‰€æ”¹å–„ï¼Œä½†åœ¨$\mathtt{HighlyKnown}$ä¸Šå¤§å¹…ä¸‹é™ã€‚è¿™çªæ˜¾äº†æ€§èƒ½ä¸‹é™å¾ˆå¤§ç¨‹åº¦ä¸Šå½’å› äºç›¸å¯¹äºé¢„è®­ç»ƒå$M$å·²ç»çŸ¥é“çš„äº‹å®çš„è™šå‡è®°å¿†ç‡å¢åŠ ã€‚'
- en: Interestingly, $D_{\mathtt{Natural}}$ in early_stop, suggesting that the mere
    presence of $\mathtt{MaybeKnown}$ suffices for high performance on $\mathtt{MaybeKnown}$
    has additional examples from other categories. Yet, $D_{\mathtt{Natural}}$â€“ indicating
    that it still suffers from overfitting, most-likely due to the presence of $\mathtt{WeaklyKnown}$
    examples. Taken together these results demonstrate that $D_{\mathtt{MaybeKnown}}$
    stands out both in terms of top performance and reduced risk to overfitting.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰è¶£çš„æ˜¯ï¼Œæ—©æœŸåœæ­¢ä¸­çš„$D_{\mathtt{Natural}}$ï¼Œè¡¨æ˜ä»…æœ‰$\mathtt{MaybeKnown}$çš„å­˜åœ¨å¯¹äº$\mathtt{MaybeKnown}$çš„é«˜æ€§èƒ½å·²ç»è¶³å¤Ÿï¼Œä¸”æœ‰æ¥è‡ªå…¶ä»–ç±»åˆ«çš„é¢å¤–ç¤ºä¾‹ã€‚ç„¶è€Œï¼Œ$D_{\mathtt{Natural}}$â€“
    è¡¨ç¤ºå®ƒä»ç„¶å—åˆ°è¿‡æ‹Ÿåˆçš„å½±å“ï¼Œæœ€å¯èƒ½æ˜¯ç”±äº$\mathtt{WeaklyKnown}$ç¤ºä¾‹çš„å­˜åœ¨ã€‚ç»¼åˆæ¥çœ‹ï¼Œè¿™äº›ç»“æœè¡¨æ˜$D_{\mathtt{MaybeKnown}}$åœ¨é¡¶çº§æ€§èƒ½å’Œé™ä½è¿‡æ‹Ÿåˆé£é™©æ–¹é¢éƒ½è¡¨ç°çªå‡ºã€‚
- en: 6 SliCK Knowledge Categories Analysis
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 SliCKçŸ¥è¯†ç±»åˆ«åˆ†æ
- en: 'Assessing a modelâ€™s knowledge remains an open problem, particularly since evaluating
    the quality of such methods is challenging due to the lack of ground truth about
    what the model truly knows. In this work we proposed SliCK (Â§[3](#S3 "3 Quantifying
    Knowledge in LLMs â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")):
    a four-category classification of facts w.r.t. the modelâ€™s knowledge. We now further
    analyze and discuss our design choices, hoping that SliCK can serve as a useful
    taxonomy to guide future research on this subject.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: è¯„ä¼°æ¨¡å‹çŸ¥è¯†ä»ç„¶æ˜¯ä¸€ä¸ªå¼€æ”¾é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯ç”±äºç¼ºä¹å…³äºæ¨¡å‹çœŸæ­£çŸ¥é“çš„å†…å®¹çš„çœŸå®æ•°æ®ï¼Œè¯„ä¼°è¿™äº›æ–¹æ³•çš„è´¨é‡å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†SliCKï¼ˆÂ§[3](#S3
    "3 Quantifying Knowledge in LLMs â€£ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?")ï¼‰ï¼šä¸€ä¸ªå…³äºæ¨¡å‹çŸ¥è¯†çš„å››ç±»äº‹å®åˆ†ç±»æ–¹æ³•ã€‚æˆ‘ä»¬ç°åœ¨è¿›ä¸€æ­¥åˆ†æå’Œè®¨è®ºäº†æˆ‘ä»¬çš„è®¾è®¡é€‰æ‹©ï¼Œå¸Œæœ›SliCKå¯ä»¥ä½œä¸ºæœ‰ç”¨çš„åˆ†ç±»æ³•ï¼Œä»¥æŒ‡å¯¼æœªæ¥åœ¨è¿™ä¸€ä¸»é¢˜ä¸Šçš„ç ”ç©¶ã€‚
- en: Fine-grained Known Categories
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç»†ç²’åº¦å·²çŸ¥ç±»åˆ«
- en: 'We first reflect on whether our choice of splitting $\mathtt{Known}$ indeed
    captures facts with high degree of knowledge, as it consistently exceeds $95\%$
    and $\mathtt{WeaklyKnown}$ is worse that on $\mathtt{MaybeKnown}$. Additionally,
    the *exact* categories distinction we made was proven useful since it revealed
    important insights on the importance of the $\mathtt{MaybeKnown}$ fine-tuning
    examples, as discussed in detail in Â§[5](#S5 "5 Understanding Knowledge Types:
    Their Value and Impact â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 'æˆ‘ä»¬é¦–å…ˆåæ€æˆ‘ä»¬åˆ’åˆ†$\mathtt{Known}$çš„é€‰æ‹©æ˜¯å¦ç¡®å®æ•æ‰åˆ°äº†å…·æœ‰é«˜çŸ¥è¯†åº¦çš„äº‹å®ï¼Œå› ä¸ºå®ƒå§‹ç»ˆè¶…è¿‡$95\%$ï¼Œè€Œ$\mathtt{WeaklyKnown}$çš„è¡¨ç°æ¯”$\mathtt{MaybeKnown}$æ›´å·®ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ‰€åšçš„*å‡†ç¡®*ç±»åˆ«åŒºåˆ†è¢«è¯æ˜æ˜¯æœ‰ç”¨çš„ï¼Œå› ä¸ºå®ƒæ­ç¤ºäº†å…³äº$\mathtt{MaybeKnown}$ç»†è°ƒç¤ºä¾‹çš„é‡è¦è§è§£ï¼Œå¦‚Â§[5](#S5
    "5 Understanding Knowledge Types: Their Value and Impact â€£ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?")ä¸­è¯¦ç»†è®¨è®ºçš„ã€‚'
- en: '![Refer to caption](img/207718f4a13afc5dc87f1cb456cc87f8.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜](img/207718f4a13afc5dc87f1cb456cc87f8.png)'
- en: 'Figure 5: SliCK $\mathtt{Unknown}$ as $\mathtt{Unknown}$ of test examples classified
    as $\mathtt{Unknown}$. Our $\mathtt{Unknown}$ with less than $10$ random 4-shot
    exemplars (see Â§[3](#S3 "3 Quantifying Knowledge in LLMs â€£ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?") and Â§[C](#A3 "Appendix C ğ‘·_ğ™²ğš˜ğš›ğš›ğšğšŒğš
    Approximation â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾5ï¼šSliCK $\mathtt{Unknown}$ä½œä¸ºè¢«åˆ†ç±»ä¸º$\mathtt{Unknown}$çš„æµ‹è¯•ç¤ºä¾‹çš„$\mathtt{Unknown}$ã€‚æˆ‘ä»¬çš„$\mathtt{Unknown}$æœ‰å°‘äº$10$ä¸ªéšæœºçš„4-shotç¤ºä¾‹ï¼ˆè§Â§[3](#S3
    "3 Quantifying Knowledge in LLMs â€£ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?")å’ŒÂ§[C](#A3 "Appendix C ğ‘·_ğ™²ğš˜ğš›ğš›ğšğšŒğš Approximation â€£ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?")ï¼‰ã€‚
- en: Benchmarking Unknown Test Examples
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: åŸºå‡†æµ‹è¯•æœªçŸ¥æµ‹è¯•ç¤ºä¾‹
- en: A desired property for $(q,a)$ that appear in the test set, is that $M$ post
    fine-tuning (otherwise they are not truly $\mathtt{Unknown}$ is extremely low
    ($3.2\%$ examples are actually unknown to $M$.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå‡ºç°åœ¨æµ‹è¯•é›†ä¸­çš„$(q,a)$ï¼ŒæœŸæœ›çš„å±æ€§æ˜¯$M$å¾®è°ƒåï¼ˆå¦åˆ™å®ƒä»¬å¹¶éçœŸæ­£çš„$\mathtt{Unknown}$ï¼‰ï¼Œå…¶æä½ï¼ˆ$3.2\%$ï¼‰çš„å®é™…æœªçŸ¥ç¤ºä¾‹æ•°ã€‚
- en: 'As a case study for comparison, we analyze the P(True) approach by Kadavath
    etÂ al. ([2022](#bib.bib10)): a continuous score that estimates the probability
    a model assigns to the correctness of a specific answer. P(True) was originally
    used for *self-evaluating* model-generated answers, while we use it to assess
    whether $M$ and compare this methodology to SliCK. Our results indicate that,
    at least in our setting, our approach categorizes $\mathtt{Unknown}$ using both
    methods, the accuracy on the P(True)-based $\mathtt{Unknown}$ is crucial, as using
    $N_{\text{ex}}<10$ examples.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºæ¯”è¾ƒçš„æ¡ˆä¾‹ç ”ç©¶ï¼Œæˆ‘ä»¬åˆ†æäº†Kadavathç­‰äººï¼ˆ[2022](#bib.bib10)ï¼‰çš„P(True)æ–¹æ³•ï¼šä¸€ç§ä¼°è®¡æ¨¡å‹å¯¹ç‰¹å®šç­”æ¡ˆæ­£ç¡®æ€§çš„æ¦‚ç‡çš„è¿ç»­è¯„åˆ†ã€‚P(True)æœ€åˆç”¨äº*è‡ªæˆ‘è¯„ä¼°*æ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆï¼Œè€Œæˆ‘ä»¬ç”¨å®ƒæ¥è¯„ä¼°$M$å¹¶å°†è¿™ç§æ–¹æ³•ä¸SliCKè¿›è¡Œæ¯”è¾ƒã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œè‡³å°‘åœ¨æˆ‘ä»¬çš„è®¾ç½®ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨ä¸¤ç§æ–¹æ³•å¯¹$\mathtt{Unknown}$è¿›è¡Œåˆ†ç±»ï¼ŒåŸºäºP(True)çš„$\mathtt{Unknown}$çš„å‡†ç¡®æ€§è‡³å…³é‡è¦ï¼Œå› ä¸ºä½¿ç”¨$N_{\text{ex}}<10$ç¤ºä¾‹ã€‚
- en: 7 Discussion
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 è®¨è®º
- en: Practical Implications.
  id: totrans-113
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å®é™…æ„ä¹‰ã€‚
- en: 'This work highlights the risk in using supervised fine-tuning to update LLMsâ€™
    knowledge, as we present empirical evidence that acquiring new knowledge through
    fine-tuning is correlated with hallucinations w.r.t pre-existing knowledge. Additionally,
    this work raises important questions for future exploration regarding fine-tuning
    practices. We saw that $\mathtt{Unknown}$ ones, thus their negative effect manifests
    as a form of *overfitting*, which emphasizes the importance of using *early-stopping*
    instead of a fixed number of fine-tuning steps. However, early-stopping may be
    less effective when fine-tuning on numerous tasks with distinct optimal stopping
    points. An alternative solution can be to align the fine-tuning data with the
    modelâ€™s knowledge by filtering-out $\mathtt{Unknown}$ fine-tuning examples can
    still be useful to teach LLMs to express uncertainty on $\mathtt{Unknown}$ fine-tuning
    examples with uncertainty expressions* (e.g., *â€œI donâ€™t knowâ€*) *reduce their
    negative effect?* Our preliminary experiment (described in Â§[K](#A11 "Appendix
    K Re-labeling ğš„ğš—ğš”ğš—ğš˜ğš ğš— Fine-tuning Example with an Uncertainty Expression: Initial
    Experiment â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"))
    suggests that the answer is *yes*, which indicates that such approaches could
    be the most promising. Exploring this is an interesting direction for future work.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 'æœ¬ç ”ç©¶çªå‡ºäº†ä½¿ç”¨ç›‘ç£æ€§å¾®è°ƒæ›´æ–°LLMsçŸ¥è¯†çš„é£é™©ï¼Œå› ä¸ºæˆ‘ä»¬æä¾›äº†å®è¯è¯æ®è¡¨æ˜ï¼Œé€šè¿‡å¾®è°ƒè·å¾—æ–°çŸ¥è¯†ä¸ç›¸å¯¹äºç°æœ‰çŸ¥è¯†çš„å¹»è§‰æœ‰å…³ã€‚æ­¤å¤–ï¼Œæœ¬ç ”ç©¶æå‡ºäº†æœªæ¥æ¢ç´¢å¾®è°ƒå®è·µçš„é‡è¦é—®é¢˜ã€‚æˆ‘ä»¬å‘ç°ï¼Œ$\mathtt{Unknown}$
    çš„æƒ…å†µï¼Œå› æ­¤å®ƒä»¬çš„è´Ÿé¢å½±å“è¡¨ç°ä¸ºä¸€ç§*è¿‡æ‹Ÿåˆ*ï¼Œè¿™å¼ºè°ƒäº†ä½¿ç”¨*æ—©åœ*è€Œéå›ºå®šæ•°é‡çš„å¾®è°ƒæ­¥éª¤çš„é‡è¦æ€§ã€‚ç„¶è€Œï¼Œå½“åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå¾®è°ƒä¸”è¿™äº›ä»»åŠ¡æœ‰ä¸åŒçš„æœ€ä½³åœæ­¢ç‚¹æ—¶ï¼Œæ—©åœå¯èƒ½æ•ˆæœè¾ƒå·®ã€‚ä¸€ä¸ªæ›¿ä»£æ–¹æ¡ˆæ˜¯é€šè¿‡ç­›é€‰æ‰$\mathtt{Unknown}$
    å¾®è°ƒç¤ºä¾‹æ¥å°†å¾®è°ƒæ•°æ®ä¸æ¨¡å‹çš„çŸ¥è¯†å¯¹é½ï¼Œè¿™ä»ç„¶å¯ä»¥æœ‰åŠ©äºæ•™å¯¼LLMsåœ¨$\mathtt{Unknown}$ å¾®è°ƒç¤ºä¾‹ä¸­ç”¨ä¸ç¡®å®šæ€§è¡¨è¾¾*ï¼ˆä¾‹å¦‚ï¼Œ*â€œæˆ‘ä¸çŸ¥é“â€*ï¼‰*æ¥å‡å°‘å…¶è´Ÿé¢å½±å“*ï¼Ÿæˆ‘ä»¬çš„åˆæ­¥å®éªŒï¼ˆè§Â§[K](#A11
    "é™„å½• K: ä½¿ç”¨ä¸ç¡®å®šæ€§è¡¨è¾¾é‡æ–°æ ‡è®° $\mathtt{Unknown}$ å¾®è°ƒç¤ºä¾‹: åˆæ­¥å®éªŒ â€£ å¾®è°ƒLLMsä¸Šçš„æ–°çŸ¥è¯†æ˜¯å¦ä¼šä¿ƒè¿›å¹»è§‰ï¼Ÿ")ï¼‰è¡¨æ˜ç­”æ¡ˆæ˜¯*æ˜¯çš„*ï¼Œè¿™è¡¨æ˜è¿™ç§æ–¹æ³•å¯èƒ½æ˜¯æœ€æœ‰å‰é€”çš„ã€‚æ¢ç´¢è¿™ä¸€ç‚¹æ˜¯æœªæ¥å·¥ä½œçš„ä¸€ä¸ªæœ‰è¶£æ–¹å‘ã€‚'
- en: Superficial Alignment Hypothesis.
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: è¡¨é¢å¯¹é½å‡è®¾ã€‚
- en: Zhou etÂ al. ([2023](#bib.bib34)) hypothesized that the knowledge and capabilities
    of LLMs are mostly learned during pre-training, while alignment is a simple process
    where the model learns the style or format for interacting with users. They substantiate
    this hypothesis by showing that fine-tuning on just $\mathtt{1k}$ examples and
    mostly learn to utilize their pre-existing knowledge. We also showed that fine-tuning
    on $\mathtt{HighlyKnown}$ examples led to sub-optimal utilization of pre-existing
    knowledge, despite our task format being simpler than LIMAâ€™s and our dataset being
    six times larger. Taken together, our findings suggest that even though most of
    the LLMâ€™s knowledge is indeed acquired through pre-training, the model learns
    more than just style or format through fine-tuning, as the selection of fine-tuning
    examples significantly influences the modelâ€™s capability to utilize its pre-existing
    knowledge post fine-tuning.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: å‘¨ç­‰äººï¼ˆ[2023](#bib.bib34)ï¼‰å‡è®¾ LLM çš„çŸ¥è¯†å’Œèƒ½åŠ›ä¸»è¦æ˜¯åœ¨é¢„è®­ç»ƒæœŸé—´è·å¾—çš„ï¼Œè€Œå¯¹é½æ˜¯ä¸€ä¸ªç®€å•çš„è¿‡ç¨‹ï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­æ¨¡å‹å­¦ä¹ ä¸ç”¨æˆ·äº’åŠ¨çš„é£æ ¼æˆ–æ ¼å¼ã€‚ä»–ä»¬é€šè¿‡å±•ç¤ºä»…åœ¨
    $\mathtt{1k}$ ç¤ºä¾‹ä¸Šè¿›è¡Œå¾®è°ƒå¤§å¤šå­¦ä¹ å¦‚ä½•åˆ©ç”¨å·²æœ‰çŸ¥è¯†æ¥è¯å®è¿™ä¸€å‡è®¾ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†åœ¨ $\mathtt{HighlyKnown}$ ç¤ºä¾‹ä¸Šè¿›è¡Œå¾®è°ƒå¯¼è‡´äº†å¯¹å·²æœ‰çŸ¥è¯†çš„æ¬¡ä¼˜åˆ©ç”¨ï¼Œå°½ç®¡æˆ‘ä»¬çš„ä»»åŠ¡æ ¼å¼æ¯”
    LIMA çš„æ›´ç®€å•ï¼Œä¸”æˆ‘ä»¬çš„æ•°æ®é›†å¤§å…­å€ã€‚ç»¼åˆæ¥çœ‹ï¼Œæˆ‘ä»¬çš„å‘ç°è¡¨æ˜ï¼Œå°½ç®¡ LLM çš„å¤§éƒ¨åˆ†çŸ¥è¯†ç¡®å®æ˜¯é€šè¿‡é¢„è®­ç»ƒè·å¾—çš„ï¼Œä½†æ¨¡å‹é€šè¿‡å¾®è°ƒå­¦åˆ°çš„ä¸ä»…ä»…æ˜¯é£æ ¼æˆ–æ ¼å¼ï¼Œå› ä¸ºå¾®è°ƒç¤ºä¾‹çš„é€‰æ‹©æ˜¾è‘—å½±å“äº†æ¨¡å‹åœ¨å¾®è°ƒååˆ©ç”¨å·²æœ‰çŸ¥è¯†çš„èƒ½åŠ›ã€‚
- en: 8 Related Work
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 ç›¸å…³å·¥ä½œ
- en: New knowledge and hallucinations.
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ–°çŸ¥è¯†ä¸å¹»è§‰ã€‚
- en: Schulman ([2023](#bib.bib24)), Goldberg ([2023](#bib.bib7)) and Gudibande etÂ al.
    ([2023](#bib.bib8)) mention the conjecture that fine-tuning on new factual knowledge
    may encourage hallucinations. Huang etÂ al. ([2023](#bib.bib9)) categorized hallucination
    causes and formally defined this scenario as *capability misalignment*. They highlight
    that limited research addresses capability misalignment due to the challenge of
    defining the knowledge boundary of LLMs. Kang etÂ al. ([2024](#bib.bib12)) showed
    that when a fine-tuned LLM encounters unknown queries at test time, its responses
    mimic the responses associated with the unknown examples in the fine-tuning data.
    Yin etÂ al. ([2023](#bib.bib31)) showed that LLMsâ€™ performance is not satisfactory
    when they face new knowledge in their input contexts and Lee etÂ al. ([2023](#bib.bib14))
    analyzed the impact of unknown *in-context* learning examples. To the best of
    our knowledge, our work is the first to empirically assess the impact of exposure
    to new knowledge through fine-tuning on tendency of the fine-tuned model to hallucinate.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Schulmanï¼ˆ[2023](#bib.bib24)ï¼‰ã€Goldbergï¼ˆ[2023](#bib.bib7)ï¼‰å’Œ Gudibande ç­‰äººï¼ˆ[2023](#bib.bib8)ï¼‰æåˆ°å¾®è°ƒæ–°äº‹å®çŸ¥è¯†å¯èƒ½ä¼šå¼•å‘å¹»è§‰çš„çŒœæƒ³ã€‚Huang
    ç­‰äººï¼ˆ[2023](#bib.bib9)ï¼‰å°†å¹»è§‰åŸå› è¿›è¡Œäº†åˆ†ç±»ï¼Œå¹¶æ­£å¼å°†è¿™ä¸€æƒ…æ™¯å®šä¹‰ä¸º*èƒ½åŠ›ä¸åŒ¹é…*ã€‚ä»–ä»¬æŒ‡å‡ºï¼Œç”±äºå®šä¹‰ LLM çŸ¥è¯†è¾¹ç•Œçš„æŒ‘æˆ˜ï¼Œæœ‰é™çš„ç ”ç©¶è§£å†³äº†èƒ½åŠ›ä¸åŒ¹é…çš„é—®é¢˜ã€‚Kang
    ç­‰äººï¼ˆ[2024](#bib.bib12)ï¼‰å±•ç¤ºäº†å½“å¾®è°ƒåçš„ LLM åœ¨æµ‹è¯•æ—¶é‡åˆ°æœªçŸ¥æŸ¥è¯¢æ—¶ï¼Œå…¶å“åº”ç±»ä¼¼äºå¾®è°ƒæ•°æ®ä¸­ä¸æœªçŸ¥ç¤ºä¾‹ç›¸å…³çš„å“åº”ã€‚Yin ç­‰äººï¼ˆ[2023](#bib.bib31)ï¼‰å±•ç¤ºäº†
    LLM åœ¨è¾“å…¥ä¸Šä¸‹æ–‡ä¸­é¢å¯¹æ–°çŸ¥è¯†æ—¶è¡¨ç°ä¸ä½³ï¼Œè€Œ Lee ç­‰äººï¼ˆ[2023](#bib.bib14)ï¼‰åˆ†æäº†æœªçŸ¥*ä¸Šä¸‹æ–‡*å­¦ä¹ ç¤ºä¾‹çš„å½±å“ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬çš„å·¥ä½œæ˜¯é¦–æ¬¡å®è¯è¯„ä¼°é€šè¿‡å¾®è°ƒæš´éœ²äºæ–°çŸ¥è¯†å¯¹å¾®è°ƒæ¨¡å‹äº§ç”Ÿå¹»è§‰çš„å€¾å‘çš„å½±å“ã€‚
- en: Quantifying knowledge in LLMs.
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: é‡åŒ– LLM ä¸­çš„çŸ¥è¯†ã€‚
- en: SliCK can be seen as a confidence elicitation method for the ground truth label
    ($M$ if it is confident that $a$). Existing work derive calibrated confidence
    from LLMs by examining agreement across multiple samples Kuhn etÂ al. ([2023](#bib.bib13));
    Manakul etÂ al. ([2023](#bib.bib17)); Tian etÂ al. ([2023a](#bib.bib26)); Lyu etÂ al.
    ([2024](#bib.bib16)), probing internal representations Azaria and Mitchell ([2023](#bib.bib3));
    Burns etÂ al. ([2022](#bib.bib4)), eliciting verbalized probability Tian etÂ al.
    ([2023b](#bib.bib27)) or direct prompting Kadavath etÂ al. ([2022](#bib.bib10)).
    [Kadavath etÂ al.](#bib.bib10) also trained a separate P(IK) model to predict if
    the LLM knows the answer to $q$ (Â§[3](#S3 "3 Quantifying Knowledge in LLMs â€£ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")). A key difference
    is that we also define the SliCK categories, and provide evidence that we capture
    meaningful and useful categories.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: SliCK å¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§å¯¹çœŸå®æ ‡ç­¾çš„ä¿¡å¿ƒå¼•å¯¼æ–¹æ³•ï¼ˆ$M$ å¦‚æœå®ƒå¯¹ $a$ æœ‰ä¿¡å¿ƒï¼‰ã€‚ç°æœ‰å·¥ä½œé€šè¿‡æ£€æŸ¥å¤šä¸ªæ ·æœ¬ä¹‹é—´çš„ä¸€è‡´æ€§æ¥ä» LLM ä¸­æ¨å¯¼å‡ºæ ¡å‡†çš„ä¿¡å¿ƒ
    Kuhn ç­‰äºº ([2023](#bib.bib13)); Manakul ç­‰äºº ([2023](#bib.bib17)); Tian ç­‰äºº ([2023a](#bib.bib26));
    Lyu ç­‰äºº ([2024](#bib.bib16))ï¼Œæ¢æµ‹å†…éƒ¨è¡¨å¾ Azaria å’Œ Mitchell ([2023](#bib.bib3)); Burns
    ç­‰äºº ([2022](#bib.bib4))ï¼Œå¼•å‡ºå£å¤´æ¦‚ç‡ Tian ç­‰äºº ([2023b](#bib.bib27)) æˆ–ç›´æ¥æç¤º Kadavath ç­‰äºº
    ([2022](#bib.bib10))ã€‚ [Kadavath ç­‰äºº](#bib.bib10) è¿˜è®­ç»ƒäº†ä¸€ä¸ªå•ç‹¬çš„ P(IK) æ¨¡å‹æ¥é¢„æµ‹ LLM æ˜¯å¦çŸ¥é“
    $q$ çš„ç­”æ¡ˆ (Â§[3](#S3 "3 Quantifying Knowledge in LLMs â€£ Does Fine-Tuning LLMs on
    New Knowledge Encourage Hallucinations?"))ã€‚ä¸€ä¸ªå…³é”®çš„åŒºåˆ«æ˜¯æˆ‘ä»¬è¿˜å®šä¹‰äº† SliCK ç±»åˆ«ï¼Œå¹¶æä¾›äº†æˆ‘ä»¬æ•è·æœ‰æ„ä¹‰ä¸”æœ‰ç”¨ç±»åˆ«çš„è¯æ®ã€‚
- en: 9 Conclusion
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 ç»“è®º
- en: 'We study the impact of integrating new factual knowledge through fine-tuning
    on the modelâ€™s tendency to hallucinate. We first propose SliCK, a categorization
    of facts w.r.t. LLMâ€™s knowledge. We then design a controlled study where we isolate
    the impact of new knowledge and rigorously evaluate its effects. We provide multiple
    insights on the fine-tuning dynamics, with the following key findings: (1) Acquiring
    new knowledge via supervised fine-tuning is correlated with hallucinations w.r.t.
    pre-existing knowledge. (2) LLMs struggle to integrate new knowledge through fine-tuning
    and mostly learn to use their pre-existing knowledge.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç ”ç©¶äº†é€šè¿‡å¾®è°ƒæ•´åˆæ–°äº‹å®çŸ¥è¯†å¯¹æ¨¡å‹å¹»è§‰å€¾å‘çš„å½±å“ã€‚æˆ‘ä»¬é¦–å…ˆæå‡ºäº† SliCKï¼Œä¸€ç§å…³äº LLM çŸ¥è¯†çš„äº‹å®åˆ†ç±»ã€‚ç„¶åæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå—æ§ç ”ç©¶ï¼Œåœ¨è¯¥ç ”ç©¶ä¸­æˆ‘ä»¬éš”ç¦»äº†æ–°çŸ¥è¯†çš„å½±å“å¹¶ä¸¥æ ¼è¯„ä¼°å…¶æ•ˆæœã€‚æˆ‘ä»¬æä¾›äº†å…³äºå¾®è°ƒåŠ¨æ€çš„å¤šä¸ªè§è§£ï¼Œä¸»è¦å‘ç°å¦‚ä¸‹ï¼š(1)
    é€šè¿‡ç›‘ç£å¾®è°ƒè·å–æ–°çŸ¥è¯†ä¸ç›¸å¯¹äºç°æœ‰çŸ¥è¯†çš„å¹»è§‰ç›¸å…³ã€‚(2) LLM åœ¨é€šè¿‡å¾®è°ƒæ•´åˆæ–°çŸ¥è¯†æ—¶é¢ä¸´å›°éš¾ï¼Œä¸»è¦å­¦ä¹ ä½¿ç”¨å…¶ç°æœ‰çŸ¥è¯†ã€‚
- en: 10 Limitations
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10 å±€é™æ€§
- en: 'Our experiments were conducted using a single LLM, and thus it is unclear whether
    results will vary with different LLMs. Having said that, our study is extremely
    compute-heavy and thus challenging to replicate on multiple LLMs: First, our fine-tuning
    is compute-heavy as its runs are very long as we wanted to analyze the behavior
    during different stages of fine-tuning (including the overfitting stages). Second,
    and most importantly, to facilitate our study we needed to annotate a large scale
    dataset w.r.t the SliCK categories. To derive reliable conclusions, it was crucial
    to accurately assess the modelâ€™s knowledge w.r.t. a single fine-tuning example.
    In our case we run 170 inference steps per example, i.e., more than $15M$ inference
    steps to categorize our full dataset.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„å®éªŒä½¿ç”¨äº†å•ä¸€çš„ LLMï¼Œå› æ­¤å°šä¸æ¸…æ¥šä¸åŒçš„ LLM æ˜¯å¦ä¼šå¾—å‡ºä¸åŒçš„ç»“æœã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»¬çš„ç ”ç©¶è®¡ç®—é‡éå¸¸å¤§ï¼Œå› æ­¤åœ¨å¤šä¸ª LLM ä¸Šé‡å¤å®éªŒå…·æœ‰æŒ‘æˆ˜æ€§ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬çš„å¾®è°ƒè®¡ç®—é‡å¤§ï¼Œå› ä¸ºè¿è¡Œæ—¶é—´éå¸¸é•¿ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨ä¸åŒçš„å¾®è°ƒé˜¶æ®µï¼ˆåŒ…æ‹¬è¿‡æ‹Ÿåˆé˜¶æ®µï¼‰åˆ†æè¡Œä¸ºã€‚å…¶æ¬¡ï¼Œä¹Ÿæ˜¯æœ€é‡è¦çš„ï¼Œä¸ºäº†æ–¹ä¾¿æˆ‘ä»¬çš„ç ”ç©¶ï¼Œæˆ‘ä»¬éœ€è¦å¯¹å¤§è§„æ¨¡æ•°æ®é›†è¿›è¡Œ
    SliCK ç±»åˆ«çš„æ³¨é‡Šã€‚ä¸ºäº†å¾—å‡ºå¯é çš„ç»“è®ºï¼Œå‡†ç¡®è¯„ä¼°æ¨¡å‹åœ¨å•ä¸ªå¾®è°ƒç¤ºä¾‹ä¸‹çš„çŸ¥è¯†è‡³å…³é‡è¦ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬æ¯ä¸ªç¤ºä¾‹è¿è¡Œ 170 æ¬¡æ¨ç†æ­¥éª¤ï¼Œå³å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œè¶…è¿‡
    $15M$ æ¬¡æ¨ç†æ­¥éª¤ã€‚
- en: In addition, since we focus on closed-book QA, the practical implications from
    our study such as filtering-out $\mathtt{Unknown}$. We leave this for future work.
    Long-form generation tasks introduce evaluation challenges, leading to a wide
    adoption of LLM-based evaluations. Our choice to focus explicitly on closed book
    QA facilitates more accurate evaluation that enhances the reliability of our findings.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œç”±äºæˆ‘ä»¬ä¸“æ³¨äºé—­å· QAï¼Œå› æ­¤æˆ‘ä»¬çš„ç ”ç©¶çš„å®é™…æ„ä¹‰ï¼Œå¦‚è¿‡æ»¤ $\mathtt{Unknown}$ã€‚æˆ‘ä»¬å°†æ­¤ç•™å¾…æœªæ¥å·¥ä½œã€‚é•¿ç¯‡ç”Ÿæˆä»»åŠ¡å¼•å…¥äº†è¯„ä¼°æŒ‘æˆ˜ï¼Œå¯¼è‡´
    LLM åŸºäºè¯„ä¼°çš„å¹¿æ³›é‡‡ç”¨ã€‚æˆ‘ä»¬é€‰æ‹©æ˜ç¡®å…³æ³¨é—­å· QAï¼Œæœ‰åŠ©äºæ›´å‡†ç¡®çš„è¯„ä¼°ï¼Œä»è€Œæé«˜æˆ‘ä»¬ç ”ç©¶ç»“æœçš„å¯é æ€§ã€‚
- en: Lastly, we did not test the effect of adding additional fine-tuning examples
    from diverse tasks into the fine-tuning mixture. While this could more closely
    approximate a typical instruction fine-tuning scenario, such dataset extension
    may introduce new factual knowledge in an uncontrollable way, which will limit
    our findings.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬æ²¡æœ‰æµ‹è¯•å°†æ¥è‡ªä¸åŒä»»åŠ¡çš„é¢å¤–å¾®è°ƒç¤ºä¾‹æ·»åŠ åˆ°å¾®è°ƒæ··åˆä¸­ã€‚è™½ç„¶è¿™å¯èƒ½æ›´æ¥è¿‘å…¸å‹çš„æŒ‡ä»¤å¾®è°ƒåœºæ™¯ï¼Œä½†è¿™ç§æ•°æ®é›†æ‰©å±•å¯èƒ½ä¼šä»¥ä¸å¯æ§çš„æ–¹å¼å¼•å…¥æ–°çš„äº‹å®çŸ¥è¯†ï¼Œä»è€Œé™åˆ¶æˆ‘ä»¬çš„å‘ç°ã€‚
- en: 11 Acknowledgments
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11 è‡´è°¢
- en: We would like to thank Ori Ram, Uri Shaham, Alon Jacovi, Mor Ventura, Yochai
    Blau, Eyal Ben-David, Avi Caciularu, Avinatan Hassidim and the members of Roi
    Reichartâ€™s NLP group for reviewing the paper draft and providing valuable feedback.
    Special thanks to Uri Shaham for assisting in setting up the fine-tuning pipeline
    during the early stages of our research.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¦æ„Ÿè°¢ Ori Ramã€Uri Shahamã€Alon Jacoviã€Mor Venturaã€Yochai Blauã€Eyal Ben-Davidã€Avi
    Caciularuã€Avinatan Hassidim ä»¥åŠ Roi Reichart çš„ NLP ç»„æˆå‘˜å®¡é˜…è®ºæ–‡è‰ç¨¿å¹¶æä¾›å®è´µåé¦ˆã€‚ç‰¹åˆ«æ„Ÿè°¢ Uri Shaham
    åœ¨æˆ‘ä»¬ç ”ç©¶æ—©æœŸé˜¶æ®µååŠ©è®¾ç½®å¾®è°ƒç®¡é“ã€‚
- en: References
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: AlKhamissi etÂ al. (2022) Badr AlKhamissi, Millicent Li, Asli Celikyilmaz, Mona
    Diab, and Marjan Ghazvininejad. 2022. A review on language models as knowledge
    bases. *arXiv preprint arXiv:2204.06031*.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AlKhamissi ç­‰ï¼ˆ2022ï¼‰Badr AlKhamissiã€Millicent Liã€Asli Celikyilmazã€Mona Diab å’Œ
    Marjan Ghazvininejadã€‚2022å¹´ã€‚è¯­è¨€æ¨¡å‹ä½œä¸ºçŸ¥è¯†åº“çš„ç»¼è¿°ã€‚ *arXiv é¢„å°æœ¬ arXiv:2204.06031*ã€‚
- en: Anil etÂ al. (2023) Rohan Anil, AndrewÂ M Dai, Orhan Firat, Melvin Johnson, Dmitry
    Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng
    Chen, etÂ al. 2023. Palm 2 technical report. *arXiv preprint arXiv:2305.10403*.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anil ç­‰ï¼ˆ2023ï¼‰Rohan Anilã€Andrew M Daiã€Orhan Firatã€Melvin Johnsonã€Dmitry Lepikhinã€Alexandre
    Passosã€Siamak Shakeriã€Emanuel Taropaã€Paige Baileyã€Zhifeng Chen ç­‰ã€‚2023å¹´ã€‚Palm 2
    æŠ€æœ¯æŠ¥å‘Šã€‚ *arXiv é¢„å°æœ¬ arXiv:2305.10403*ã€‚
- en: Azaria and Mitchell (2023) Amos Azaria and Tom Mitchell. 2023. The internal
    state of an llm knows when its lying. *arXiv preprint arXiv:2304.13734*.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azaria å’Œ Mitchellï¼ˆ2023ï¼‰Amos Azaria å’Œ Tom Mitchellã€‚2023å¹´ã€‚LLM çš„å†…éƒ¨çŠ¶æ€çŸ¥é“ä½•æ—¶æ’’è°ã€‚ *arXiv
    é¢„å°æœ¬ arXiv:2304.13734*ã€‚
- en: Burns etÂ al. (2022) Collin Burns, Haotian Ye, Dan Klein, and Jacob Steinhardt.
    2022. Discovering latent knowledge in language models without supervision. *arXiv
    preprint arXiv:2212.03827*.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Burns ç­‰ï¼ˆ2022ï¼‰Collin Burnsã€Haotian Yeã€Dan Klein å’Œ Jacob Steinhardtã€‚2022å¹´ã€‚åœ¨æ²¡æœ‰ç›‘ç£çš„æƒ…å†µä¸‹å‘ç°è¯­è¨€æ¨¡å‹ä¸­çš„æ½œåœ¨çŸ¥è¯†ã€‚
    *arXiv é¢„å°æœ¬ arXiv:2212.03827*ã€‚
- en: 'Cohen etÂ al. (2023) Roi Cohen, Mor Geva, Jonathan Berant, and Amir Globerson.
    2023. [Crawling the internal knowledge-base of language models](https://doi.org/10.18653/v1/2023.findings-eacl.139).
    In *Findings of the Association for Computational Linguistics: EACL 2023*, pages
    1856â€“1869, Dubrovnik, Croatia. Association for Computational Linguistics.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cohen ç­‰ï¼ˆ2023ï¼‰Roi Cohenã€Mor Gevaã€Jonathan Berant å’Œ Amir Globersonã€‚2023å¹´ã€‚[çˆ¬å–è¯­è¨€æ¨¡å‹çš„å†…éƒ¨çŸ¥è¯†åº“](https://doi.org/10.18653/v1/2023.findings-eacl.139)ã€‚åœ¨
    *è®¡ç®—è¯­è¨€å­¦åä¼šå¹´ä¼šå‘ç°ï¼šEACL 2023*ï¼Œç¬¬ 1856â€“1869 é¡µï¼Œå…‹ç½—åœ°äºšæœå¸ƒç½—å¤«å°¼å…‹ã€‚è®¡ç®—è¯­è¨€å­¦åä¼šã€‚
- en: Gao (2021) Leo Gao. 2021. [Behavior cloning is miscalibrated](https://www.alignmentforum.org/posts/BgoKdAzogxmgkuuAt/behavior-cloning-is-miscalibrated).
    *AI Alignment Forum*.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gaoï¼ˆ2021ï¼‰Leo Gaoã€‚2021å¹´ã€‚[è¡Œä¸ºå…‹éš†æ˜¯è¯¯æ ¡å‡†çš„](https://www.alignmentforum.org/posts/BgoKdAzogxmgkuuAt/behavior-cloning-is-miscalibrated)ã€‚*AI
    Alignment Forum*ã€‚
- en: Goldberg (2023) Yoav Goldberg. 2023. [Reinforcement learning for language models](https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81).
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goldbergï¼ˆ2023ï¼‰Yoav Goldbergã€‚2023å¹´ã€‚[è¯­è¨€æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ](https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81)ã€‚
- en: Gudibande etÂ al. (2023) Arnav Gudibande, Eric Wallace, Charlie Snell, Xinyang
    Geng, Hao Liu, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. The false promise
    of imitating proprietary llms. *arXiv preprint arXiv:2305.15717*.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gudibande ç­‰ï¼ˆ2023ï¼‰Arnav Gudibandeã€Eric Wallaceã€Charlie Snellã€Xinyang Gengã€Hao
    Liuã€Pieter Abbeelã€Sergey Levine å’Œ Dawn Songã€‚2023å¹´ã€‚æ¨¡ä»¿ä¸“æœ‰å¤§è¯­è¨€æ¨¡å‹çš„è™šå‡æ‰¿è¯ºã€‚ *arXiv é¢„å°æœ¬ arXiv:2305.15717*ã€‚
- en: 'Huang etÂ al. (2023) Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin
    Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, etÂ al.
    2023. A survey on hallucination in large language models: Principles, taxonomy,
    challenges, and open questions. *arXiv preprint arXiv:2311.05232*.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang ç­‰ï¼ˆ2023ï¼‰Lei Huangã€Weijiang Yuã€Weitao Maã€Weihong Zhongã€Zhangyin Fengã€Haotian
    Wangã€Qianglong Chenã€Weihua Pengã€Xiaocheng Fengã€Bing Qin ç­‰ã€‚2023å¹´ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰è°ƒæŸ¥ï¼šåŸåˆ™ã€åˆ†ç±»ã€æŒ‘æˆ˜å’Œæœªè§£ä¹‹è°œã€‚
    *arXiv é¢„å°æœ¬ arXiv:2311.05232*ã€‚
- en: Kadavath etÂ al. (2022) Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan,
    Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma,
    Eli Tran-Johnson, etÂ al. 2022. Language models (mostly) know what they know. *arXiv
    preprint arXiv:2207.05221*.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kadavath ç­‰ï¼ˆ2022ï¼‰Saurav Kadavathã€Tom Conerlyã€Amanda Askellã€Tom Henighanã€Dawn
    Drainã€Ethan Perezã€Nicholas Schieferã€Zac Hatfield-Doddsã€Nova DasSarmaã€Eli Tran-Johnson
    ç­‰ã€‚2022å¹´ã€‚è¯­è¨€æ¨¡å‹ï¼ˆå¤§å¤šæ•°æƒ…å†µä¸‹ï¼‰çŸ¥é“å®ƒä»¬çŸ¥é“ä»€ä¹ˆã€‚ *arXiv é¢„å°æœ¬ arXiv:2207.05221*ã€‚
- en: 'Kamalloo etÂ al. (2023) Ehsan Kamalloo, Nouha Dziri, Charles L.Â A. Clarke, and
    Davood Rafiei. 2023. [Evaluating open-domain question answering in the era of
    large language models](https://doi.org/10.18653/V1/2023.ACL-LONG.307). In *Proceedings
    of the 61st Annual Meeting of the Association for Computational Linguistics (Volume
    1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023*, pages 5591â€“5606\.
    Association for Computational Linguistics.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kamalloo ç­‰äººï¼ˆ2023ï¼‰Ehsan Kamallooã€Nouha Dziriã€Charles L. A. Clarke å’Œ Davood Rafieiã€‚2023å¹´ã€‚[åœ¨å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£è¯„ä¼°å¼€æ”¾åŸŸé—®ç­”](https://doi.org/10.18653/V1/2023.ACL-LONG.307)ã€‚åœ¨
    *ã€Šç¬¬61å±Šè®¡ç®—è¯­è¨€å­¦åä¼šå¹´ä¼šè®ºæ–‡é›†ï¼ˆç¬¬1å·ï¼šé•¿ç¯‡è®ºæ–‡ï¼‰ï¼ŒACL 2023ï¼Œå¤šä¼¦å¤šï¼ŒåŠ æ‹¿å¤§ï¼Œ2023å¹´7æœˆ9æ—¥è‡³14æ—¥ã€‹* ä¸­ï¼Œç¬¬5591-5606é¡µã€‚è®¡ç®—è¯­è¨€å­¦åä¼šã€‚
- en: Kang etÂ al. (2024) Katie Kang, Eric Wallace, Claire Tomlin, Aviral Kumar, and
    Sergey Levine. 2024. Unfamiliar finetuning examples control how language models
    hallucinate. *arXiv preprint arXiv:2403.05612*.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kang ç­‰äººï¼ˆ2024ï¼‰Katie Kangã€Eric Wallaceã€Claire Tomlinã€Aviral Kumar å’Œ Sergey Levineã€‚2024å¹´ã€‚ä¸ç†Ÿæ‚‰çš„å¾®è°ƒç¤ºä¾‹æ§åˆ¶è¯­è¨€æ¨¡å‹çš„å¹»è§‰ã€‚*arXiv
    é¢„å°æœ¬ arXiv:2403.05612*ã€‚
- en: 'Kuhn etÂ al. (2023) Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. 2023. Semantic
    uncertainty: Linguistic invariances for uncertainty estimation in natural language
    generation. *arXiv preprint arXiv:2302.09664*.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kuhn ç­‰äººï¼ˆ2023ï¼‰Lorenz Kuhnã€Yarin Gal å’Œ Sebastian Farquharã€‚2023å¹´ã€‚è¯­ä¹‰ä¸ç¡®å®šæ€§ï¼šè‡ªç„¶è¯­è¨€ç”Ÿæˆä¸­çš„è¯­è¨€ä¸å˜æ€§ç”¨äºä¸ç¡®å®šæ€§ä¼°è®¡ã€‚*arXiv
    é¢„å°æœ¬ arXiv:2302.09664*ã€‚
- en: Lee etÂ al. (2023) Yoonsang Lee, Pranav Atreya, XiÂ Ye, and Eunsol Choi. 2023.
    Crafting in-context examples according to lmsâ€™ parametric knowledge. *arXiv preprint
    arXiv:2311.09579*.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee ç­‰äººï¼ˆ2023ï¼‰Yoonsang Leeã€Pranav Atreyaã€Xi Ye å’Œ Eunsol Choiã€‚2023å¹´ã€‚æ ¹æ® LMs çš„å‚æ•°çŸ¥è¯†åˆ¶ä½œä¸Šä¸‹æ–‡ç¤ºä¾‹ã€‚*arXiv
    é¢„å°æœ¬ arXiv:2311.09579*ã€‚
- en: 'Lin etÂ al. (2023) BillÂ Yuchen Lin, Abhilasha Ravichander, Ximing Lu, Nouha
    Dziri, Melanie Sclar, Khyathi Chandu, Chandra Bhagavatula, and Yejin Choi. 2023.
    [The unlocking spell on base llms: Rethinking alignment via in-context learning](http://arxiv.org/abs/2312.01552).
    *ArXiv preprint*.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin ç­‰äººï¼ˆ2023ï¼‰Bill Yuchen Linã€Abhilasha Ravichanderã€Ximing Luã€Nouha Dziriã€Melanie
    Sclarã€Khyathi Chanduã€Chandra Bhagavatula å’Œ Yejin Choiã€‚2023å¹´ã€‚[åŸºç¡€ LLMs çš„è§£é”å’’è¯­ï¼šé€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ é‡æ–°æ€è€ƒå¯¹é½](http://arxiv.org/abs/2312.01552)ã€‚*ArXiv
    é¢„å°æœ¬*ã€‚
- en: Lyu etÂ al. (2024) Qing Lyu, Kumar Shridhar, Chaitanya Malaviya, LiÂ Zhang, Yanai
    Elazar, Niket Tandon, Marianna Apidianaki, Mrinmaya Sachan, and Chris Callison-Burch.
    2024. Calibrating large language models with sample consistency. *arXiv preprint
    arXiv:2402.13904*.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lyu ç­‰äººï¼ˆ2024ï¼‰Qing Lyuã€Kumar Shridharã€Chaitanya Malaviyaã€Li Zhangã€Yanai Elazarã€Niket
    Tandonã€Marianna Apidianakiã€Mrinmaya Sachan å’Œ Chris Callison-Burchã€‚2024å¹´ã€‚ç”¨æ ·æœ¬ä¸€è‡´æ€§å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæ ‡å®šã€‚*arXiv
    é¢„å°æœ¬ arXiv:2402.13904*ã€‚
- en: 'Manakul etÂ al. (2023) Potsawee Manakul, Adian Liusie, and MarkÂ JF Gales. 2023.
    Selfcheckgpt: Zero-resource black-box hallucination detection for generative large
    language models. *arXiv preprint arXiv:2303.08896*.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Manakul ç­‰äººï¼ˆ2023ï¼‰Potsawee Manakulã€Adian Liusie å’Œ Mark JF Galesã€‚2023å¹´ã€‚Selfcheckgptï¼šé›¶èµ„æºé»‘ç®±å¹»è§‰æ£€æµ‹ç”¨äºç”Ÿæˆå¤§å‹è¯­è¨€æ¨¡å‹ã€‚*arXiv
    é¢„å°æœ¬ arXiv:2303.08896*ã€‚
- en: 'Mishra etÂ al. (2022) Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh
    Hajishirzi. 2022. [Cross-task generalization via natural language crowdsourcing
    instructions](https://doi.org/10.18653/v1/2022.acl-long.244). In *Proceedings
    of the 60th Annual Meeting of the Association for Computational Linguistics (Volume
    1: Long Papers)*, pages 3470â€“3487, Dublin, Ireland. Association for Computational
    Linguistics.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mishra ç­‰äººï¼ˆ2022ï¼‰Swaroop Mishraã€Daniel Khashabiã€Chitta Baral å’Œ Hannaneh Hajishirziã€‚2022å¹´ã€‚[é€šè¿‡è‡ªç„¶è¯­è¨€ä¼—åŒ…æŒ‡ä»¤è¿›è¡Œè·¨ä»»åŠ¡æ³›åŒ–](https://doi.org/10.18653/v1/2022.acl-long.244)ã€‚åœ¨
    *ã€Šç¬¬60å±Šè®¡ç®—è¯­è¨€å­¦åä¼šå¹´ä¼šè®ºæ–‡é›†ï¼ˆç¬¬1å·ï¼šé•¿ç¯‡è®ºæ–‡ï¼‰ã€‹* ä¸­ï¼Œç¬¬3470-3487é¡µï¼Œçˆ±å°”å…°éƒ½æŸæ—ã€‚è®¡ç®—è¯­è¨€å­¦åä¼šã€‚
- en: 'Ouyang etÂ al. (2022) Long Ouyang, Jeffrey Wu, XuÂ Jiang, Diogo Almeida, CarrollÂ L.
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda
    Askell, Peter Welinder, PaulÂ F. Christiano, Jan Leike, and Ryan Lowe. 2022. [Training
    language models to follow instructions with human feedback](http://papers.nips.cc/paper_files/paper/2022/hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html).
    In *Advances in Neural Information Processing Systems 35: Annual Conference on
    Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA,
    November 28 - December 9, 2022*.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¬§é˜³ç­‰äººï¼ˆ2022ï¼‰Long Ouyangã€Jeffrey Wuã€Xu Jiangã€Diogo Almeidaã€Carroll L. Wainwrightã€Pamela
    Mishkinã€Chong Zhangã€Sandhini Agarwalã€Katarina Slamaã€Alex Rayã€John Schulmanã€Jacob
    Hiltonã€Fraser Keltonã€Luke Millerã€Maddie Simensã€Amanda Askellã€Peter Welinderã€Paul
    F. Christianoã€Jan Leike å’Œ Ryan Loweã€‚2022å¹´ã€‚[é€šè¿‡äººç±»åé¦ˆè®­ç»ƒè¯­è¨€æ¨¡å‹ä»¥è·ŸéšæŒ‡ä»¤](http://papers.nips.cc/paper_files/paper/2022/hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html)ã€‚åœ¨
    *ã€Šç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•ç¬¬35å·ï¼š2022å¹´ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿå¹´ä¼šï¼ŒNeurIPS 2022ï¼Œæ–°å¥¥å°”è‰¯ï¼Œç¾å›½ï¼Œ2022å¹´11æœˆ28æ—¥è‡³12æœˆ9æ—¥ã€‹* ä¸­ã€‚
- en: Petroni etÂ al. (2019) Fabio Petroni, Tim RocktÃ¤schel, Sebastian Riedel, Patrick
    Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. 2019. [Language models
    as knowledge bases?](https://doi.org/10.18653/v1/D19-1250) In *Proceedings of
    the 2019 Conference on Empirical Methods in Natural Language Processing and the
    9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)*,
    pages 2463â€“2473, Hong Kong, China. Association for Computational Linguistics.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Petroni et al. (2019) æ³•æ¯”å¥¥Â·ä½©ç‰¹ç½—å°¼ã€è’‚å§†Â·ç½—å…‹å¡”è°¢å°”ã€å¡å·´æ–¯è’‚å®‰Â·é‡Œå¾·å°”ã€å¸•ç‰¹é‡Œå…‹Â·åˆ˜æ˜“æ–¯ã€å®‰ä¸œÂ·å·´èµ«å»·ã€ä½™ç¿”Â·å´å’Œäºšå†å±±å¤§Â·ç±³å‹’ã€‚2019ã€‚
    [è¯­è¨€æ¨¡å‹ä½œä¸ºçŸ¥è¯†åº“ï¼Ÿ](https://doi.org/10.18653/v1/D19-1250) è§äº *2019å¹´è‡ªç„¶è¯­è¨€å¤„ç†å®è¯æ–¹æ³•ä¼šè®®æš¨ç¬¬ä¹å±Šå›½é™…è”åˆè‡ªç„¶è¯­è¨€å¤„ç†ä¼šè®®ï¼ˆEMNLP-IJCNLPï¼‰*ï¼Œç¬¬2463â€“2473é¡µï¼Œä¸­å›½é¦™æ¸¯ã€‚è®¡ç®—è¯­è¨€å­¦åä¼šã€‚
- en: 'Rafailov etÂ al. (2024) Rafael Rafailov, Archit Sharma, Eric Mitchell, ChristopherÂ D
    Manning, Stefano Ermon, and Chelsea Finn. 2024. Direct preference optimization:
    Your language model is secretly a reward model. *Advances in Neural Information
    Processing Systems*, 36.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rafailov et al. (2024) æ‹‰æ–å°”Â·æ‹‰æ–æ´›å¤«ã€é˜¿å°”åŸºç‰¹Â·å¤å°”é©¬ã€åŸƒé‡Œå…‹Â·ç±³åˆ‡å°”ã€å…‹é‡Œæ–¯æ‰˜å¼—Â·DÂ·æ›¼å®ã€æ–¯ç‰¹æ³•è¯ºÂ·å„å°”è’™å’Œåˆ‡å°”è¥¿Â·èŠ¬æ©ã€‚2024ã€‚ç›´æ¥åå¥½ä¼˜åŒ–ï¼šä½ çš„è¯­è¨€æ¨¡å‹å…¶å®æ˜¯å¥–åŠ±æ¨¡å‹ã€‚*ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œ36ã€‚
- en: 'Rajpurkar etÂ al. (2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and
    Percy Liang. 2016. [SQuAD: 100,000+ questions for machine comprehension of text](https://doi.org/10.18653/v1/D16-1264).
    In *Proceedings of the 2016 Conference on Empirical Methods in Natural Language
    Processing*, pages 2383â€“2392, Austin, Texas. Association for Computational Linguistics.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rajpurkar et al. (2016) æ™®æ‹‰çº³å¤«Â·æ‹‰æœ±å°”å¡å°”ã€ç®€Â·å¼ ã€åº·æ–¯å¦ä¸Â·æ´›çš®è€¶å¤«å’Œç€è¥¿Â·æ¢ã€‚2016ã€‚ [SQuAD: 100,000+
    æœºå™¨æ–‡æœ¬ç†è§£é—®é¢˜](https://doi.org/10.18653/v1/D16-1264)ã€‚è§äº *2016å¹´è‡ªç„¶è¯­è¨€å¤„ç†å®è¯æ–¹æ³•ä¼šè®®*ï¼Œç¬¬2383â€“2392é¡µï¼Œç¾å›½å¾·å…‹è¨æ–¯å·å¥¥æ–¯æ±€ã€‚è®¡ç®—è¯­è¨€å­¦åä¼šã€‚'
- en: 'Rubin etÂ al. (2022) Ohad Rubin, Jonathan Herzig, and Jonathan Berant. 2022.
    [Learning to retrieve prompts for in-context learning](https://doi.org/10.18653/v1/2022.naacl-main.191).
    In *Proceedings of the 2022 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies*, pages 2655â€“2671,
    Seattle, United States. Association for Computational Linguistics.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rubin et al. (2022) å¥¥å“ˆå¾·Â·é²å®¾ã€ä¹”çº³æ£®Â·èµ«å°”é½å’Œä¹”çº³æ£®Â·è´å…°ç‰¹ã€‚2022ã€‚ [å­¦ä¹ æ£€ç´¢ä¸Šä¸‹æ–‡å­¦ä¹ çš„æç¤º](https://doi.org/10.18653/v1/2022.naacl-main.191)ã€‚è§äº
    *2022å¹´åŒ—ç¾è®¡ç®—è¯­è¨€å­¦åä¼šï¼šäººç±»è¯­è¨€æŠ€æœ¯ä¼šè®®*ï¼Œç¬¬2655â€“2671é¡µï¼Œç¾å›½è¥¿é›…å›¾ã€‚è®¡ç®—è¯­è¨€å­¦åä¼šã€‚
- en: 'Schulman (2023) John Schulman. 2023. [Reinforcement learning from human feedback:
    Progress and challenges](https://www.youtube.com/watch?v=hhiLw5Q_UFg&ab_channel=BerkeleyEECS).'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schulman (2023) çº¦ç¿°Â·èˆ’å°”æ›¼ã€‚2023ã€‚ [æ¥è‡ªäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼šè¿›å±•ä¸æŒ‘æˆ˜](https://www.youtube.com/watch?v=hhiLw5Q_UFg&ab_channel=BerkeleyEECS)ã€‚
- en: Sciavolino etÂ al. (2021) Christopher Sciavolino, Zexuan Zhong, Jinhyuk Lee,
    and Danqi Chen. 2021. [Simple entity-centric questions challenge dense retrievers](https://doi.org/10.18653/V1/2021.EMNLP-MAIN.496).
    In *Proceedings of the 2021 Conference on Empirical Methods in Natural Language
    Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November,
    2021*, pages 6138â€“6148\. Association for Computational Linguistics.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sciavolino et al. (2021) å…‹é‡Œæ–¯æ‰˜å¼—Â·è¥¿äºšæ²ƒåˆ©è¯ºã€æ³½è½©Â·é’Ÿã€æ™‹èµ«Â·æå’Œä¸¹çªÂ·é™ˆã€‚2021ã€‚ [ç®€å•çš„å®ä½“ä¸­å¿ƒé—®é¢˜æŒ‘æˆ˜å¯†é›†æ£€ç´¢å™¨](https://doi.org/10.18653/V1/2021.EMNLP-MAIN.496)ã€‚è§äº
    *2021å¹´è‡ªç„¶è¯­è¨€å¤„ç†å®è¯æ–¹æ³•ä¼šè®®ï¼ŒEMNLP 2021ï¼Œè™šæ‹Ÿæ´»åŠ¨/å¤šç±³å°¼åŠ å…±å’Œå›½è“¬å¡”å¡çº³ï¼Œ2021å¹´11æœˆ7-11æ—¥*ï¼Œç¬¬6138â€“6148é¡µã€‚è®¡ç®—è¯­è¨€å­¦åä¼šã€‚
- en: Tian etÂ al. (2023a) Katherine Tian, Eric Mitchell, Huaxiu Yao, ChristopherÂ D
    Manning, and Chelsea Finn. 2023a. Fine-tuning language models for factuality.
    *arXiv preprint arXiv:2311.08401*.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tian et al. (2023a) å‡¯ç‘Ÿç³Â·ç”°ã€åŸƒé‡Œå…‹Â·ç±³åˆ‡å°”ã€åç§€Â·å§šã€å…‹é‡Œæ–¯æ‰˜å¼—Â·DÂ·æ›¼å®å’Œåˆ‡å°”è¥¿Â·èŠ¬æ©ã€‚2023aã€‚ä¸ºäº‹å®æ€§å¾®è°ƒè¯­è¨€æ¨¡å‹ã€‚*arXiv
    é¢„å°æœ¬ arXiv:2311.08401*ã€‚
- en: 'Tian etÂ al. (2023b) Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma,
    Rafael Rafailov, Huaxiu Yao, Chelsea Finn, and ChristopherÂ D Manning. 2023b. Just
    ask for calibration: Strategies for eliciting calibrated confidence scores from
    language models fine-tuned with human feedback. *arXiv preprint arXiv:2305.14975*.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tian et al. (2023b) å‡¯ç‘Ÿç³Â·ç”°ã€åŸƒé‡Œå…‹Â·ç±³åˆ‡å°”ã€è‰¾ä¼¦Â·å‘¨ã€é˜¿å°”åŸºç‰¹Â·å¤å°”é©¬ã€æ‹‰æ–å°”Â·æ‹‰æ–æ´›å¤«ã€åç§€Â·å§šã€åˆ‡å°”è¥¿Â·èŠ¬æ©å’Œå…‹é‡Œæ–¯æ‰˜å¼—Â·DÂ·æ›¼å®ã€‚2023bã€‚åªéœ€è¯·æ±‚æ ¡å‡†ï¼šä»è¯­è¨€æ¨¡å‹ä¸­å¼•å‡ºæ ¡å‡†ä¿¡å¿ƒè¯„åˆ†çš„ç­–ç•¥ã€‚*arXiv
    é¢„å°æœ¬ arXiv:2305.14975*ã€‚
- en: 'VrandeÄiÄ‡ and KrÃ¶tzsch (2014) Denny VrandeÄiÄ‡ and Markus KrÃ¶tzsch. 2014. [Wikidata:
    a free collaborative knowledgebase](https://doi.org/10.1145/2629489). *Commun.
    ACM*, 57(10):78â€“85.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'VrandeÄiÄ‡ å’Œ KrÃ¶tzsch (2014) ä¸¹å°¼Â·å¼—å…°å¾·é½å¥‡å’Œé©¬åº“æ–¯Â·å…‹ç½—èŒ¨æ–½ã€‚2014ã€‚ [Wikidata: ä¸€ä¸ªå…è´¹çš„åä½œçŸ¥è¯†åº“](https://doi.org/10.1145/2629489)ã€‚*Commun.
    ACM*ï¼Œ57(10):78â€“85ã€‚'
- en: 'Wang etÂ al. (2023) Cunxiang Wang, Sirui Cheng, Qipeng Guo, Yuanhao Yue, Bowen
    Ding, Zhikun Xu, Yidong Wang, Xiangkun Hu, Zheng Zhang, and Yue Zhang. 2023. [Evaluating
    open-qa evaluation](http://papers.nips.cc/paper_files/paper/2023/hash/f323d594aa5d2c68154433a131c07959-Abstract-Datasets_and_Benchmarks.html).
    In *Advances in Neural Information Processing Systems 36: Annual Conference on
    Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA,
    December 10 - 16, 2023*.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang ç­‰äººï¼ˆ2023ï¼‰Cunxiang Wangã€Sirui Chengã€Qipeng Guoã€Yuanhao Yueã€Bowen Dingã€Zhikun
    Xuã€Yidong Wangã€Xiangkun Huã€Zheng Zhang å’Œ Yue Zhangã€‚2023å¹´ã€‚[è¯„ä¼°å¼€æ”¾é—®ç­”è¯„ä¼°](http://papers.nips.cc/paper_files/paper/2023/hash/f323d594aa5d2c68154433a131c07959-Abstract-Datasets_and_Benchmarks.html)ã€‚åœ¨*ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•
    36ï¼š2023å¹´åº¦ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿå¤§ä¼šï¼ŒNeurIPS 2023ï¼Œæ–°å¥¥å°”è‰¯ï¼ŒLAï¼Œç¾å›½ï¼Œ2023å¹´12æœˆ10-16æ—¥*ã€‚
- en: Wei etÂ al. (2022) Jason Wei, Maarten Bosma, VincentÂ Y. Zhao, Kelvin Guu, AdamsÂ Wei
    Yu, Brian Lester, Nan Du, AndrewÂ M. Dai, and QuocÂ V. Le. 2022. [Finetuned language
    models are zero-shot learners](https://openreview.net/forum?id=gEZrGCozdqR). In
    *The Tenth International Conference on Learning Representations, ICLR 2022, Virtual
    Event, April 25-29, 2022*. OpenReview.net.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei ç­‰äººï¼ˆ2022ï¼‰Jason Weiã€Maarten Bosmaã€Vincent Y. Zhaoã€Kelvin Guuã€Adams Wei Yuã€Brian
    Lesterã€Nan Duã€Andrew M. Dai å’Œ Quoc V. Leã€‚2022å¹´ã€‚[å¾®è°ƒè¯­è¨€æ¨¡å‹æ˜¯é›¶æ ·æœ¬å­¦ä¹ è€…](https://openreview.net/forum?id=gEZrGCozdqR)ã€‚åœ¨*ç¬¬åå±Šå›½é™…å­¦ä¹ è¡¨å¾å¤§ä¼šï¼ŒICLR
    2022ï¼Œè™šæ‹Ÿæ´»åŠ¨ï¼Œ2022å¹´4æœˆ25-29æ—¥*ã€‚OpenReview.netã€‚
- en: 'Yin etÂ al. (2023) Xunjian Yin, Baizhou Huang, and Xiaojun Wan. 2023. [ALCUNA:
    Large language models meet new knowledge](https://doi.org/10.18653/v1/2023.emnlp-main.87).
    In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language
    Processing*, pages 1397â€“1414, Singapore. Association for Computational Linguistics.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yin ç­‰äººï¼ˆ2023ï¼‰Xunjian Yinã€Baizhou Huang å’Œ Xiaojun Wanã€‚2023å¹´ã€‚[ALCUNAï¼šå¤§å‹è¯­è¨€æ¨¡å‹é‡è§æ–°çŸ¥è¯†](https://doi.org/10.18653/v1/2023.emnlp-main.87)ã€‚åœ¨*2023å¹´è‡ªç„¶è¯­è¨€å¤„ç†å®è¯æ–¹æ³•ä¼šè®®è®ºæ–‡é›†*ï¼Œç¬¬1397â€“1414é¡µï¼Œæ–°åŠ å¡ã€‚è®¡ç®—è¯­è¨€å­¦åä¼šã€‚
- en: 'Yona etÂ al. (2024) Gal Yona, Roee Aharoni, and Mor Geva. 2024. Narrowing the
    knowledge evaluation gap: Open-domain question answering with multi-granularity
    answers. *arXiv preprint arXiv:2401.04695*.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yona ç­‰äººï¼ˆ2024ï¼‰Gal Yonaã€Roee Aharoni å’Œ Mor Gevaã€‚2024å¹´ã€‚ç¼©å°çŸ¥è¯†è¯„ä¼°å·®è·ï¼šå…·æœ‰å¤šç²’åº¦ç­”æ¡ˆçš„å¼€æ”¾é¢†åŸŸé—®ç­”ã€‚*arXiv
    é¢„å°æœ¬ arXiv:2401.04695*ã€‚
- en: 'Zhang etÂ al. (2023) Hanning Zhang, Shizhe Diao, Yong Lin, YiÂ R Fung, Qing Lian,
    Xingyao Wang, Yangyi Chen, Heng Ji, and Tong Zhang. 2023. R-tuning: Teaching large
    language models to refuse unknown questions. *arXiv preprint arXiv:2311.09677*.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang ç­‰äººï¼ˆ2023ï¼‰Hanning Zhangã€Shizhe Diaoã€Yong Linã€Yi R Fungã€Qing Lianã€Xingyao
    Wangã€Yangyi Chenã€Heng Ji å’Œ Tong Zhangã€‚2023å¹´ã€‚R-tuningï¼šæ•™å¤§å‹è¯­è¨€æ¨¡å‹æ‹’ç»æœªçŸ¥é—®é¢˜ã€‚*arXiv é¢„å°æœ¬
    arXiv:2311.09677*ã€‚
- en: 'Zhou etÂ al. (2023) Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao
    Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, Susan Zhang, Gargi Ghosh,
    Mike Lewis, Luke Zettlemoyer, and Omer Levy. 2023. [LIMA: less is more for alignment](http://papers.nips.cc/paper_files/paper/2023/hash/ac662d74829e4407ce1d126477f4a03a-Abstract-Conference.html).
    In *Advances in Neural Information Processing Systems 36: Annual Conference on
    Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA,
    December 10 - 16, 2023*.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou ç­‰äººï¼ˆ2023ï¼‰Chunting Zhouã€Pengfei Liuã€Puxin Xuã€Srinivasan Iyerã€Jiao Sunã€Yuning
    Maoã€Xuezhe Maã€Avia Efratã€Ping Yuã€Lili Yuã€Susan Zhangã€Gargi Ghoshã€Mike Lewisã€Luke
    Zettlemoyer å’Œ Omer Levyã€‚2023å¹´ã€‚[LIMAï¼šå¯¹é½çš„â€œå°‘å³æ˜¯å¤šâ€](http://papers.nips.cc/paper_files/paper/2023/hash/ac662d74829e4407ce1d126477f4a03a-Abstract-Conference.html)ã€‚åœ¨*ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•
    36ï¼š2023å¹´åº¦ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿå¤§ä¼šï¼ŒNeurIPS 2023ï¼Œæ–°å¥¥å°”è‰¯ï¼ŒLAï¼Œç¾å›½ï¼Œ2023å¹´12æœˆ10-16æ—¥*ã€‚
- en: Appendix A Data Preprocessing
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½• A æ•°æ®é¢„å¤„ç†
- en: '| relation | question template | $\mathtt{HighlyKnown}$ | $\mathtt{WeaklyKnown}$
    | Total | Min |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| relation | question template | $\mathtt{HighlyKnown}$ | $\mathtt{WeaklyKnown}$
    | Total | Min |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| P131 | Where is [E] located? | 553 | 2529 | 1493 | 3071 | 7646 | 553 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| P131 | [E] ä½äºå“ªé‡Œï¼Ÿ | 553 | 2529 | 1493 | 3071 | 7646 | 553 |'
- en: '| P136 | What type of music does [E] play? | 236 | 3410 | 1892 | 1978 | 7516
    | 236 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| P136 | [E] æ¼”å¥ä»€ä¹ˆç±»å‹çš„éŸ³ä¹ï¼Ÿ | 236 | 3410 | 1892 | 1978 | 7516 | 236 |'
- en: '| P17 | Which country is [E] located in? | 4387 | 2628 | 511 | 364 | 7890 |
    364 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| P17 | [E] ä½äºå“ªä¸ªå›½å®¶ï¼Ÿ | 4387 | 2628 | 511 | 364 | 7890 | 364 |'
- en: '| P19 | Where was [E] born? | 369 | 1884 | 1498 | 4170 | 7921 | 369 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| P19 | [E] å‡ºç”Ÿåœ¨å“ªé‡Œï¼Ÿ | 369 | 1884 | 1498 | 4170 | 7921 | 369 |'
- en: '| P26 | Who is [E] married to? | 1609 | 1503 | 1087 | 3257 | 7456 | 1087 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| P26 | [E] ç»“å©šå¯¹è±¡æ˜¯è°ï¼Ÿ | 1609 | 1503 | 1087 | 3257 | 7456 | 1087 |'
- en: '| P264 | What music label is [E] represented by? | 206 | 1444 | 1854 | 3820
    | 7324 | 206 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| P264 | [E] ç”±å“ªä¸ªéŸ³ä¹æ ‡ç­¾ä»£è¡¨ï¼Ÿ | 206 | 1444 | 1854 | 3820 | 7324 | 206 |'
- en: '| P36 | What is the capital of [E]? | 4160 | 1634 | 449 | 572 | 6815 | 449
    |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| P36 | [E] çš„é¦–éƒ½æ˜¯ä»€ä¹ˆï¼Ÿ | 4160 | 1634 | 449 | 572 | 6815 | 449 |'
- en: '| P40 | Who is [E]â€™s child? | 692 | 1467 | 1271 | 2680 | 6110 | 692 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| P40 | [E] çš„å­©å­æ˜¯è°ï¼Ÿ | 692 | 1467 | 1271 | 2680 | 6110 | 692 |'
- en: '| P495 | Which country was [E] created in? | 5459 | 1101 | 408 | 706 | 7674
    | 408 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| P495 | [E] æ˜¯åœ¨å“ªä¸ªå›½å®¶åˆ›ç«‹çš„ï¼Ÿ | 5459 | 1101 | 408 | 706 | 7674 | 408 |'
- en: '| P69 | Where was [E] educated? | 233 | 1126 | 1712 | 3650 | 6721 | 233 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| P69 | [E] çš„æ•™è‚²èƒŒæ™¯æ˜¯ä»€ä¹ˆï¼Ÿ | 233 | 1126 | 1712 | 3650 | 6721 | 233 |'
- en: '| P740 | Where was [E] founded? | 1323 | 1618 | 1428 | 2902 | 7271 | 1323 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| P740 | [E] çš„åˆ›ç«‹åœ°ç‚¹åœ¨å“ªé‡Œï¼Ÿ | 1323 | 1618 | 1428 | 2902 | 7271 | 1323 |'
- en: '| P800 | What is [E] famous for? | 301 | 330 | 222 | 503 | 1356 | 222 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| P800 | [E] å› ä½•é—»åï¼Ÿ | 301 | 330 | 222 | 503 | 1356 | 222 |'
- en: '| TOTAL | - | 19528 | 20674 | 13825 | 27673 | 81700 | 6142 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| æ€»è®¡ | - | 19528 | 20674 | 13825 | 27673 | 81700 | 6142 |'
- en: 'Table 3: Statistics of the EntityQuestions train split annotated with SliCK
    categories. We annotate the entire train split but always fine-tune on exactly
    6142 examples (see the Min column). Refer to Â§[E](#A5 "Appendix E Fine-tuning
    Details â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") for
    more details.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 'è¡¨ 3: æ ‡æ³¨äº† SliCK ç±»åˆ«çš„ EntityQuestions è®­ç»ƒæ•°æ®é›†ç»Ÿè®¡æ•°æ®ã€‚æˆ‘ä»¬å¯¹æ•´ä¸ªè®­ç»ƒé›†è¿›è¡Œäº†æ ‡æ³¨ï¼Œä½†æ€»æ˜¯å¯¹ç¡®åˆ‡çš„ 6142 ä¸ªæ ·æœ¬è¿›è¡Œå¾®è°ƒï¼ˆå‚è§
    Min åˆ—ï¼‰ã€‚æ›´å¤šç»†èŠ‚è¯·å‚è§ Â§[E](#A5 "é™„å½• E å¾®è°ƒç»†èŠ‚ â€£ å¾®è°ƒ LLM åœ¨æ–°çŸ¥è¯†ä¸Šçš„å½±å“æ˜¯å¦ä¼šå¯¼è‡´è™šå‡ä¿¡æ¯ï¼Ÿ")ã€‚'
- en: '| relation | question template | $\mathtt{HighlyKnown}$ | $\mathtt{WeaklyKnown}$
    | Total |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| å…³ç³» | é—®é¢˜æ¨¡æ¿ | $\mathtt{HighlyKnown}$ | $\mathtt{WeaklyKnown}$ | æ€»è®¡ |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| P131 | Where is [E] located? | 57 | 362 | 158 | 388 | 965 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| P131 | [E] ä½äºå“ªé‡Œï¼Ÿ | 57 | 362 | 158 | 388 | 965 |'
- en: '| P136 | What type of music does [E] play? | 6 | 432 | 248 | 281 | 967 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| P136 | [E] æ¼”å¥å“ªç§ç±»å‹çš„éŸ³ä¹ï¼Ÿ | 6 | 432 | 248 | 281 | 967 |'
- en: '| P17 | Which country is [E] located in? | 448 | 432 | 65 | 51 | 996 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| P17 | [E] ä½äºå“ªä¸ªå›½å®¶ï¼Ÿ | 448 | 432 | 65 | 51 | 996 |'
- en: '| P19 | Where was [E] born? | 107 | 148 | 243 | 501 | 999 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| P19 | [E] çš„å‡ºç”Ÿåœ°åœ¨å“ªé‡Œï¼Ÿ | 107 | 148 | 243 | 501 | 999 |'
- en: '| P26 | Who is [E] married to? | 177 | 238 | 158 | 378 | 951 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| P26 | [E] çš„é…å¶æ˜¯è°ï¼Ÿ | 177 | 238 | 158 | 378 | 951 |'
- en: '| P264 | What music label is [E] represented by? | 47 | 157 | 268 | 486 | 958
    |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| P264 | [E] ç”±å“ªä¸ªéŸ³ä¹æ ‡ç­¾ä»£è¡¨ï¼Ÿ | 47 | 157 | 268 | 486 | 958 |'
- en: '| P36 | What is the capital of [E]? | 580 | 152 | 62 | 86 | 880 |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| P36 | [E] çš„é¦–éƒ½æ˜¯ä»€ä¹ˆï¼Ÿ | 580 | 152 | 62 | 86 | 880 |'
- en: '| P40 | Who is [E]â€™s child? | 99 | 191 | 167 | 344 | 801 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| P40 | [E] çš„å­©å­æ˜¯è°ï¼Ÿ | 99 | 191 | 167 | 344 | 801 |'
- en: '| P495 | Which country was [E] created in? | 699 | 147 | 51 | 96 | 993 |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| P495 | [E] æ˜¯åœ¨å“ªä¸ªå›½å®¶åˆ›ç«‹çš„ï¼Ÿ | 699 | 147 | 51 | 96 | 993 |'
- en: '| P69 | Where was [E] educated? | 27 | 145 | 227 | 441 | 840 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| P69 | [E] çš„æ•™è‚²èƒŒæ™¯æ˜¯ä»€ä¹ˆï¼Ÿ | 27 | 145 | 227 | 441 | 840 |'
- en: '| P740 | Where was [E] founded? | 182 | 245 | 181 | 334 | 942 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| P740 | [E] çš„åˆ›ç«‹åœ°ç‚¹åœ¨å“ªé‡Œï¼Ÿ | 182 | 245 | 181 | 334 | 942 |'
- en: '| P800 | What is [E] famous for? | 35 | 50 | 28 | 76 | 189 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| P800 | [E] å› ä½•é—»åï¼Ÿ | 35 | 50 | 28 | 76 | 189 |'
- en: '| TOTAL | - | 2464 | 2699 | 1856 | 3462 | 10481 |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| æ€»è®¡ | - | 2464 | 2699 | 1856 | 3462 | 10481 |'
- en: 'Table 4: In-distribution test set statistics.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 'è¡¨ 4: åˆ†å¸ƒå†…æµ‹è¯•é›†ç»Ÿè®¡æ•°æ®ã€‚'
- en: '| relation | question template | $\mathtt{HighlyKnown}$ | $\mathtt{WeaklyKnown}$
    | Total |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| å…³ç³» | é—®é¢˜æ¨¡æ¿ | $\mathtt{HighlyKnown}$ | $\mathtt{WeaklyKnown}$ | æ€»è®¡ |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| P127 | Who owns [E]? | 125 | 383 | 168 | 314 | 990 |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| P127 | è°æ‹¥æœ‰ [E]ï¼Ÿ | 125 | 383 | 168 | 314 | 990 |'
- en: '| P50 | Who is the author of [E]? | 287 | 193 | 115 | 372 | 967 |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| P50 | [E] çš„ä½œè€…æ˜¯è°ï¼Ÿ | 287 | 193 | 115 | 372 | 967 |'
- en: '| P407 | Which language was [E] written in? | 366 | 153 | 59 | 45 | 623 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| P407 | [E] æ˜¯ç”¨ä»€ä¹ˆè¯­è¨€å†™çš„ï¼Ÿ | 366 | 153 | 59 | 45 | 623 |'
- en: '| P176 | Which company is [E] produced by? | 289 | 277 | 181 | 225 | 972 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| P176 | [E] æ˜¯å“ªä¸ªå…¬å¸ç”Ÿäº§çš„ï¼Ÿ | 289 | 277 | 181 | 225 | 972 |'
- en: '| P170 | Who was [E] created by? | 142 | 284 | 120 | 304 | 850 |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| P170 | [E] ç”±è°åˆ›ä½œï¼Ÿ | 142 | 284 | 120 | 304 | 850 |'
- en: '| P175 | Who performed [E]? | 94 | 120 | 103 | 663 | 980 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| P175 | è°è¡¨æ¼”äº† [E]ï¼Ÿ | 94 | 120 | 103 | 663 | 980 |'
- en: '| P112 | Who founded [E]? | 134 | 116 | 76 | 140 | 466 |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| P112 | è°åˆ›ç«‹äº† [E]ï¼Ÿ | 134 | 116 | 76 | 140 | 466 |'
- en: '| TOTAL | - | 1437 | 1526 | 822 | 2063 | 5848 |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| æ€»è®¡ | - | 1437 | 1526 | 822 | 2063 | 5848 |'
- en: 'Table 5: Out-of-distribution test set statistics.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 'è¡¨ 5: åˆ†å¸ƒå¤–æµ‹è¯•é›†ç»Ÿè®¡æ•°æ®ã€‚'
- en: This section expands Â§[2](#S2 "2 Study Setup â€£ Does Fine-Tuning LLMs on New
    Knowledge Encourage Hallucinations?") with additional details about our data preprocessing
    steps. The EntityQuestions dataset Sciavolino etÂ al. ([2021](#bib.bib25)) consists
    of train, development and test splits and spans 24 relations. Our train, development
    and test sets are curated based on the original splits from EntityQuestions. However,
    we use only 12 relations, since we wanted to reserve some relations for out-of-distribution
    test set. To avoid cherry-picking, the 12 relations used in our train, development
    and test sets are randomly sampled. The resulting relations are presented in Tables
    [3](#A1.T3 "Table 3 â€£ Appendix A Data Preprocessing â€£ Does Fine-Tuning LLMs on
    New Knowledge Encourage Hallucinations?") and [4](#A1.T4 "Table 4 â€£ Appendix A
    Data Preprocessing â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬èŠ‚æ‰©å±•äº† Â§[2](#S2 "2 ç ”ç©¶è®¾ç½® â€£ å¯¹æ–°çŸ¥è¯†è¿›è¡Œå¾®è°ƒçš„ LLM æ˜¯å¦ä¼šå¼•å‘å¹»è§‰ï¼Ÿ")ï¼Œæä¾›äº†æœ‰å…³æˆ‘ä»¬çš„æ•°æ®é¢„å¤„ç†æ­¥éª¤çš„æ›´å¤šç»†èŠ‚ã€‚EntityQuestions
    æ•°æ®é›† Sciavolino ç­‰äºº ([2021](#bib.bib25)) åŒ…å«è®­ç»ƒã€å¼€å‘å’Œæµ‹è¯•åˆ†å‰²ï¼Œå¹¶æ¶µç›–äº† 24 ä¸ªå…³ç³»ã€‚æˆ‘ä»¬çš„è®­ç»ƒã€å¼€å‘å’Œæµ‹è¯•é›†æ˜¯åŸºäº
    EntityQuestions çš„åŸå§‹åˆ†å‰²è¿›è¡Œæ•´ç†çš„ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬åªä½¿ç”¨äº† 12 ä¸ªå…³ç³»ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³ä¿ç•™ä¸€äº›å…³ç³»ç”¨äºåˆ†å¸ƒå¤–æµ‹è¯•é›†ã€‚ä¸ºäº†é¿å…æŒ‘é€‰ï¼Œè®­ç»ƒã€å¼€å‘å’Œæµ‹è¯•é›†ä¸­ä½¿ç”¨çš„
    12 ä¸ªå…³ç³»æ˜¯éšæœºæŠ½æ ·çš„ã€‚ç»“æœå…³ç³»è§è¡¨ [3](#A1.T3 "è¡¨ 3 â€£ é™„å½• A æ•°æ®é¢„å¤„ç† â€£ å¯¹æ–°çŸ¥è¯†è¿›è¡Œå¾®è°ƒçš„ LLM æ˜¯å¦ä¼šå¼•å‘å¹»è§‰ï¼Ÿ") å’Œ
    [4](#A1.T4 "è¡¨ 4 â€£ é™„å½• A æ•°æ®é¢„å¤„ç† â€£ å¯¹æ–°çŸ¥è¯†è¿›è¡Œå¾®è°ƒçš„ LLM æ˜¯å¦ä¼šå¼•å‘å¹»è§‰ï¼Ÿ")ã€‚
- en: 'We reserved the remaining 12 relations for out-of-distribution test set. However,
    we found that in those 12 reserved relations, 5 were too similar to some of the
    relations that we train on (Table [3](#A1.T3 "Table 3 â€£ Appendix A Data Preprocessing
    â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")), thus we
    suspected that this could lead to a test set that is not truly out-of-distribution.
    To address that, we filtered out those relations and were left with 7 relations
    for our-of-distribution. Specifically we filtered-out the following relations:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¿ç•™äº†å…¶ä½™çš„ 12 ä¸ªå…³ç³»ç”¨äºåˆ†å¸ƒå¤–æµ‹è¯•é›†ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°è¿™ 12 ä¸ªä¿ç•™çš„å…³ç³»ä¸­ï¼Œæœ‰ 5 ä¸ªä¸æˆ‘ä»¬è®­ç»ƒä¸­çš„ä¸€äº›å…³ç³»è¿‡äºç›¸ä¼¼ï¼ˆè§è¡¨ [3](#A1.T3
    "è¡¨ 3 â€£ é™„å½• A æ•°æ®é¢„å¤„ç† â€£ å¯¹æ–°çŸ¥è¯†è¿›è¡Œå¾®è°ƒçš„ LLM æ˜¯å¦ä¼šå¼•å‘å¹»è§‰ï¼Ÿ")ï¼‰ï¼Œå› æ­¤æˆ‘ä»¬æ€€ç–‘è¿™å¯èƒ½å¯¼è‡´æµ‹è¯•é›†ä¸å®Œå…¨æ˜¯åˆ†å¸ƒå¤–çš„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ç­›é™¤äº†è¿™äº›å…³ç³»ï¼Œæœ€ç»ˆä¿ç•™äº†
    7 ä¸ªå…³ç³»ç”¨äºåˆ†å¸ƒå¤–æµ‹è¯•é›†ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç­›é™¤äº†ä»¥ä¸‹å…³ç³»ï¼š
- en: â€¢
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: P276 was filtered out since it directly overlaps with P131 since for both relations
    the question in EntityQuestions is of the form â€œWhere is [E] located?â€. P276 stands
    for â€œlocationâ€ ([https://www.wikidata.org/wiki/Property:P276](https://www.wikidata.org/wiki/Property:P276))
    and P131 stands for â€œlocated in the administrative territorial entityâ€ ([https://www.wikidata.org/wiki/Property:P131](https://www.wikidata.org/wiki/Property:P131)).
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: P276 è¢«ç­›é™¤ï¼Œå› ä¸ºå®ƒä¸ P131 ç›´æ¥é‡å ï¼Œä¸¤è€…çš„é—®å¥éƒ½æ˜¯â€œ[E] ä½äºä½•å¤„ï¼Ÿâ€ P276 ä»£è¡¨â€œä½ç½®â€ ([https://www.wikidata.org/wiki/Property:P276](https://www.wikidata.org/wiki/Property:P276))ï¼Œè€Œ
    P131 ä»£è¡¨â€œä½äºè¡Œæ”¿åŒºåˆ’å®ä½“ä¸­â€ ([https://www.wikidata.org/wiki/Property:P131](https://www.wikidata.org/wiki/Property:P131))ã€‚
- en: â€¢
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: P20, for which the question template is *â€œWhere did [E] die?â€*, was filtered
    out since it may require knowledge that relates to P19, for which the question
    template is *â€œWhere was [E] born?â€*. P20 stands for â€œplace of deathâ€ ([https://www.wikidata.org/wiki/Property:P20](https://www.wikidata.org/wiki/Property:P20))
    and P19 stands for â€œplace of birthâ€ ([https://www.wikidata.org/wiki/Property:P19](https://www.wikidata.org/wiki/Property:P19)).
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: P20ï¼Œå…¶é—®é¢˜æ¨¡æ¿ä¸º*â€œ[E] æ­»äºä½•å¤„ï¼Ÿâ€*ï¼Œè¢«ç­›é™¤ï¼Œå› ä¸ºå®ƒå¯èƒ½éœ€è¦ä¸ P19 ç›¸å…³çš„çŸ¥è¯†ï¼Œè€Œ P19 çš„é—®é¢˜æ¨¡æ¿æ˜¯*â€œ[E] å‡ºç”Ÿäºä½•å¤„ï¼Ÿâ€*ã€‚P20
    ä»£è¡¨â€œæ­»äº¡åœ°ç‚¹â€ ([https://www.wikidata.org/wiki/Property:P20](https://www.wikidata.org/wiki/Property:P20))ï¼Œè€Œ
    P19 ä»£è¡¨â€œå‡ºç”Ÿåœ°ç‚¹â€ ([https://www.wikidata.org/wiki/Property:P19](https://www.wikidata.org/wiki/Property:P19))ã€‚
- en: â€¢
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: P106, for which the question template is *â€œWhat kind of work does [E] do?â€*,
    was filtered out since it may require knowledge that relates to P800, for which
    the question template is *â€œWhat is [E] famous for?â€*. P106 stands for â€œoccupationâ€
    ([https://www.wikidata.org/wiki/Property:P106](https://www.wikidata.org/wiki/Property:P106))
    and P800 stands for â€œnotable workâ€ ([https://www.wikidata.org/wiki/Property:P800](https://www.wikidata.org/wiki/Property:P800)).
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: P106ï¼Œå…¶é—®é¢˜æ¨¡æ¿ä¸º*â€œ[E] ä»äº‹ä»€ä¹ˆå·¥ä½œï¼Ÿâ€*ï¼Œè¢«ç­›é™¤ï¼Œå› ä¸ºå®ƒå¯èƒ½éœ€è¦ä¸ P800 ç›¸å…³çš„çŸ¥è¯†ï¼Œè€Œ P800 çš„é—®é¢˜æ¨¡æ¿æ˜¯*â€œ[E] å› ä»€ä¹ˆè€Œè‘—åï¼Ÿâ€*ã€‚P106
    ä»£è¡¨â€œèŒä¸šâ€ ([https://www.wikidata.org/wiki/Property:P106](https://www.wikidata.org/wiki/Property:P106))ï¼Œè€Œ
    P800 ä»£è¡¨â€œè‘—åä½œå“â€ ([https://www.wikidata.org/wiki/Property:P800](https://www.wikidata.org/wiki/Property:P800))ã€‚
- en: â€¢
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: P413, for which the question template is *â€œWhat position does [E] play?â€*, was
    filtered out since it may require knowledge that relates to P800, for which the
    question template is *â€œWhat is [E] famous for?â€*. P413 stands for â€œposition played
    on team / specialityâ€ ([https://www.wikidata.org/wiki/Property:P413](https://www.wikidata.org/wiki/Property:P413))
    and P800 stands for â€œnotable workâ€ ([https://www.wikidata.org/wiki/Property:P800](https://www.wikidata.org/wiki/Property:P800)).
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: P413ï¼Œé—®é¢˜æ¨¡æ¿ä¸º*â€œ[E]çš„èŒä½æ˜¯ä»€ä¹ˆï¼Ÿâ€*ï¼Œè¢«ç­›é™¤ï¼Œå› ä¸ºå®ƒå¯èƒ½éœ€è¦ä¸P800ç›¸å…³çš„çŸ¥è¯†ï¼ŒP800çš„é—®ç­”æ¨¡æ¿æ˜¯*â€œ[E]å› ä¸ºä»€ä¹ˆè€Œé—»åï¼Ÿâ€*ã€‚P413
    ä»£è¡¨â€œçƒé˜Ÿä¸Šçš„èŒä½/ä¸“é•¿â€ ([https://www.wikidata.org/wiki/Property:P413](https://www.wikidata.org/wiki/Property:P413))ï¼Œè€Œ
    P800 ä»£è¡¨â€œè‘—åä½œå“â€ ([https://www.wikidata.org/wiki/Property:P800](https://www.wikidata.org/wiki/Property:P800))ã€‚
- en: â€¢
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: P159, for which the question template is *â€œWhere is the headquarters of [E]?â€*,
    was filtered out since it may require knowledge that relates to P36, for which
    the question template is *â€œWhat is the capital of [E]?â€*. P159 stands for â€œheadquarters
    locationâ€ ([https://www.wikidata.org/wiki/Property:P159](https://www.wikidata.org/wiki/Property:P159))
    and P36 stands for â€œcapitalâ€ ([https://www.wikidata.org/wiki/Property:P36](https://www.wikidata.org/wiki/Property:P36)).
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: P159ï¼Œé—®é¢˜æ¨¡æ¿ä¸º*â€œ[E]çš„æ€»éƒ¨åœ¨å“ªé‡Œï¼Ÿâ€*ï¼Œè¢«ç­›é™¤ï¼Œå› ä¸ºå®ƒå¯èƒ½éœ€è¦ä¸P36ç›¸å…³çš„çŸ¥è¯†ï¼ŒP36çš„é—®ç­”æ¨¡æ¿æ˜¯*â€œ[E]çš„é¦–éƒ½æ˜¯ä»€ä¹ˆï¼Ÿâ€*ã€‚P159ä»£è¡¨â€œæ€»éƒ¨ä½ç½®â€
    ([https://www.wikidata.org/wiki/Property:P159](https://www.wikidata.org/wiki/Property:P159))ï¼Œè€Œ
    P36 ä»£è¡¨â€œé¦–éƒ½â€ ([https://www.wikidata.org/wiki/Property:P36](https://www.wikidata.org/wiki/Property:P36))ã€‚
- en: The 7 relations used for out-of-distribution test set are presented in [TableÂ 5](#A1.T5
    "In Appendix A Data Preprocessing â€£ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?").
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºåˆ†å¸ƒå¤–æµ‹è¯•é›†çš„7ä¸ªå…³ç³»è§[è¡¨ 5](#A1.T5 "é™„å½• A æ•°æ®é¢„å¤„ç† â€£ å¯¹æ–°çŸ¥è¯†è¿›è¡Œå¾®è°ƒæ˜¯å¦ä¼šé¼“åŠ±å¹»è§‰ï¼Ÿ")ã€‚
- en: 'Lastly, we perform two additional filtering steps: (1) To simplify the process
    of categorizing the examples w.r.t. $M$ and $3.9\%$ and $P413$ of the EntityQuestions
    train set.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬è¿›è¡Œä¸¤ä¸ªé¢å¤–çš„è¿‡æ»¤æ­¥éª¤ï¼šï¼ˆ1ï¼‰ä¸ºäº†ç®€åŒ–å¯¹$M$å’Œ$3.9\%$ä»¥åŠEntityQuestionsè®­ç»ƒé›†ä¸­çš„P413ç¤ºä¾‹çš„åˆ†ç±»è¿‡ç¨‹ã€‚
- en: Appendix B Test performance as Proxy for Hallucinations
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½• B æµ‹è¯•æ€§èƒ½ä½œä¸ºå¹»è§‰çš„ä»£ç†
- en: We now detail the relation between the test performance in our setting and hallucinations.
    In our study, poorer performance of a fine-tuned model $M_{D1}$ on the test set,
    can be attributed to a higher rate of hallucinations in $M_{D1}$, relative to
    its pre-existing knowledge, due to the following explanation.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨è¯¦ç»†æè¿°æˆ‘ä»¬è®¾ç½®ä¸­æµ‹è¯•æ€§èƒ½ä¸å¹»è§‰ä¹‹é—´çš„å…³ç³»ã€‚åœ¨æˆ‘ä»¬çš„ç ”ç©¶ä¸­ï¼Œå¾®è°ƒæ¨¡å‹$M_{D1}$åœ¨æµ‹è¯•é›†ä¸Šçš„è¾ƒå·®è¡¨ç°å¯ä»¥å½’å› äº$M_{D1}$ä¸­å¹»è§‰çš„å‘ç”Ÿç‡ç›¸å¯¹äºå…¶å·²æœ‰çŸ¥è¯†è¾ƒé«˜ï¼ŒåŸå› å¦‚ä¸‹ã€‚
- en: The test set can be conceptually divided into two types of questions. First,
    there are questions with answers that are unknown to $M$ and $M_{D2}$ and $M_{D2}$,
    i.e. $M$ and $M_{D2}$ must rely on their pre-existing knowledge to answer such
    questions, and a lower performance on such question can be only categorized as
    an hallucination w.r.t. pre-existing knowledge.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: æµ‹è¯•é›†å¯ä»¥ä»æ¦‚å¿µä¸Šåˆ†ä¸ºä¸¤ç§é—®é¢˜ç±»å‹ã€‚é¦–å…ˆï¼Œå­˜åœ¨ä¸€äº›é—®é¢˜çš„ç­”æ¡ˆæ˜¯$M$å’Œ$M_{D2}$æœªçŸ¥çš„ï¼Œå³$M$å’Œ$M_{D2}$å¿…é¡»ä¾èµ–äºå…¶å·²æœ‰çŸ¥è¯†æ¥å›ç­”è¿™äº›é—®é¢˜ï¼Œä¸”åœ¨è¿™ç§é—®é¢˜ä¸Šè¡¨ç°è¾ƒå·®åªèƒ½å½’ç±»ä¸ºç›¸å¯¹äºå·²æœ‰çŸ¥è¯†çš„å¹»è§‰ã€‚
- en: Appendix C $\bm{P_{\bm{\mathtt{Correct}}}}$ Approximation
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½• C $\bm{P_{\bm{\mathtt{Correct}}}}$ è¿‘ä¼¼
- en: This section expands Â§[3](#S3 "3 Quantifying Knowledge in LLMs â€£ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?") with additional details about
    our $P_{\mathtt{Correct}}$ based on the fraction of correct answers to $q$. We
    begin with randomly sampling $N_{\text{ex}}$-shot exemplars for each relation
    in our dataset (Â§[A](#A1 "Appendix A Data Preprocessing â€£ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?")). Then, to approximate $P_{\mathtt{Correct}}(q,a;M,T)$
    to generate answers to $q$ exemplars from the relation corresponding to $q$ to
    sample $N_{\text{sample}}$ exemplars. $P_{\mathtt{Correct}}(q,a;M,T> predictions.
    We also generate the greedy decoding prediction (<math id=$ exemplars. $P_{\mathtt{Correct}}(q,a;M,T=0)$
    predictions.^(13)^(13)13Since we can only have one greedy prediction for every
    k-shot exemplars.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬èŠ‚æ‰©å±•äº†Â§[3](#S3 "3 é‡åŒ– LLM ä¸­çš„çŸ¥è¯† â€£ å¯¹æ–°çŸ¥è¯†è¿›è¡Œå¾®è°ƒæ˜¯å¦ä¼šé¼“åŠ±å¹»è§‰ï¼Ÿ")ï¼Œå¢åŠ äº†å…³äºæˆ‘ä»¬åŸºäºæ­£ç¡®ç­”æ¡ˆæ¯”ä¾‹çš„$P_{\mathtt{Correct}}$çš„é¢å¤–ç»†èŠ‚ã€‚æˆ‘ä»¬é¦–å…ˆä¸ºæ•°æ®é›†ä¸­çš„æ¯ä¸ªå…³ç³»éšæœºæŠ½å–$N_{\text{ex}}$-shot
    ç¤ºä¾‹ (Â§[A](#A1 "é™„å½• A æ•°æ®é¢„å¤„ç† â€£ å¯¹æ–°çŸ¥è¯†è¿›è¡Œå¾®è°ƒæ˜¯å¦ä¼šé¼“åŠ±å¹»è§‰ï¼Ÿ"))ã€‚ç„¶åï¼Œä¸ºäº†è¿‘ä¼¼$P_{\mathtt{Correct}}(q,a;M,T)$ï¼Œä»ä¸$q$ç›¸å…³çš„å…³ç³»ä¸­ç”Ÿæˆå¯¹$q$çš„ç­”æ¡ˆï¼ŒæŠ½å–$N_{\text{sample}}$
    ç¤ºä¾‹ã€‚$P_{\mathtt{Correct}}(q,a;M,T)$çš„é¢„æµ‹ã€‚æˆ‘ä»¬è¿˜ç”Ÿæˆè´ªå©ªè§£ç é¢„æµ‹ï¼ˆ<math id=$ ç¤ºä¾‹ã€‚$P_{\mathtt{Correct}}(q,a;M,T=0)$
    é¢„æµ‹ã€‚^(13)^(13)13ç”±äºæˆ‘ä»¬æ¯ä¸ªk-shotç¤ºä¾‹åªèƒ½æœ‰ä¸€ä¸ªè´ªå©ªé¢„æµ‹ã€‚
- en: We use $k=4$ to output answers in the correct format. We use $N_{\text{ex}}=10$.
    The $N_{\text{sample}}=16$ are sampled from Top 40.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨$k=4$æ¥ä»¥æ­£ç¡®æ ¼å¼è¾“å‡ºç­”æ¡ˆã€‚æˆ‘ä»¬ä½¿ç”¨$N_{\text{ex}}=10$ã€‚$N_{\text{sample}}=16$ä»å‰40åä¸­é‡‡æ ·ã€‚
- en: The $k$ different samples since we found that even when the few-shot exemplars
    are sampled per-relation, their exact choice still affects the prediction. In
    Â§[6](#S6 "6 SliCK Knowledge Categories Analysis â€£ Does Fine-Tuning LLMs on New
    Knowledge Encourage Hallucinations?") and [FigureÂ 5](#S6.F5 "In Fine-grained Known
    Categories â€£ 6 SliCK Knowledge Categories Analysis â€£ Does Fine-Tuning LLMs on
    New Knowledge Encourage Hallucinations?") we show evidence that this also improves
    the quality of our categories.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‘ç°ï¼Œå³ä½¿åœ¨æ¯ç§å…³ç³»ä¸Šé‡‡æ ·å°‘é‡ç¤ºä¾‹æ—¶ï¼Œè¿™$k$ä¸ªä¸åŒçš„æ ·æœ¬çš„ç¡®åˆ‡é€‰æ‹©ä»ç„¶ä¼šå½±å“é¢„æµ‹ã€‚åœ¨Â§[6](#S6 "6 SliCK çŸ¥è¯†ç±»åˆ«åˆ†æ â€£ å¾®è°ƒLLMsä»¥å­¦ä¹ æ–°çŸ¥è¯†æ˜¯å¦ä¼šå¼•å‘å¹»è§‰ï¼Ÿ")å’Œ[å›¾5](#S6.F5
    "åœ¨ç»†ç²’åº¦å·²çŸ¥ç±»åˆ« â€£ 6 SliCK çŸ¥è¯†ç±»åˆ«åˆ†æ â€£ å¾®è°ƒLLMsä»¥å­¦ä¹ æ–°çŸ¥è¯†æ˜¯å¦ä¼šå¼•å‘å¹»è§‰ï¼Ÿ")ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¿™ä¹Ÿæé«˜äº†æˆ‘ä»¬ç±»åˆ«çš„è´¨é‡ã€‚
- en: Below is an example of our 4-shot prompt format, from real example from EntityQuestions
    with the relation $P106$ representing occupation.^(14)^(14)14[https://www.wikidata.org/wiki/Property:P106](https://www.wikidata.org/wiki/Property:P106)
    The question in this case is *â€œWhat kind of work does Ron Konopka do?â€* and the
    ground truth asnwer is *â€œgeneticistâ€*.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯æˆ‘ä»¬4-shotæç¤ºæ ¼å¼çš„ä¸€ä¸ªç¤ºä¾‹ï¼Œæ¥è‡ªEntityQuestionsä¸­çš„çœŸå®ç¤ºä¾‹ï¼Œå…¶ä¸­å…³ç³»$P106$è¡¨ç¤ºèŒä¸šã€‚^(14)^(14)14[https://www.wikidata.org/wiki/Property:P106](https://www.wikidata.org/wiki/Property:P106)
    åœ¨è¿™ä¸ªæ¡ˆä¾‹ä¸­ï¼Œé—®é¢˜æ˜¯*â€œRon Konopkaåšä»€ä¹ˆå·¥ä½œï¼Ÿâ€*ï¼ŒçœŸå®ç­”æ¡ˆæ˜¯*â€œé—ä¼ å­¦å®¶â€*ã€‚
- en: 'Q: What kind of work does Nicolas Roeg do? A: film director Q: What kind of
    work does Crystal GeoffrÃ© do? A: actor Q: What kind of work does Maurice Blondel
    do? A: philosopher Q: What kind of work does Javier de Burgos do? A: politician
    Q: What kind of work does Ron Konopka do? A: | Wrong Answer | Paraphrase | Higher
    Granularity | Lower Granularity |'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: Nicolas Roegåšä»€ä¹ˆå·¥ä½œï¼Ÿ A: ç”µå½±å¯¼æ¼” Q: Crystal GeoffrÃ©åšä»€ä¹ˆå·¥ä½œï¼Ÿ A: æ¼”å‘˜ Q: Maurice Blondelåšä»€ä¹ˆå·¥ä½œï¼Ÿ
    A: å“²å­¦å®¶ Q: Javier de Burgosåšä»€ä¹ˆå·¥ä½œï¼Ÿ A: æ”¿æ²»å®¶ Q: Ron Konopkaåšä»€ä¹ˆå·¥ä½œï¼Ÿ A: | é”™è¯¯ç­”æ¡ˆ | é‡Šä¹‰ |
    æ›´é«˜ç²’åº¦ | æ›´ä½ç²’åº¦ |'
- en: '| $90\%$ | $2\%$ |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| $90\%$ | $2\%$ |'
- en: 'Table 6: Error Analysis of 100 Predictions of the Pre-trained Model, for Which
    Exact Match is False.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨6ï¼š100ä¸ªé¢„è®­ç»ƒæ¨¡å‹é¢„æµ‹çš„é”™è¯¯åˆ†æï¼Œå…¶ä¸­ç²¾ç¡®åŒ¹é…ä¸ºå‡ã€‚
- en: To decide whether a sampled answer is correct, we use the Exact Match (EM) metric
    to compare it with the ground truth answer. The main advantage in this choice
    is that when EM is True, we know that the answer is correct for $100\%$) and 50
    samples with $T=0.5$ of the cases where EM is False, the predicted answer is indeed
    incorrect. Which is a reasonable performance for our purpose, especially considering
    that when EM is True the answer is $100\%$ correct.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å†³å®šä¸€ä¸ªé‡‡æ ·ç­”æ¡ˆæ˜¯å¦æ­£ç¡®ï¼Œæˆ‘ä»¬ä½¿ç”¨ç²¾ç¡®åŒ¹é…ï¼ˆEMï¼‰åº¦é‡å°†å…¶ä¸çœŸå®ç­”æ¡ˆè¿›è¡Œæ¯”è¾ƒã€‚è¿™ç§é€‰æ‹©çš„ä¸»è¦ä¼˜ç‚¹æ˜¯å½“EMä¸ºçœŸæ—¶ï¼Œæˆ‘ä»¬çŸ¥é“ç­”æ¡ˆæ˜¯$100\%$æ­£ç¡®çš„ï¼Œè€Œåœ¨EMä¸ºå‡æ—¶ï¼Œæœ‰$50$ä¸ªæ ·æœ¬ä¸­$T=0.5$çš„æƒ…å†µä¸‹ï¼Œé¢„æµ‹ç­”æ¡ˆç¡®å®æ˜¯é”™è¯¯çš„ã€‚è¿™å¯¹äºæˆ‘ä»¬çš„ç›®çš„æ¥è¯´æ˜¯ä¸€ä¸ªåˆç†çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯è€ƒè™‘åˆ°å½“EMä¸ºçœŸæ—¶ï¼Œç­”æ¡ˆæ˜¯$100\%$æ­£ç¡®çš„ã€‚
- en: Appendix D Data Annotation
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½•D æ•°æ®æ ‡æ³¨
- en: we first calculate $P_{\mathtt{Correct}}(q,a;M,T=0)$ for each $(q,a)$ approximation
    (Â§[3](#S3 "3 Quantifying Knowledge in LLMs â€£ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?") and Â§[C](#A3 "Appendix C ğ‘·_ğ™²ğš˜ğš›ğš›ğšğšŒğš Approximation â€£
    Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")). We then use
    these values to categorize each $(q,a)$ pair into one of our four categories (Â§[3](#S3
    "3 Quantifying Knowledge in LLMs â€£ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?") and [FigureÂ 2](#S2.F2 "In 2 Study Setup â€£ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?")). We provide the full statistics
    of the categories on the train and test set, as well as the out-of-distribution
    test set in Tables [3](#A1.T3 "Table 3 â€£ Appendix A Data Preprocessing â€£ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"), [4](#A1.T4 "Table
    4 â€£ Appendix A Data Preprocessing â€£ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?") and [5](#A1.T5 "Table 5 â€£ Appendix A Data Preprocessing â€£ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆè®¡ç®—æ¯ä¸ª $(q,a)$ è¿‘ä¼¼çš„ $P_{\mathtt{Correct}}(q,a;M,T=0)$ (Â§[3](#S3 "3 é‡åŒ– LLM çŸ¥è¯†
    â€£ å¾®è°ƒ LLM æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ") å’Œ Â§[C](#A3 "é™„å½• C ğ‘·_ğ™²ğš˜ğš›ğš›ğšğšŒğš è¿‘ä¼¼ â€£ å¾®è°ƒ LLM æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ"))ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™äº›å€¼å°†æ¯ä¸ª
    $(q,a)$ å¯¹åˆ†ç±»åˆ°æˆ‘ä»¬çš„å››ä¸ªç±»åˆ«ä¹‹ä¸€ (Â§[3](#S3 "3 é‡åŒ– LLM çŸ¥è¯† â€£ å¾®è°ƒ LLM æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ") å’Œ [å›¾ 2](#S2.F2
    "åœ¨ 2 ç ”ç©¶è®¾ç½® â€£ å¾®è°ƒ LLM æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ"))ã€‚æˆ‘ä»¬æä¾›äº†è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ç±»åˆ«ç»Ÿè®¡æ•°æ®ï¼Œä»¥åŠè¶…å‡ºåˆ†å¸ƒæµ‹è¯•é›†çš„ç»Ÿè®¡æ•°æ®ï¼Œè¯¦è§è¡¨ [3](#A1.T3
    "è¡¨ 3 â€£ é™„å½• A æ•°æ®é¢„å¤„ç† â€£ å¾®è°ƒ LLM æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")ã€[4](#A1.T4 "è¡¨ 4 â€£ é™„å½• A æ•°æ®é¢„å¤„ç† â€£ å¾®è°ƒ LLM æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")
    å’Œ [5](#A1.T5 "è¡¨ 5 â€£ é™„å½• A æ•°æ®é¢„å¤„ç† â€£ å¾®è°ƒ LLM æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")ã€‚
- en: Appendix E Fine-tuning Details
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½• E å¾®è°ƒç»†èŠ‚
- en: Fine-tuning Data.
  id: totrans-238
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å¾®è°ƒæ•°æ®ã€‚
- en: In Â§[4](#S4 "4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on
    New Knowledge Encourage Hallucinations?") we examine the effect of new knowledge
    in the fine-tuning dataset $D$, by varying the proportion of $\mathtt{Unknown}$.
    When we create variants of $D$ of $\mathtt{Unknown}$ $\mathtt{Known}$ of $\mathtt{Unknown}$
    *from each relation*.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Â§[4](#S4 "4 æœªçŸ¥ç¤ºä¾‹æœ‰å¤šæœ‰å®³ï¼Ÿ â€£ å¾®è°ƒ LLM æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ") ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æ”¹å˜ $\mathtt{Unknown}$ çš„æ¯”ä¾‹æ¥æ£€æŸ¥æ–°çŸ¥è¯†åœ¨å¾®è°ƒæ•°æ®é›†
    $D$ ä¸­çš„å½±å“ã€‚å½“æˆ‘ä»¬åˆ›å»º $\mathtt{Unknown}$ å’Œ $\mathtt{Known}$ çš„å˜ä½“æ—¶ï¼Œ*æ¥è‡ªæ¯ä¸ªå…³ç³»* çš„æ¯”ä¾‹ã€‚
- en: 'In Â§[5](#S5 "5 Understanding Knowledge Types: Their Value and Impact â€£ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") we create single-category
    variants of $D$ across all variants, we want to make sure that we have $|D|$ as
    their sum. In other words, for each relation we calculate the size of the smallest
    category and sum these values. This leads to $|D|=6142$ to be the examples from
    category CAT and relation r. Consequently $\text{size}(\text{CAT}_{\text{r}})$.
    For example $\text{size}($ ${}_{\text{P131}})=553$ (see [TableÂ 3](#A1.T3 "In Appendix
    A Data Preprocessing â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")).
    We then define:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Â§[5](#S5 "5 ç†è§£çŸ¥è¯†ç±»å‹ï¼šå®ƒä»¬çš„ä»·å€¼å’Œå½±å“ â€£ å¾®è°ƒ LLM æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ") ä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºäº† $D$ çš„å•ç±»åˆ«å˜ä½“ï¼Œç¡®ä¿ $|D|$
    æ˜¯å®ƒä»¬çš„æ€»å’Œã€‚æ¢å¥è¯è¯´ï¼Œå¯¹äºæ¯ä¸ªå…³ç³»ï¼Œæˆ‘ä»¬è®¡ç®—æœ€å°ç±»åˆ«çš„å¤§å°å¹¶æ±‚å’Œã€‚è¿™å¯¼è‡´ $|D|=6142$ ä¸ºç±»åˆ« CAT å’Œå…³ç³» r çš„ç¤ºä¾‹ã€‚å› æ­¤ $\text{size}(\text{CAT}_{\text{r}})$ã€‚ä¾‹å¦‚
    $\text{size}($ ${}_{\text{P131}})=553$ï¼ˆè§ [è¡¨ 3](#A1.T3 "åœ¨é™„å½• A æ•°æ®é¢„å¤„ç† â€£ å¾®è°ƒ LLM æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")ï¼‰ã€‚ç„¶åæˆ‘ä»¬å®šä¹‰ï¼š
- en: '|  | $$&#124;D&#124;=\sum_{r\in R_{\text{Train}}}\min\left\{\text{size}(CAT_{r})&#124;\
    \left.\begin{array}[]{l}\text{CAT}\in\{\\ \text{$\mathtt{HighlyKnown}$},\\'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | $$&#124;D&#124;=\sum_{r\in R_{\text{Train}}}\min\left\{\text{size}(CAT_{r})&#124;\
    \left.\begin{array}[]{l}\text{CAT}\in\{\\ \text{$\mathtt{HighlyKnown}$},\\'
- en: \text{$\mathtt{MaybeKnown}$},\\
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: \text{$\mathtt{MaybeKnown}$},\\
- en: \text{$\mathtt{WeaklyKnown}$},\\
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: \text{$\mathtt{WeaklyKnown}$},\\
- en: \text{$\mathtt{Unknown}$}\}\\
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: \text{$\mathtt{Unknown}$}\}\\
- en: \end{array}\right\}\right.$$ |  |
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: \end{array}\right\}\right.$$ |  |
- en: where $\text{R}_{\text{Train}}$ are the 12 relations from the training set.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ $\text{R}_{\text{Train}}$ æ˜¯æ¥è‡ªè®­ç»ƒé›†çš„ 12 ä¸ªå…³ç³»ã€‚
- en: Below is an example of our data format in the train, development and test sets,
    from real example from EntityQuestions with the relation $P106$ representing occupation.^(15)^(15)15[https://www.wikidata.org/wiki/Property:P106](https://www.wikidata.org/wiki/Property:P106)
    The question in this case is *â€œWhat kind of work does Ron Konopka do?â€* and the
    ground truth asnwer is *â€œgeneticistâ€*. Answer the following question. What kind
    of work does Ron Konopka do?
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯æˆ‘ä»¬åœ¨è®­ç»ƒã€å¼€å‘å’Œæµ‹è¯•é›†ä¸­çš„æ•°æ®æ ¼å¼ç¤ºä¾‹ï¼Œæ¥è‡ªäºçœŸå®çš„EntityQuestionsä¾‹å­ï¼Œå…¶ä¸­å…³ç³»$P106$è¡¨ç¤ºèŒä¸šã€‚^(15)^(15)15[https://www.wikidata.org/wiki/Property:P106](https://www.wikidata.org/wiki/Property:P106)
    åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œé—®é¢˜æ˜¯*â€œRon Konopka ä»äº‹ä»€ä¹ˆæ ·çš„å·¥ä½œï¼Ÿâ€*ï¼Œè€ŒçœŸå®çš„ç­”æ¡ˆæ˜¯*â€œé—ä¼ å­¦å®¶â€*ã€‚å›ç­”ä»¥ä¸‹é—®é¢˜ï¼šRon Konopka ä»äº‹ä»€ä¹ˆæ ·çš„å·¥ä½œï¼Ÿ
- en: Fine-tuning hypeparameters.
  id: totrans-248
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å¾®è°ƒè¶…å‚æ•°ã€‚
- en: We fine-tune every model for 50 epochs for all our model variants to completely
    fit the training set, so we can examine all stages of fine-tuning. We use learning
    rate of 1e-5, a batch size of 128, and a dropout rate of 0.05. We evaluate the
    models every epoch on the development set. The early_stop stopping criteria is
    defined to be the epoch with the maximum accuracy on the development set.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯¹æ‰€æœ‰æ¨¡å‹å˜ä½“è¿›è¡Œ50è½®çš„å¾®è°ƒï¼Œä»¥å®Œå…¨é€‚åº”è®­ç»ƒé›†ï¼Œä»è€Œå¯ä»¥æ£€æŸ¥å¾®è°ƒçš„å„ä¸ªé˜¶æ®µã€‚æˆ‘ä»¬ä½¿ç”¨å­¦ä¹ ç‡ä¸º1e-5ï¼Œæ‰¹é‡å¤§å°ä¸º128ï¼Œä¸¢å¼ƒç‡ä¸º0.05ã€‚æˆ‘ä»¬åœ¨æ¯ä¸€è½®ä¸Šéƒ½è¯„ä¼°æ¨¡å‹åœ¨å¼€å‘é›†ä¸Šçš„è¡¨ç°ã€‚early_stopåœæ­¢æ ‡å‡†å®šä¹‰ä¸ºåœ¨å¼€å‘é›†ä¸Šå‡†ç¡®åº¦æœ€é«˜çš„è½®æ¬¡ã€‚
- en: Appendix F Train Accuracy on Different $\mathtt{Known}$ Categories
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½•F åœ¨ä¸åŒ$\mathtt{Known}$ç±»åˆ«ä¸Šçš„è®­ç»ƒå‡†ç¡®ç‡
- en: '![Refer to caption](img/0f1bebe64fac6944111fa1f3da2001f6.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§æ ‡é¢˜](img/0f1bebe64fac6944111fa1f3da2001f6.png)'
- en: 'Figure 6: Training accuracy as a function of fine-tuning duration, evaluated
    on the variant with $50\%$ fine-tuning examples. For reference, we also include
    the accuracy on the development set, accompanied by a zoom-in plot within a narrower
    range, to provide a more visible and clear view.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾6ï¼šè®­ç»ƒå‡†ç¡®ç‡ä¸å¾®è°ƒæ—¶é—´çš„å‡½æ•°å…³ç³»ï¼Œè¯„ä¼°äº†$50\%$å¾®è°ƒæ ·æœ¬çš„å˜ä½“ã€‚ä¸ºäº†å‚è€ƒï¼Œæˆ‘ä»¬è¿˜åŒ…æ‹¬äº†å¼€å‘é›†ä¸Šçš„å‡†ç¡®ç‡ï¼Œå¹¶é™„ä¸Šäº†åœ¨è¾ƒçª„èŒƒå›´å†…çš„æ”¾å¤§å›¾ï¼Œä»¥æä¾›æ›´æ¸…æ™°çš„è§†å›¾ã€‚
- en: In Â§[4.3](#S4.SS3 "4.3 ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples are Fitted Slower than ğ™ºğš—ğš˜ğš ğš— Examples
    â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?") we analyze the fine-tuning dynamic and present the
    training accuracy as function of the fine-tuning duration in [FigureÂ 1](#S1.F1
    "In 1 Introduction â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
    For simplicity we treated the $\mathtt{Known}$ categories collectively. For reference
    we also include the plot with the full per-category breakdown in [FigureÂ 6](#A6.F6
    "In Appendix F Train Accuracy on Different ğ™ºğš—ğš˜ğš ğš— Categories â€£ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?").
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Â§[4.3](#S4.SS3 "4.3 ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples are Fitted Slower than ğ™ºğš—ğš˜ğšğšœ Examples
    â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?")ä¸­ï¼Œæˆ‘ä»¬åˆ†æäº†å¾®è°ƒåŠ¨æ€ï¼Œå¹¶åœ¨[å›¾1](#S1.F1 "åœ¨1 å¼•è¨€ â€£ å¾®è°ƒLLMsåœ¨æ–°çŸ¥è¯†ä¸Šæ˜¯å¦ä¼šé¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")ä¸­å‘ˆç°äº†è®­ç»ƒå‡†ç¡®ç‡ä¸å¾®è°ƒæ—¶é—´çš„å‡½æ•°å…³ç³»ã€‚ä¸ºç®€ä¾¿èµ·è§ï¼Œæˆ‘ä»¬å°†$\mathtt{Known}$ç±»åˆ«ä¸€èµ·å¤„ç†ã€‚ä½œä¸ºå‚è€ƒï¼Œæˆ‘ä»¬è¿˜åŒ…æ‹¬äº†[å›¾6](#A6.F6
    "åœ¨é™„å½•F ä¸åŒğ™ºğš—ğš˜ğš ğš—ç±»åˆ«ä¸Šçš„è®­ç»ƒå‡†ç¡®ç‡ â€£ å¾®è°ƒLLMsåœ¨æ–°çŸ¥è¯†ä¸Šæ˜¯å¦ä¼šé¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")ä¸­æŒ‰ç±»åˆ«åˆ†è§£çš„å®Œæ•´å›¾è¡¨ã€‚
- en: Appendix G Linear Model
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½•G çº¿æ€§æ¨¡å‹
- en: 'In Â§[4.4](#S4.SS4 "4.4 The Influence of ğš„ğš—ğš”ğš—ğš˜ğš ğš— vs ğ™ºğš—ğš˜ğš ğš— on Accuracy: A Linear
    Model Perspective â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?") and Â§[4.5](#S4.SS5 "4.5 Generalization
    to New Relations â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?") we use a linear model ([EquationÂ 1](#S4.E1
    "In 4.4 The Influence of ğš„ğš—ğš”ğš—ğš˜ğš ğš— vs ğ™ºğš—ğš˜ğš ğš— on Accuracy: A Linear Model Perspective
    â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?")) that predicts that test accuracy and the out-of-distribution
    test accuracy. We estimate the parameters of this linear model based on results
    from all our variants of $D$ and $\mathtt{Unknown}$ fits during different fine-tuning
    stages. This way we collect a dataset with examples of the form $(Accuracy,N_{\text{Kn}},N_{\text{Unk}})$,
    which we use to fit a linear regression model.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Â§[4.4](#S4.SS4 "4.4 ğš„ğš—ğš”ğš—ğš˜ğš ğš— ä¸ ğ™ºğš—ğš˜ğš ğš— å¯¹å‡†ç¡®ç‡çš„å½±å“ï¼šçº¿æ€§æ¨¡å‹è§†è§’ â€£ 4 ğš„ğš—ğš”ğš—ğš˜ğš ğš— ç¤ºä¾‹æœ‰å¤šæœ‰å®³ï¼Ÿ â€£ å¾®è°ƒ
    LLM æ˜¯å¦ä¼šä¿ƒä½¿è™šå‡ä¿¡æ¯ï¼Ÿ") å’Œ Â§[4.5](#S4.SS5 "4.5 å¯¹æ–°å…³ç³»çš„æ³›åŒ– â€£ 4 ğš„ğš—ğš”ğš—ğš˜ğšğš£ ç¤ºä¾‹æœ‰å¤šæœ‰å®³ï¼Ÿ â€£ å¾®è°ƒ LLM æ˜¯å¦ä¼šä¿ƒä½¿è™šå‡ä¿¡æ¯ï¼Ÿ")
    ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªçº¿æ€§æ¨¡å‹ ([å…¬å¼ 1](#S4.E1 "åœ¨ 4.4 ğš„ğš—ğš”ğš—ğš˜ğš ğš— ä¸ ğ™ºğš—ğš˜ğš ğšŸ å¯¹å‡†ç¡®ç‡çš„å½±å“ï¼šçº¿æ€§æ¨¡å‹è§†è§’ â€£ 4 ğš„ğšŸğš•ğš˜ğšğšğš‰
    ç¤ºä¾‹æœ‰å¤šæœ‰å®³ï¼Ÿ â€£ å¾®è°ƒ LLM æ˜¯å¦ä¼šä¿ƒä½¿è™šå‡ä¿¡æ¯ï¼Ÿ")) æ¥é¢„æµ‹æµ‹è¯•å‡†ç¡®ç‡å’Œåˆ†å¸ƒå¤–æµ‹è¯•å‡†ç¡®ç‡ã€‚æˆ‘ä»¬åŸºäº $D$ å’Œ $\mathtt{Unknown}$
    åœ¨ä¸åŒå¾®è°ƒé˜¶æ®µçš„æ‰€æœ‰å˜ä½“ç»“æœæ¥ä¼°è®¡è¿™ä¸ªçº¿æ€§æ¨¡å‹çš„å‚æ•°ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬æ”¶é›†äº†ä¸€ä¸ªå½¢å¼ä¸º $(å‡†ç¡®ç‡, N_{\text{Kn}}, N_{\text{Unk}})$
    çš„æ•°æ®é›†ï¼Œå¹¶ç”¨æ¥æ‹Ÿåˆä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹ã€‚
- en: Appendix H Out-of-distribution (OOD) Evaluation
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½• H åˆ†å¸ƒå¤– (OOD) è¯„ä¼°
- en: '![Refer to caption](img/094837f6c2114bc180b4e31f77fb3f4f.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜](img/094837f6c2114bc180b4e31f77fb3f4f.png)'
- en: (a)
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/d374814505ee99c74a3063838f0169a7.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜](img/d374814505ee99c74a3063838f0169a7.png)'
- en: (b)
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 7: Performance on the *out-of-distribution (OOD)* test set as a function
    of the $\%$ examples in the fine-tuning dataset $D$. This plot is the OOD version
    of [FigureÂ 3](#S3.F3 "In 3 Quantifying Knowledge in LLMs â€£ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?"). Everything is similar to [FigureÂ 3](#S3.F3
    "In 3 Quantifying Knowledge in LLMs â€£ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?"), except that y-axis is the accuracy on the OOD test set. We
    note that *the development set did not change (not OOD)*, thus it does not necessarily
    reflects the optimal stopping point for OOD.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 7ï¼š*åˆ†å¸ƒå¤– (OOD)* æµ‹è¯•é›†çš„æ€§èƒ½ï¼Œä½œä¸ºå¾®è°ƒæ•°æ®é›† $D$ ä¸­ $\%$ æ ·æœ¬çš„å‡½æ•°ã€‚è¿™ä¸ªå›¾æ˜¯[å›¾ 3](#S3.F3 "åœ¨ 3 é‡åŒ– LLM
    çŸ¥è¯† â€£ å¾®è°ƒ LLM æ˜¯å¦ä¼šä¿ƒä½¿è™šå‡ä¿¡æ¯ï¼Ÿ") çš„ OOD ç‰ˆæœ¬ã€‚ä¸[å›¾ 3](#S3.F3 "åœ¨ 3 é‡åŒ– LLM çŸ¥è¯† â€£ å¾®è°ƒ LLM æ˜¯å¦ä¼šä¿ƒä½¿è™šå‡ä¿¡æ¯ï¼Ÿ")
    ä¸€æ ·ï¼Œå”¯ä¸€çš„ä¸åŒæ˜¯ y è½´æ˜¯ OOD æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ã€‚æˆ‘ä»¬æ³¨æ„åˆ°*å¼€å‘é›†æ²¡æœ‰å˜åŒ–ï¼ˆä¸æ˜¯ OODï¼‰*ï¼Œå› æ­¤è¿™ä¸ä¸€å®šåæ˜ äº† OOD çš„æœ€ä½³åœæ­¢ç‚¹ã€‚
- en: 'In Â§[4.5](#S4.SS5 "4.5 Generalization to New Relations â€£ 4 How Harmful are
    ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")
    we discuss *out-of-distribution (OOD)* results. In these experiments we simply
    used our OOD test set consisting of 7 relations unseen during fine-tuning (see
    Â§[A](#A1 "Appendix A Data Preprocessing â€£ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?")). When we perform the analysis discussed in Â§[4.1](#S4.SS1
    "4.1 Higher ğš„ğš—ğš”ğš—ğš˜ğš ğš— Ratio is Proportional to Performance Degradation â€£ 4 How Harmful
    are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")
    and Â§[4.2](#S4.SS2 "4.2 ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples: Harmful or Neutral? â€£ 4 How Harmful
    are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"),
    we additionally evaluated the models on the OOD test set. For completeness, we
    add here [FigureÂ 7](#A8.F7 "In Appendix H Out-of-distribution (OOD) Evaluation
    â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"), which is
    the out-of-distribution version of [FigureÂ 3](#S3.F3 "In 3 Quantifying Knowledge
    in LLMs â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?").
    [FigureÂ 7(a)](#A8.F7.sf1 "In Figure 7 â€£ Appendix H Out-of-distribution (OOD) Evaluation
    â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") presents
    the OOD test performance as a function of $\%$ examples in $D$ fine-tuning examples.
    The corresponding *in-distribution* results ([FigureÂ 3(b)](#S3.F3.sf2 "In Figure
    3 â€£ 3 Quantifying Knowledge in LLMs â€£ Does Fine-Tuning LLMs on New Knowledge Encourage
    Hallucinations?")) were discussed in Â§[4.2](#S4.SS2 "4.2 ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples: Harmful
    or Neutral? â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New
    Knowledge Encourage Hallucinations?"). We notice that similar trends, just with
    a smaller overall magnitude of the performance drop, up to 6 points drop compared
    to up to 14 for in-distribution. This smaller drop magnitude is also reflected
    in smaller values of $|\beta_{\text{ukn}}|$ ([TableÂ 1](#S2.T1 "In 4.4 The Influence
    of ğš„ğš—ğš”ğš—ğš˜ğš ğš— vs ğ™ºğš—ğš˜ğš ğš— on Accuracy: A Linear Model Perspective â€£ 4 How Harmful are
    ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")).'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Â§[4.5](#S4.SS5 "4.5 ä¸€èˆ¬åŒ–åˆ°æ–°å…³ç³» â€£ 4 æœªçŸ¥æ ·æœ¬çš„å±å®³æœ‰å¤šå¤§ï¼Ÿ â€£ å¾®è°ƒ LLM å¯¹æ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†*åˆ†å¸ƒå¤–ï¼ˆOODï¼‰*ç»“æœã€‚åœ¨è¿™äº›å®éªŒä¸­ï¼Œæˆ‘ä»¬ç®€å•åœ°ä½¿ç”¨äº†åŒ…å«7ä¸ªåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­æœªè§è¿‡çš„å…³ç³»çš„OODæµ‹è¯•é›†ï¼ˆè§Â§[A](#A1
    "é™„å½• A æ•°æ®é¢„å¤„ç† â€£ å¾®è°ƒ LLM å¯¹æ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")ï¼‰ã€‚å½“æˆ‘ä»¬è¿›è¡ŒÂ§[4.1](#S4.SS1 "4.1 æ›´é«˜çš„æœªçŸ¥æ¯”ä¾‹ä¸æ€§èƒ½ä¸‹é™æˆæ­£æ¯”
    â€£ 4 æœªçŸ¥æ ·æœ¬çš„å±å®³æœ‰å¤šå¤§ï¼Ÿ â€£ å¾®è°ƒ LLM å¯¹æ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")å’ŒÂ§[4.2](#S4.SS2 "4.2 æœªçŸ¥æ ·æœ¬ï¼šæœ‰å®³è¿˜æ˜¯ä¸­æ€§ï¼Ÿ â€£ 4
    æœªçŸ¥æ ·æœ¬çš„å±å®³æœ‰å¤šå¤§ï¼Ÿ â€£ å¾®è°ƒ LLM å¯¹æ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")ä¸­è®¨è®ºçš„åˆ†ææ—¶ï¼Œæˆ‘ä»¬è¿˜åœ¨OODæµ‹è¯•é›†ä¸Šè¯„ä¼°äº†æ¨¡å‹ã€‚ä¸ºäº†å®Œæ•´æ€§ï¼Œæˆ‘ä»¬åœ¨æ­¤æ·»åŠ [å›¾ 7](#A8.F7
    "é™„å½• H åˆ†å¸ƒå¤–ï¼ˆOODï¼‰è¯„ä¼° â€£ å¾®è°ƒ LLM å¯¹æ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")ï¼Œè¿™æ˜¯[å›¾ 3](#S3.F3 "åœ¨ 3 é‡åŒ– LLM çŸ¥è¯† â€£ å¾®è°ƒ LLM
    å¯¹æ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")çš„åˆ†å¸ƒå¤–ç‰ˆæœ¬ã€‚[å›¾ 7(a)](#A8.F7.sf1 "å›¾ 7 â€£ é™„å½• H åˆ†å¸ƒå¤–ï¼ˆOODï¼‰è¯„ä¼° â€£ å¾®è°ƒ LLM å¯¹æ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")å±•ç¤ºäº†OODæµ‹è¯•æ€§èƒ½ä¸$D$å¾®è°ƒæ ·æœ¬ä¸­$\%$æ ·æœ¬çš„å…³ç³»ã€‚ç›¸åº”çš„*åˆ†å¸ƒå†…*ç»“æœï¼ˆ[å›¾
    3(b)](#S3.F3.sf2 "å›¾ 3 â€£ 3 é‡åŒ– LLM çŸ¥è¯† â€£ å¾®è°ƒ LLM å¯¹æ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")ï¼‰åœ¨Â§[4.2](#S4.SS2 "4.2
    æœªçŸ¥æ ·æœ¬ï¼šæœ‰å®³è¿˜æ˜¯ä¸­æ€§ï¼Ÿ â€£ 4 æœªçŸ¥æ ·æœ¬çš„å±å®³æœ‰å¤šå¤§ï¼Ÿ â€£ å¾®è°ƒ LLM å¯¹æ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")ä¸­è®¨è®ºã€‚æˆ‘ä»¬æ³¨æ„åˆ°ç±»ä¼¼çš„è¶‹åŠ¿ï¼Œåªæ˜¯æ€§èƒ½ä¸‹é™çš„æ€»ä½“å¹…åº¦è¾ƒå°ï¼Œæœ€å¤šä¸‹é™6ç‚¹ï¼Œè€Œåˆ†å¸ƒå†…åˆ™æœ€å¤šä¸‹é™14ç‚¹ã€‚è¿™ä¸€è¾ƒå°çš„ä¸‹é™å¹…åº¦åœ¨$|\beta_{\text{ukn}}|$çš„è¾ƒå°å€¼ä¸­ä¹Ÿæœ‰æ‰€ä½“ç°ï¼ˆ[è¡¨
    1](#S2.T1 "åœ¨ 4.4 æœªçŸ¥ä¸å·²çŸ¥å¯¹å‡†ç¡®ç‡çš„å½±å“ï¼šçº¿æ€§æ¨¡å‹è§†è§’ â€£ 4 æœªçŸ¥æ ·æœ¬çš„å±å®³æœ‰å¤šå¤§ï¼Ÿ â€£ å¾®è°ƒ LLM å¯¹æ–°çŸ¥è¯†æ˜¯å¦é¼“åŠ±è™šå‡ä¿¡æ¯ï¼Ÿ")ï¼‰ã€‚
- en: '|  | early_stop |  | Convergence |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '|  | early_stop |  | æ”¶æ•› |'
- en: '| --- | --- | --- | --- |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  | $\mathtt{Full}$ | $\mathtt{Mkn}$ | $\mathtt{Unk}$ |  | $\mathtt{Hkn}$
    | $\mathtt{Wkn}$ |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathtt{Full}$ | $\mathtt{Mkn}$ | $\mathtt{Unk}$ |  | $\mathtt{Hkn}$
    | $\mathtt{Wkn}$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- |'
- en: '| $D_{\mathtt{HighlyKnown}}$ | 40.5^(âˆ—âˆ—) |  | 98.7 | 60.1^(âˆ—âˆ—) | 9.0^(âˆ—âˆ—) |
    0.6^(âˆ—âˆ—) |  | 40.0^(âˆ—âˆ—) |  | 98.4 | 58.8^(âˆ—âˆ—) | 8.5^(âˆ—âˆ—) | 0.7^(âˆ—âˆ—) |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{HighlyKnown}}$ | 40.5^(âˆ—âˆ—) |  | 98.7 | 60.1^(âˆ—âˆ—) | 9.0^(âˆ—âˆ—) |
    0.6^(âˆ—âˆ—) |  | 40.0^(âˆ—âˆ—) |  | 98.4 | 58.8^(âˆ—âˆ—) | 8.5^(âˆ—âˆ—) | 0.7^(âˆ—âˆ—) |'
- en: '| $D_{\mathtt{MaybeKnown}}$ | 43.6 |  | 98.4 | 69.9 | 12.1^(âˆ—âˆ—) | 1.0^(âˆ—âˆ—)
    |  | 43.2 |  | 97.5^âˆ— | 68.2 | 12.9^(âˆ—âˆ—) | 1.3^(âˆ—âˆ—) |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{MaybeKnown}}$ | 43.6 |  | 98.4 | 69.9 | 12.1^(âˆ—âˆ—) | 1.0^(âˆ—âˆ—)
    |  | 43.2 |  | 97.5^âˆ— | 68.2 | 12.9^(âˆ—âˆ—) | 1.3^(âˆ—âˆ—) |'
- en: '| $D_{\mathtt{WeaklyKnown}}$ | 39.2^(âˆ—âˆ—) |  | 95.0^(âˆ—âˆ—) | 59.2^(âˆ—âˆ—) | 8.6^(âˆ—âˆ—)
    | 0.4^(âˆ—âˆ—) |  | 35.4^(âˆ—âˆ—) |  | 73.5^(âˆ—âˆ—) | 55.8^(âˆ—âˆ—) | 17.2 | 2.2^(âˆ—âˆ—) |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{WeaklyKnown}}$ | 39.2^(âˆ—âˆ—) |  | 95.0^(âˆ—âˆ—) | 59.2^(âˆ—âˆ—) | 8.6^(âˆ—âˆ—)
    | 0.4^(âˆ—âˆ—) |  | 35.4^(âˆ—âˆ—) |  | 73.5^(âˆ—âˆ—) | 55.8^(âˆ—âˆ—) | 17.2 | 2.2^(âˆ—âˆ—) |'
- en: '| $D_{\mathtt{Unknown}}$ | 37.5^(âˆ—âˆ—) |  | 95.6^(âˆ—âˆ—) | 52.9^(âˆ—âˆ—) | 6.5^(âˆ—âˆ—)
    | 0.6^(âˆ—âˆ—) |  | 25.8^(âˆ—âˆ—) |  | 55.8^(âˆ—âˆ—) | 36.6^(âˆ—âˆ—) | 12.2^(âˆ—âˆ—) | 3.2 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{Unknown}}$ | 37.5^(âˆ—âˆ—) |  | 95.6^(âˆ—âˆ—) | 52.9^(âˆ—âˆ—) | 6.5^(âˆ—âˆ—)
    | 0.6^(âˆ—âˆ—) |  | 25.8^(âˆ—âˆ—) |  | 55.8^(âˆ—âˆ—) | 36.6^(âˆ—âˆ—) | 12.2^(âˆ—âˆ—) | 3.2 |'
- en: '| $D_{\mathtt{Natural}}$ | 43.5 |  | 98.0^âˆ— | 67.6^(âˆ—âˆ—) | 14.1 | 1.8 |  | 41.8^(âˆ—âˆ—)
    |  | 95.5^(âˆ—âˆ—) | 61.7^(âˆ—âˆ—) | 14.8^(âˆ—âˆ—) | 2.5^âˆ— |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{Natural}}$ | 43.5 |  | 98.0^âˆ— | 67.6^(âˆ—âˆ—) | 14.1 | 1.8 |  | 41.8^(âˆ—âˆ—)
    |  | 95.5^(âˆ—âˆ—) | 61.7^(âˆ—âˆ—) | 14.8^(âˆ—âˆ—) | 2.5^âˆ— |'
- en: 'Table 7: A copy of [TableÂ 2](#S4.T2 "In 4.4 The Influence of ğš„ğš—ğš”ğš—ğš˜ğš ğš— vs ğ™ºğš—ğš˜ğš ğš—
    on Accuracy: A Linear Model Perspective â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples?
    â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") with detailed
    notation of the statistic significant test results. In each column, statistically
    significant differences from the best result are indicated using ^âˆ— and ^(âˆ—âˆ—)
    for $p<0.05$ respectively.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 'è¡¨7: [è¡¨2](#S4.T2 "åœ¨4.4 ğš„ğš—ğš”ğš—ğš˜ğšğšğš™ğš‹ğš›ğšğšğšğšğšœ")çš„å‰¯æœ¬ï¼Œè¯¦ç»†æ ‡æ³¨äº†ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒç»“æœã€‚åœ¨æ¯åˆ—ä¸­ï¼Œç»Ÿè®¡æ˜¾è‘—æ€§å·®å¼‚ç”¨^âˆ—å’Œ^(âˆ—âˆ—)è¡¨ç¤ºï¼Œåˆ†åˆ«å¯¹åº”$p<0.05$ã€‚'
- en: Appendix I Statistic Significance Tests
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½•I ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
- en: 'In Â§[5](#S5 "5 Understanding Knowledge Types: Their Value and Impact â€£ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") we present [TableÂ 2](#S4.T2
    "In 4.4 The Influence of ğš„ğš—ğš”ğš—ğš˜ğš ğš— vs ğ™ºğš—ğš˜ğš ğš— on Accuracy: A Linear Model Perspective
    â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?"). As mentioned in the caption, we perform statistic
    significance tests for each column. To this end we compare all the values to the
    maximal value in this column.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Â§[5](#S5 "5 ç†è§£çŸ¥è¯†ç±»å‹ï¼šå®ƒä»¬çš„ä»·å€¼å’Œå½±å“ â€£ å¯¹LLMsè¿›è¡Œæ–°çŸ¥è¯†å¾®è°ƒæ˜¯å¦ä¼šä¿ƒè¿›å¹»è§‰ï¼Ÿ")ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†[è¡¨2](#S4.T2 "åœ¨4.4
    ğš„ğš—ğš”ğšğšğš™ğš‹ğš›ğšğšğšğšğšœ")ã€‚å¦‚æ ‡é¢˜ä¸­æ‰€è¿°ï¼Œæˆ‘ä»¬å¯¹æ¯åˆ—è¿›è¡Œäº†ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†æ‰€æœ‰å€¼ä¸è¯¥åˆ—ä¸­çš„æœ€å¤§å€¼è¿›è¡Œæ¯”è¾ƒã€‚
- en: For each subset of the test set, we randomly shuffle all the examples in it,
    split them up into 100 approximately equally sized subsets, and compute accuracy
    for each of them for all the models of interest. We then apply paired-sample t-test
    with $p<0.05$.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæµ‹è¯•é›†çš„æ¯ä¸ªå­é›†ï¼Œæˆ‘ä»¬éšæœºæ‰“ä¹±å…¶ä¸­çš„æ‰€æœ‰ç¤ºä¾‹ï¼Œå°†å…¶åˆ†æˆ100ä¸ªå¤§è‡´ç›¸ç­‰çš„å­é›†ï¼Œç„¶åè®¡ç®—æ‰€æœ‰æ„Ÿå…´è¶£æ¨¡å‹çš„æ¯ä¸ªå­é›†çš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬éšååº”ç”¨é…å¯¹æ ·æœ¬tæ£€éªŒï¼Œ$p<0.05$ã€‚
- en: 'In [TableÂ 2](#S4.T2 "In 4.4 The Influence of ğš„ğš—ğš”ğš—ğš˜ğš ğš— vs ğ™ºğš—ğš˜ğš ğš— on Accuracy:
    A Linear Model Perspective â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning
    LLMs on New Knowledge Encourage Hallucinations?"), the best result is in bold,
    as well as all the results with statistically non-significant difference from
    the best with $p<0.05$, except two cases where it is only with $p<0.05$ $\mathtt{Unk}$
    $\mathtt{Mkn}$).'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[è¡¨2](#S4.T2 "åœ¨4.4 ğš„ğš—ğš”ğšğšğš™ğš‹ğš›ğšğšğšğšğšœ")ä¸­ï¼Œæœ€ä½³ç»“æœç”¨ç²—ä½“è¡¨ç¤ºï¼Œæ‰€æœ‰ä¸æœ€ä½³ç»“æœå·®å¼‚ç»Ÿè®¡ä¸Šä¸æ˜¾è‘—çš„ç»“æœç”¨$p<0.05$è¡¨ç¤ºï¼Œé™¤äº†ä¸¤ä¸ªä»…ç”¨$p<0.05$
    $\mathtt{Unk}$ $\mathtt{Mkn}$)çš„æƒ…å†µã€‚
- en: 'Since we also discuss â€œhorizontalâ€ comparisons, where we compare early_stop
    to Convergence, we additionally run significance tests (not annotated in [TableÂ 2](#S4.T2
    "In 4.4 The Influence of ğš„ğš—ğš”ğš—ğš˜ğš ğš— vs ğ™ºğš—ğš˜ğš ğš— on Accuracy: A Linear Model Perspective
    â€£ 4 How Harmful are ğš„ğš—ğš”ğš—ğš˜ğš ğš— Examples? â€£ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?")) for $All$ was not statistically significant while
    for all others (including $D_{\mathtt{Natural}}$.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬è¿˜è®¨è®ºäº†â€œæ¨ªå‘â€æ¯”è¾ƒï¼Œå³æ¯”è¾ƒearly_stopä¸Convergenceï¼Œæˆ‘ä»¬å¦å¤–è¿›è¡Œäº†æ˜¾è‘—æ€§æ£€éªŒï¼ˆåœ¨[è¡¨2](#S4.T2 "åœ¨4.4 ğš„ğš—ğš”ğš—ğš˜ğš ğš—ä¸ğ™ºğš—ğš˜ğšğšğš™ğš‹ğš›ğšğšğšğšğšœ")ï¼‰å¯¹$All$è¿›è¡Œäº†æ˜¾è‘—æ€§æ£€éªŒï¼Œä½†ç»“æœåœ¨ç»Ÿè®¡ä¸Šå¹¶ä¸æ˜¾è‘—ï¼Œè€Œå¯¹å…¶ä»–æ‰€æœ‰ç±»åˆ«ï¼ˆåŒ…æ‹¬$D_{\mathtt{Natural}}$ï¼‰åˆ™æ˜¾è‘—ã€‚
- en: Appendix J The P(True) Case Study
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½•J P(True)æ¡ˆä¾‹ç ”ç©¶
- en: 'In Â§[6](#S6 "6 SliCK Knowledge Categories Analysis â€£ Does Fine-Tuning LLMs
    on New Knowledge Encourage Hallucinations?") we used the P(True) metric from Kadavath
    etÂ al. ([2022](#bib.bib10)) as a case study for comparison. In [FigureÂ 5](#S6.F5
    "In Fine-grained Known Categories â€£ 6 SliCK Knowledge Categories Analysis â€£ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?") we compare our $\mathtt{Unknown}$
    based on a threshold of P(True). We calculated P(True) for every $(q,a)$ pair
    in the test set using Kadavath etÂ al. ([2022](#bib.bib10))â€™s prompt:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Â§[6](#S6 "6 SliCKçŸ¥è¯†ç±»åˆ«åˆ†æ â€£ å¯¹LLMsè¿›è¡Œæ–°çŸ¥è¯†å¾®è°ƒæ˜¯å¦ä¼šä¿ƒè¿›å¹»è§‰ï¼Ÿ")ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†Kadavathç­‰äººï¼ˆ[2022](#bib.bib10)ï¼‰æå‡ºçš„P(True)æŒ‡æ ‡ä½œä¸ºå¯¹æ¯”çš„æ¡ˆä¾‹ç ”ç©¶ã€‚åœ¨[å›¾5](#S6.F5
    "åœ¨ç»†ç²’åº¦å·²çŸ¥ç±»åˆ« â€£ 6 SliCKçŸ¥è¯†ç±»åˆ«åˆ†æ â€£ å¯¹LLMsè¿›è¡Œæ–°çŸ¥è¯†å¾®è°ƒæ˜¯å¦ä¼šä¿ƒè¿›å¹»è§‰ï¼Ÿ")ä¸­ï¼Œæˆ‘ä»¬æ ¹æ®P(True)çš„é˜ˆå€¼æ¯”è¾ƒäº†æˆ‘ä»¬çš„$\mathtt{Unknown}$ã€‚æˆ‘ä»¬ä½¿ç”¨Kadavathç­‰äººï¼ˆ[2022](#bib.bib10)ï¼‰çš„æç¤ºè®¡ç®—äº†æµ‹è¯•é›†ä¸­æ¯ä¸ª$(q,a)$å¯¹çš„P(True)ã€‚
- en: 'Question: Where is Paris located? Proposed Answer: France Is the proposed answer:
    (A) True (B) False The proposed answer is:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šå·´é»åœ¨å“ªé‡Œï¼Ÿå»ºè®®å›ç­”ï¼šæ³•å›½ã€‚å»ºè®®çš„ç­”æ¡ˆæ˜¯ï¼šï¼ˆAï¼‰æ­£ç¡®ï¼ˆBï¼‰é”™è¯¯ã€‚å»ºè®®çš„ç­”æ¡ˆæ˜¯ï¼š
- en: 'We then treated $(q,a)$. We experimented with each possible threshold $T$,
    according to our test set. For each threshold $T$ out of the test set, (2) what
    was the accuracy on these examples after fine-tuning. We plot the results in [FigureÂ 5](#S6.F5
    "In Fine-grained Known Categories â€£ 6 SliCK Knowledge Categories Analysis â€£ Does
    Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"), where P(True) is
    represented with the yellow line and our $\mathtt{Unknown}$). We also check smaller
    values of $N_{\text{ex}}$ (Â§[5](#S5 "5 Understanding Knowledge Types: Their Value
    and Impact â€£ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?")).'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ¥ç€å¤„ç†äº†$(q,a)$ã€‚æˆ‘ä»¬æ ¹æ®æµ‹è¯•é›†å°è¯•äº†æ¯ä¸€ä¸ªå¯èƒ½çš„é˜ˆå€¼$T$ã€‚å¯¹äºæµ‹è¯•é›†ä¸­çš„æ¯ä¸ªé˜ˆå€¼$T$ï¼Œï¼ˆ2ï¼‰åœ¨å¾®è°ƒåçš„è¿™äº›ä¾‹å­ä¸Šçš„å‡†ç¡®ç‡æ˜¯å¤šå°‘ã€‚æˆ‘ä»¬åœ¨[å›¾5](#S6.F5
    "åœ¨ç»†ç²’åº¦å·²çŸ¥ç±»åˆ« â€£ 6 SliCKçŸ¥è¯†ç±»åˆ«åˆ†æ â€£ å¾®è°ƒLLMåœ¨æ–°çŸ¥è¯†ä¸Šæ˜¯å¦ä¼šå¼•èµ·å¹»è§‰ï¼Ÿ")ä¸­ç»˜åˆ¶äº†ç»“æœï¼Œå…¶ä¸­P(True)ç”¨é»„è‰²çº¿è¡¨ç¤ºï¼Œä»¥åŠæˆ‘ä»¬çš„$\mathtt{Unknown}$ï¼‰ã€‚æˆ‘ä»¬è¿˜æ£€æŸ¥äº†è¾ƒå°çš„$N_{\text{ex}}$
    (Â§[5](#S5 "5 ç†è§£çŸ¥è¯†ç±»å‹ï¼šå…¶ä»·å€¼ä¸å½±å“ â€£ å¾®è°ƒLLMåœ¨æ–°çŸ¥è¯†ä¸Šæ˜¯å¦ä¼šå¼•èµ·å¹»è§‰ï¼Ÿ"))ã€‚
- en: 'Appendix K Re-labeling $\mathtt{Unknown}$ Fine-tuning Example with an Uncertainty
    Expression: Initial Experiment'
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½•K é‡æ–°æ ‡è®°$\mathtt{Unknown}$ å¾®è°ƒä¾‹å­ä¸ä¸ç¡®å®šæ€§è¡¨è¾¾ï¼šåˆæ­¥å®éªŒ
- en: '|  | early_stop |  | Convergence |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '|  | early_stop |  | Convergence |'
- en: '| --- | --- | --- | --- |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  | Accuracy | % Answered |  | Accuracy | % Answered |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '|  | å‡†ç¡®ç‡ | % å›ç­” |  | å‡†ç¡®ç‡ | % å›ç­” |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| $D$ | 43.0 | 100.0 |  | 38.8 | 100.0 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| $D$ | 43.0 | 100.0 |  | 38.8 | 100.0 |'
- en: '| $D_{\mathtt{IDK}}$ | 61.8 | 58.7 |  | 61.8 | 55.6 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| $D_{\mathtt{IDK}}$ | 61.8 | 58.7 |  | 61.8 | 55.6 |'
- en: 'Table 8: Results of our initial experiment where the label of the $\mathtt{Unknown}$
    in this case is the variant with $50\%$ and $50\%$. $D_{\mathtt{IDK}}$ $\mathtt{Unknown}$
    did not respond with *â€œI donâ€™t knowâ€*.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨8ï¼šæˆ‘ä»¬åˆæ­¥å®éªŒçš„ç»“æœï¼Œå…¶ä¸­$\mathtt{Unknown}$çš„æ ‡ç­¾åœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯$50\%$å’Œ$50\%$çš„å˜ä½“ã€‚$D_{\mathtt{IDK}}$
    $\mathtt{Unknown}$æœªä»¥*â€œæˆ‘ä¸çŸ¥é“â€*å›åº”ã€‚
- en: In this work we showed that fitting $\mathtt{Unknown}$ examples from the fine-tuning
    dataset.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æ‹Ÿåˆ$\mathtt{Unknown}$ä¾‹å­æ¥è‡ªå¾®è°ƒæ•°æ®é›†çš„æƒ…å†µã€‚
- en: We now perform a preliminary experiment where check whether fine-tuning the
    model to abstain from $\mathtt{Unknown}$ fine-tuning examples with the expression
    *â€œI donâ€™t knowâ€* and test whether this mitigates the observed overfitting.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨è¿›è¡Œä¸€ä¸ªåˆæ­¥å®éªŒï¼Œæ£€æŸ¥æ˜¯å¦é€šè¿‡å¾®è°ƒæ¨¡å‹ä»¥é¿å…$\mathtt{Unknown}$å¾®è°ƒä¾‹å­ï¼Œå¹¶æµ‹è¯•è¿™ç§æ–¹å¼æ˜¯å¦ç¼“è§£äº†è§‚å¯Ÿåˆ°çš„è¿‡æ‹Ÿåˆç°è±¡ã€‚
- en: '[TableÂ 8](#A11.T8 "In Appendix K Re-labeling ğš„ğš—ğš”ğš—ğš˜ğš ğš— Fine-tuning Example with
    an Uncertainty Expression: Initial Experiment â€£ Does Fine-Tuning LLMs on New Knowledge
    Encourage Hallucinations?") presents the $\%$ did not respond with *â€œI donâ€™t knowâ€*)
    and the accuracy on those questions. This experiment was conducted on the $D$
    $\mathtt{Unknown}$ as a reference and the second row is for the results with $D_{\mathtt{IDK}}$
    of the $\mathtt{Unknown}$ was replaced with *â€œI donâ€™t knowâ€*'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '[è¡¨8](#A11.T8 "åœ¨é™„å½•Ké‡æ–°æ ‡è®°ğš„ğš—ğš”ğš—ğš˜ğš ğš— å¾®è°ƒä¾‹å­ä¸ä¸ç¡®å®šæ€§è¡¨è¾¾ï¼šåˆæ­¥å®éªŒ â€£ å¾®è°ƒLLMåœ¨æ–°çŸ¥è¯†ä¸Šæ˜¯å¦ä¼šå¼•èµ·å¹»è§‰ï¼Ÿ")å±•ç¤ºäº†$\%$æœªä»¥*â€œæˆ‘ä¸çŸ¥é“â€*å›åº”çš„å‡†ç¡®ç‡ã€‚è¿™é¡¹å®éªŒä»¥$D$
    $\mathtt{Unknown}$ä½œä¸ºå‚è€ƒï¼Œç¬¬äºŒè¡Œæ˜¯$D_{\mathtt{IDK}}$çš„ç»“æœï¼Œå…¶ä¸­$\mathtt{Unknown}$è¢«æ›¿æ¢ä¸º*â€œæˆ‘ä¸çŸ¥é“â€*ã€‚'
- en: Consistent with the findings from previous work Zhang etÂ al. ([2023](#bib.bib33)),
    we observe an improved accuracy on willingly answered test examples (when comparing
    $D$). When we compare early_stop vs Convergence for $D$) which illustrates the
    overfitting effect. However, we observe that re-labeling the $\mathtt{Unknown}$
    remains $61.8$)
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Zhangç­‰äººï¼ˆ[2023](#bib.bib33)ï¼‰çš„å…ˆå‰ç ”ç©¶ç»“æœä¸€è‡´ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°åœ¨è‡ªæ„¿å›ç­”çš„æµ‹è¯•ä¾‹å­ä¸Šå‡†ç¡®ç‡æœ‰æ‰€æé«˜ï¼ˆå½“æ¯”è¾ƒ$D$æ—¶ï¼‰ã€‚å½“æˆ‘ä»¬æ¯”è¾ƒearly_stopä¸Convergenceå¯¹äº$D$æ—¶ï¼Œè¿™æ˜¾ç¤ºäº†è¿‡æ‹Ÿåˆæ•ˆåº”ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°é‡æ–°æ ‡è®°$\mathtt{Unknown}$çš„å‡†ç¡®ç‡ä»ä¸º$61.8$ã€‚
